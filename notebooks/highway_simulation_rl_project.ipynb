{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b48b6a92d8d88e15753faba58c47bae2",
     "grade": false,
     "grade_id": "cell-b0b3b6b4f891b031",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Reinforcement Learning\n",
    "## Graded Assessment: RL Project\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Definition\n",
    "\n",
    "For this reinforcement learning project, the challenge involves developing an RL agent that can proficiently navigate the HighwayEnv, a minimalist simulation environment tailored for autonomous driving decision-making. The primary objective is to construct an RL agent capable of effectively managing the simulated traffic dynamics of HighwayEnv, and subsequently, to benchmark its performance against a pre-existing agent implemented via the [Stable Baselines3](https://github.com/DLR-RM/stable-baselines3) library.\n",
    "\n",
    "### Environment Description\n",
    "**HighwayEnv** simulates the complex scenario where autonomous vehicles are required to navigate traffic on a multi-lane highway. The overarching goal for these agents includes optimizing travel time, executing safe lane changes, maintaining appropriate speeds, and adhering to traffic regulations to avoid collisions.\n",
    "\n",
    "### State Space (Observations)\n",
    "The state space comprises:\n",
    "- **Position and Velocity of the Agent Vehicle:** Longitudinal and lateral positions and velocities are critical for determining the agent's current and projected states.\n",
    "- **Position and Velocity of Other Vehicles:** The relative positions and velocities of nearby vehicles are essential for spatial awareness and collision avoidance.\n",
    "- **Road Geometry:** This includes the number of lanes and lane markings, which are crucial for proper lane adherence and navigation.\n",
    "\n",
    "### Action Space\n",
    "The agent can take several discrete actions:\n",
    "- **Accelerate:** Increase the vehicle's speed.\n",
    "- **Decelerate:** Reduce the vehicle's speed.\n",
    "- **Change Lane to the Left/Right:** Shift to an adjacent left or right lane if it is safe and possible.\n",
    "- **Maintain Current State:** Continue with the present speed and lane.\n",
    "\n",
    "### Transition Dynamics\n",
    "The dynamics of this environment are governed by both the physical laws of vehicle motion and the programmed behavior of other simulated vehicles, which follow basic traffic rules and patterns of lane adherence.\n",
    "\n",
    "### Reward Function\n",
    "The reward system is designed to promote safety, efficiency, comfort, and lane adherence:\n",
    "- **Safety:** Imposes penalties for near-misses and collisions.\n",
    "- **Efficiency:** Rewards are given for maintaining optimal speeds and minimizing travel time to goals.\n",
    "- **Comfort:** Discourages excessive and abrupt vehicular maneuvers.\n",
    "- **Lane Adherence:** Encourages maintaining lane discipline unless overtaking or avoiding an obstacle.\n",
    "\n",
    "### Hypothesis\n",
    "The hypothesis to be tested is whether a custom-implemented Deep Q-Network (DQN) can outperform an established RL agent from the Stable Baselines3 library in terms of cumulative rewards. This will be measured through the agent’s ability to adapt to varying traffic densities and complexities, ensuring both efficient and safe navigation.\n",
    "\n",
    "### Objectives for the DQN Implementation\n",
    "The project aims to implement a DQN that learns an optimal policy based on the defined state and action spaces, adhering to the specified transition dynamics and reward structure. The key objectives for the DQN agent include:\n",
    "- Efficiently navigating through traffic without predefined rules for specific situations.\n",
    "- Developing a balanced driving policy that optimizes speed, safety, and comfort.\n",
    "- Demonstrating superior adaptability and performance in diverse traffic scenarios when compared to the existing solution.\n",
    "\n",
    "This structured approach lays the groundwork for developing and evaluating the reinforcement learning model, focusing on fostering an autonomous driving strategy that can effectively operate within the realistic confines of highway traffic conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Reinforcement Learning (RL) has emerged as a powerful method for solving decision-making problems where an agent learns to act in an environment by performing actions and receiving feedback through rewards. In the context of autonomous driving, particularly in complex environments like those simulated by HighwayEnv, RL can be leveraged to enable vehicles to make intelligent decisions dynamically.\n",
    "\n",
    "**Deep Q-Networks (DQN)**, introduced by Mnih et al. (2015), have been pivotal in applying RL to environments with high-dimensional state spaces, such as video games and, relevantly, driving simulations (Mnih et al., 2015). DQN integrates deep neural networks with Q-learning, where the network approximates the Q-value function. The Q-value function quantifies the expected utility of taking a given action in a particular state, followed by following a certain policy. **Strengths** of DQN include its ability to handle environments with large state and action spaces and its robustness in learning stable policies in complex scenarios. However, **weaknesses** include its sample inefficiency—often requiring numerous interactions with the environment, which can be computationally expensive—and its tendency to overestimate Q-values leading to suboptimal policy decisions.\n",
    "\n",
    "**Proximal Policy Optimization (PPO)** and **Trust Region Policy Optimization (TRPO)** are policy gradient methods that optimize the policy directly. These methods are noted for their stability and efficiency, which come from limiting the steps in policy space to avoid destructive large updates (Schulman et al., 2015; 2017). For autonomous driving, the **strength** of these methods lies in their continuous action space handling, making them suitable for controlling the nuanced actions of a vehicle. The **weakness**, however, is that they can be sensitive to hyperparameter settings and require careful tuning to achieve the best performance.\n",
    "\n",
    "In autonomous driving simulations like those provided by HighwayEnv, several studies have demonstrated the effectiveness of these methods. For example, RL has been used to successfully navigate complex traffic scenarios, demonstrating significant potential in achieving human-like driving capabilities (Dosovitskiy et al., 2017). These environments often simulate realistic traffic conditions and provide a benchmark for evaluating different RL methods, including DQN and PPO, in terms of their ability to learn safe and efficient driving policies.\n",
    "\n",
    "Comparative studies, such as those by Liang et al. (2018), have shown that while DQN can effectively learn policy for discrete action spaces in driving simulations, methods like PPO tend to outperform in terms of achieving smoother control and handling continuous action spaces, which are critical in real-world driving scenarios.\n",
    "\n",
    "In summary, reinforcement learning offers significant promise for developing intelligent autonomous driving systems capable of operating in complex, dynamic environments. Both value-based methods like DQN and policy-based methods like PPO have their merits and limitations, making them suitable for different aspects of the driving problem. Continuous advancements in RL methods and computational resources are likely to further enhance their applicability and performance in autonomous driving tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up the Highway Environment\n",
    "\n",
    "The highway-env environment introduces an exciting domain focused on autonomous driving and decision-making in traffic scenarios. This environment is designed for experimenting with various aspects of vehicle behavior, such as lane following, overtaking, and navigating through intersections, making it rich in learning opportunities for reinforcement learning applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import gymnasium as gym\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "env = gym.make('highway-fast-v0', render_mode=\"rgb_array\")\n",
    "env.reset()\n",
    "\n",
    "# To visualise a initial/idle state\n",
    "action = env.unwrapped.action_type.actions_indexes[\"IDLE\"]\n",
    "obs, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "plt.imshow(env.render())\n",
    "plt.show()\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the Highway Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring and understanding the environment by analysing the observation and action spaces, the dynamics of the environment, and the reward structure. Here’s how you can start exploring highway-env:\n",
    "\n",
    "#### Understanding the Observation Space:\n",
    "\n",
    "The observation space in highway-env can vary based on the configuration but typically includes the positions, velocities, and other attributes of nearby vehicles relative to the controlled vehicle. Understanding this space is crucial for designing your agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: Box(-inf, inf, (5, 5), float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Observation space:\", env.observation_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding the Action Space:\n",
    "Actions in highway-env usually involve discrete decisions like changing lanes, accelerating, or braking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space: Discrete(5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Action space:\", env.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reward Structure Exploration\n",
    "\n",
    "Understanding how rewards are assigned is crucial for designing your RL model. Perform actions and progress through the game to see what actions increase the score, how much reward is given for different achievements, and identify if there are any penalties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward received:  0.7999999999999999\n",
      "Reward received:  0.7999999999999999\n",
      "Reward received:  0.8327113850086175\n",
      "Reward received:  0.7175567607980314\n",
      "Reward received:  0.7023121980100128\n",
      "Reward received:  0.8160795220498324\n",
      "Reward received:  0.8637845794187456\n",
      "Reward received:  0.7505909305552\n",
      "Reward received:  0.7013873830656888\n",
      "Reward received:  0.7002958141970411\n",
      "Reward received:  0.7333333333333334\n",
      "Reward received:  0.849111821699985\n",
      "Reward received:  0.06666666666666665\n",
      "Reward received:  0.06666666666666665\n",
      "Reward received:  0.06666666666666665\n",
      "Reward received:  0.06666666666666665\n",
      "Reward received:  0.06666666666666665\n",
      "Reward received:  0.06666666666666665\n",
      "Reward received:  0.06666666666666665\n",
      "Reward received:  0.06666666666666665\n",
      "Reward received:  0.06666666666666665\n",
      "Reward received:  0.06666666666666665\n",
      "Reward received:  0.06666666666666665\n",
      "Reward received:  0.06666666666666665\n",
      "Reward received:  0.06666666666666665\n",
      "Reward received:  0.06666666666666665\n",
      "Reward received:  0.06666666666666665\n",
      "Reward received:  0.06666666666666665\n",
      "Reward received:  0.03333333333333336\n",
      "Reward received:  0.03333333333333336\n",
      "Reward received:  0.03333333333333336\n",
      "Reward received:  0.03333333333333336\n",
      "Reward received:  0.06666666666666665\n",
      "Reward received:  0.06666666666666665\n",
      "Reward received:  0.06666666666666665\n",
      "Reward received:  0.06666666666666665\n",
      "Reward received:  0.06666666666666665\n",
      "Reward received:  0.03333333333333336\n",
      "Reward received:  0.03333333333333336\n",
      "Reward received:  0.06666666666666665\n",
      "Reward received:  0.03333333333333336\n",
      "Reward received:  0.03333333333333336\n",
      "Reward received:  0.03333333333333336\n",
      "Reward received:  0.03333333333333336\n",
      "Reward received:  0.03333333333333336\n",
      "Reward received:  0.03333333333333336\n",
      "Reward received:  0.03333333333333336\n",
      "Reward received:  0.03333333333333336\n",
      "Reward received:  0.03333333333333336\n",
      "Reward received:  0.03333333333333336\n"
     ]
    }
   ],
   "source": [
    "# Example: Perform an action and observe the reward\n",
    "env.reset()\n",
    "for _ in range(50):\n",
    "    _, reward, _, _, _ = env.step(env.action_space.sample())\n",
    "    print(\"Reward received: \", reward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the Environment - Simulation:\n",
    "\n",
    "You can visualize the environment in a Jupyter notebook or Python script to understand the dynamics visually. highway-env supports rendering directly to a Jupyter notebook using its render method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def generate_gif(frames):\n",
    "    # Save the captured frames as a GIF\n",
    "    gif_path = 'highway_simulation.gif'\n",
    "    imageio.mimsave(gif_path, frames, fps=10)  # fps controls the speed of the animation\n",
    "\n",
    "    # Display the GIF in the notebook\n",
    "    display(Image(filename=gif_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple environment demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/gif": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reset environment\n",
    "env.reset()\n",
    "\n",
    "frames = []  # for storing the frames captured during the simulation\n",
    "\n",
    "# Simulate the environment\n",
    "for _ in range(50):\n",
    "    action = env.action_space.sample()  # choose a random action\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    frames.append(env.render())\n",
    "    done = terminated or truncated\n",
    "    if done:\n",
    "        env.reset()\n",
    "\n",
    "# Close the environment to free resources\n",
    "env.close()\n",
    "\n",
    "generate_gif(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the objective:\n",
    "\n",
    "The agent's object is straighforward: maximize average speed while minimizing collisions, with an additional goal of staying in the right lane as much as possible for extra reward. These objectives align well with the rewards settings described (collision_reward, high_speed_reward, and implicitly mentioning a right_lane_reward). This clarity will guide the design of your reinforcement learning model and the reward structure you implement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heavy Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.        ,  0.7724457 ,  0.6666667 ,  0.3125    ,  0.        ],\n",
       "        [ 1.        ,  0.10608794, -0.6666667 , -0.04544504,  0.        ],\n",
       "        [ 1.        ,  0.23279905, -0.33333334, -0.01973059,  0.        ],\n",
       "        [ 1.        ,  0.36426824, -0.33333334, -0.02661807,  0.        ],\n",
       "        [ 1.        ,  0.49082628,  0.        , -0.03075124,  0.        ]],\n",
       "       dtype=float32),\n",
       " {'speed': 25,\n",
       "  'crashed': False,\n",
       "  'action': 3,\n",
       "  'rewards': {'collision_reward': 0.0,\n",
       "   'right_lane_reward': 1.0,\n",
       "   'high_speed_reward': 0.5,\n",
       "   'on_road_reward': 1.0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"highway-fast-v0\", render_mode='rgb_array')\n",
    "env.reset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Performance with Stable Baselines3\n",
    "\n",
    "Stable Baselines3 is a set of reliable implementations of reinforcement learning algorithms in PyTorch. It is the next major version of Stable Baselines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "Reinforcement Learning agents can be trained using libraries such as eleurent/rl-agents, openai/baselines or Stable Baselines3. In the next cell, a SB3 DQN is trained on highway-fast-v0 with its default kinematics observation and an MLP model. The hyperparameters come from the [documentation](https://highway-env.farama.org/quickstart/#training-an-agent) and, for a first training, the default values are used. Further tuning is performed next in this notebook.\n",
    "\n",
    "Before the fine-tuning process, the chosen hyperparameters for the DQN model were set with a mix of default values and some tailored adjustments expected to work well for a range of problems:\n",
    "\n",
    "- `net_arch=[256, 256]`: This specifies a neural network architecture with two hidden layers, each consisting of 256 neurons. This relatively large network architecture is chosen with the expectation that it can capture the complexity of the state space and learn effective policies.\n",
    "\n",
    "- `learning_rate=5e-4`: The learning rate determines the step size at each iteration while moving toward a minimum of the loss function. A rate of 0.0005 is a common starting point that is not too large to overshoot minima nor too small to slow the convergence.\n",
    "\n",
    "- `buffer_size=15000`: This is the size of the replay buffer. A larger buffer size allows the agent to learn from a broader set of experiences, potentially smoothing out the learning process and avoiding overfitting to recent experiences.\n",
    "\n",
    "- `learning_starts=200`: This parameter determines how many steps of the model are run before the learning process begins. This warm-up period allows the replay buffer to fill with experiences, ensuring that learning does not begin with a poor understanding of the environment.\n",
    "\n",
    "- `batch_size=32`: This sets the number of experiences to sample from the buffer to update the network at each learning step. A batch size of 32 is a standard choice that balances the variance and convergence rate.\n",
    "\n",
    "- `gamma=0.8`: The discount factor, gamma, balances immediate and future rewards. A value of 0.8 suggests that future rewards are taken into consideration significantly, but with a preference for more immediate rewards.\n",
    "\n",
    "- `train_freq=1`: This sets the frequency of training the network. Here, the network is trained at every step.\n",
    "\n",
    "- `gradient_steps=1`: This is the number of gradient steps taken for each training step. Since this is set to 1, it means that a single optimization step is taken for each training step.\n",
    "\n",
    "- `target_update_interval=50`: This parameter sets how often the target network is updated. The target network stabilizes training by providing a fixed snapshot of the policy for a period of time. An interval of 50 is a balance between stability and responsiveness to changes in the policy.\n",
    "\n",
    "- `verbose=1`: This sets the verbosity level to output detailed logs during training.\n",
    "\n",
    "- `tensorboard_log=\"highway_dqn_baseline/tensorboard_logs\"`: This argument points to the directory where TensorBoard logs should be saved, enabling visualization of the training process.\n",
    "\n",
    "These hyperparameters were chosen to provide a balance between exploration and exploitation, learning efficiency, and computational resources. They are often selected based on empirical results from similar environments or as a starting point for further refinement through fine-tuning or hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to highway_dqn_baseline/tensorboard_logs/DQN_2\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.8     |\n",
      "|    ep_rew_mean      | 11.8     |\n",
      "|    exploration_rate | 0.97     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 63       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11       |\n",
      "|    ep_rew_mean      | 8.1      |\n",
      "|    exploration_rate | 0.958    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 88       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.8     |\n",
      "|    ep_rew_mean      | 9.62     |\n",
      "|    exploration_rate | 0.927    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 154      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.4     |\n",
      "|    ep_rew_mean      | 7.72     |\n",
      "|    exploration_rate | 0.921    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 167      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.9     |\n",
      "|    ep_rew_mean      | 8.15     |\n",
      "|    exploration_rate | 0.896    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 219      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0541   |\n",
      "|    n_updates        | 18       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.4     |\n",
      "|    ep_rew_mean      | 7.79     |\n",
      "|    exploration_rate | 0.881    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 66       |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 250      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0351   |\n",
      "|    n_updates        | 49       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10       |\n",
      "|    ep_rew_mean      | 7.55     |\n",
      "|    exploration_rate | 0.867    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 66       |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 281      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.156    |\n",
      "|    n_updates        | 80       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.3     |\n",
      "|    ep_rew_mean      | 7.82     |\n",
      "|    exploration_rate | 0.843    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 65       |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 330      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.174    |\n",
      "|    n_updates        | 129      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.4     |\n",
      "|    ep_rew_mean      | 7.88     |\n",
      "|    exploration_rate | 0.822    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 64       |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 374      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.474    |\n",
      "|    n_updates        | 173      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.3     |\n",
      "|    ep_rew_mean      | 7.87     |\n",
      "|    exploration_rate | 0.803    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 64       |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 414      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.208    |\n",
      "|    n_updates        | 213      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 7.7      |\n",
      "|    exploration_rate | 0.789    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 63       |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 445      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.197    |\n",
      "|    n_updates        | 244      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.4     |\n",
      "|    ep_rew_mean      | 7.9      |\n",
      "|    exploration_rate | 0.763    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 63       |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 498      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.166    |\n",
      "|    n_updates        | 297      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 7.78     |\n",
      "|    exploration_rate | 0.748    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 63       |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 530      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.172    |\n",
      "|    n_updates        | 329      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 7.82     |\n",
      "|    exploration_rate | 0.727    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 63       |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 574      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.101    |\n",
      "|    n_updates        | 373      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 7.7      |\n",
      "|    exploration_rate | 0.712    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 63       |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 606      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.449    |\n",
      "|    n_updates        | 405      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 7.65     |\n",
      "|    exploration_rate | 0.693    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 63       |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 646      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.204    |\n",
      "|    n_updates        | 445      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10       |\n",
      "|    ep_rew_mean      | 7.61     |\n",
      "|    exploration_rate | 0.676    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 683      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.502    |\n",
      "|    n_updates        | 482      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.81     |\n",
      "|    ep_rew_mean      | 7.41     |\n",
      "|    exploration_rate | 0.665    |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 706      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.187    |\n",
      "|    n_updates        | 505      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.59     |\n",
      "|    ep_rew_mean      | 7.24     |\n",
      "|    exploration_rate | 0.654    |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 729      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.279    |\n",
      "|    n_updates        | 528      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.55     |\n",
      "|    ep_rew_mean      | 7.24     |\n",
      "|    exploration_rate | 0.637    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 764      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.363    |\n",
      "|    n_updates        | 563      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.63     |\n",
      "|    ep_rew_mean      | 7.29     |\n",
      "|    exploration_rate | 0.616    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 809      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.491    |\n",
      "|    n_updates        | 608      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.51     |\n",
      "|    ep_rew_mean      | 7.21     |\n",
      "|    exploration_rate | 0.602    |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 837      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.282    |\n",
      "|    n_updates        | 636      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.51     |\n",
      "|    ep_rew_mean      | 7.21     |\n",
      "|    exploration_rate | 0.584    |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 875      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.114    |\n",
      "|    n_updates        | 674      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.78     |\n",
      "|    ep_rew_mean      | 7.44     |\n",
      "|    exploration_rate | 0.554    |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 939      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.216    |\n",
      "|    n_updates        | 738      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.86     |\n",
      "|    ep_rew_mean      | 7.49     |\n",
      "|    exploration_rate | 0.532    |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 986      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.248    |\n",
      "|    n_updates        | 785      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.59     |\n",
      "|    ep_rew_mean      | 7.3      |\n",
      "|    exploration_rate | 0.515    |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 1022     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.59     |\n",
      "|    n_updates        | 821      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 7.78     |\n",
      "|    exploration_rate | 0.473    |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 1110     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.75     |\n",
      "|    n_updates        | 909      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 7.77     |\n",
      "|    exploration_rate | 0.44     |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 1178     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.209    |\n",
      "|    n_updates        | 977      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.3     |\n",
      "|    ep_rew_mean      | 7.84     |\n",
      "|    exploration_rate | 0.43     |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 1199     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.409    |\n",
      "|    n_updates        | 998      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.5     |\n",
      "|    ep_rew_mean      | 7.96     |\n",
      "|    exploration_rate | 0.399    |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 1265     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.666    |\n",
      "|    n_updates        | 1064     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.8     |\n",
      "|    ep_rew_mean      | 8.17     |\n",
      "|    exploration_rate | 0.37     |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 1326     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.428    |\n",
      "|    n_updates        | 1125     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.8     |\n",
      "|    ep_rew_mean      | 8.2      |\n",
      "|    exploration_rate | 0.352    |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 1365     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.306    |\n",
      "|    n_updates        | 1164     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.1     |\n",
      "|    ep_rew_mean      | 8.37     |\n",
      "|    exploration_rate | 0.316    |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 1439     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.278    |\n",
      "|    n_updates        | 1238     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.5     |\n",
      "|    ep_rew_mean      | 8.66     |\n",
      "|    exploration_rate | 0.278    |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 1520     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.188    |\n",
      "|    n_updates        | 1319     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.7     |\n",
      "|    ep_rew_mean      | 8.87     |\n",
      "|    exploration_rate | 0.246    |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 1587     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.113    |\n",
      "|    n_updates        | 1386     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12       |\n",
      "|    ep_rew_mean      | 9.1      |\n",
      "|    exploration_rate | 0.218    |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 1647     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.542    |\n",
      "|    n_updates        | 1446     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.8     |\n",
      "|    ep_rew_mean      | 8.97     |\n",
      "|    exploration_rate | 0.202    |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 1680     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.193    |\n",
      "|    n_updates        | 1479     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.9     |\n",
      "|    ep_rew_mean      | 9.02     |\n",
      "|    exploration_rate | 0.184    |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 1718     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.121    |\n",
      "|    n_updates        | 1517     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.4     |\n",
      "|    ep_rew_mean      | 9.44     |\n",
      "|    exploration_rate | 0.137    |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 1817     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.365    |\n",
      "|    n_updates        | 1616     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.8     |\n",
      "|    ep_rew_mean      | 9.76     |\n",
      "|    exploration_rate | 0.105    |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 1885     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0332   |\n",
      "|    n_updates        | 1684     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.8     |\n",
      "|    ep_rew_mean      | 9.87     |\n",
      "|    exploration_rate | 0.0837   |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 1929     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.12     |\n",
      "|    n_updates        | 1728     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13       |\n",
      "|    ep_rew_mean      | 10       |\n",
      "|    exploration_rate | 0.0586   |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 1982     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0229   |\n",
      "|    n_updates        | 1781     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 10.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 2039     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.399    |\n",
      "|    n_updates        | 1838     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 10.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 2107     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.118    |\n",
      "|    n_updates        | 1906     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14       |\n",
      "|    ep_rew_mean      | 10.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 2167     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 1966     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.4     |\n",
      "|    ep_rew_mean      | 11.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 2254     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.186    |\n",
      "|    n_updates        | 2053     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.8     |\n",
      "|    ep_rew_mean      | 11.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 2316     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.137    |\n",
      "|    n_updates        | 2115     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.8     |\n",
      "|    ep_rew_mean      | 11.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 2360     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.191    |\n",
      "|    n_updates        | 2159     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.9     |\n",
      "|    ep_rew_mean      | 11.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 2427     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.109    |\n",
      "|    n_updates        | 2226     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15       |\n",
      "|    ep_rew_mean      | 11.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 2484     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.102    |\n",
      "|    n_updates        | 2283     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15       |\n",
      "|    ep_rew_mean      | 11.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 2520     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.2      |\n",
      "|    n_updates        | 2319     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.6     |\n",
      "|    ep_rew_mean      | 11.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 2567     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.303    |\n",
      "|    n_updates        | 2366     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.3     |\n",
      "|    ep_rew_mean      | 11.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 2605     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.256    |\n",
      "|    n_updates        | 2404     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.7     |\n",
      "|    ep_rew_mean      | 11.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 2668     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.282    |\n",
      "|    n_updates        | 2467     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.7     |\n",
      "|    ep_rew_mean      | 11.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 2739     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.247    |\n",
      "|    n_updates        | 2538     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.9     |\n",
      "|    ep_rew_mean      | 11.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 2817     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.267    |\n",
      "|    n_updates        | 2616     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.1     |\n",
      "|    ep_rew_mean      | 11.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 2870     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.185    |\n",
      "|    n_updates        | 2669     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15       |\n",
      "|    ep_rew_mean      | 11.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 2937     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.183    |\n",
      "|    n_updates        | 2736     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.1     |\n",
      "|    ep_rew_mean      | 12       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 3031     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.2      |\n",
      "|    n_updates        | 2830     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.3     |\n",
      "|    ep_rew_mean      | 12.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 3120     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.134    |\n",
      "|    n_updates        | 2919     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.3     |\n",
      "|    ep_rew_mean      | 12.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 3181     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.102    |\n",
      "|    n_updates        | 2980     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.4     |\n",
      "|    ep_rew_mean      | 12.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 3220     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.341    |\n",
      "|    n_updates        | 3019     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.6     |\n",
      "|    ep_rew_mean      | 12.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 3276     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0814   |\n",
      "|    n_updates        | 3075     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.1     |\n",
      "|    ep_rew_mean      | 12.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 3331     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.19     |\n",
      "|    n_updates        | 3130     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.2     |\n",
      "|    ep_rew_mean      | 12.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 3405     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.157    |\n",
      "|    n_updates        | 3204     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.3     |\n",
      "|    ep_rew_mean      | 12.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 3459     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.194    |\n",
      "|    n_updates        | 3258     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.3     |\n",
      "|    ep_rew_mean      | 12.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 3510     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0205   |\n",
      "|    n_updates        | 3309     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.6     |\n",
      "|    ep_rew_mean      | 12.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 3601     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.294    |\n",
      "|    n_updates        | 3400     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.4     |\n",
      "|    ep_rew_mean      | 12.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 3650     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0275   |\n",
      "|    n_updates        | 3449     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.8     |\n",
      "|    ep_rew_mean      | 12.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 3747     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.158    |\n",
      "|    n_updates        | 3546     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.6     |\n",
      "|    ep_rew_mean      | 12.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 3817     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0201   |\n",
      "|    n_updates        | 3616     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.3     |\n",
      "|    ep_rew_mean      | 12.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 3850     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.19     |\n",
      "|    n_updates        | 3649     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.5     |\n",
      "|    ep_rew_mean      | 12.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 3908     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.169    |\n",
      "|    n_updates        | 3707     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.5     |\n",
      "|    ep_rew_mean      | 12.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 3974     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0215   |\n",
      "|    n_updates        | 3773     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16       |\n",
      "|    ep_rew_mean      | 12.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 4083     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0977   |\n",
      "|    n_updates        | 3882     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.5     |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 4173     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.186    |\n",
      "|    n_updates        | 3972     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.6     |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 4222     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.235    |\n",
      "|    n_updates        | 4021     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.8     |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 4289     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0539   |\n",
      "|    n_updates        | 4088     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.7     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 4342     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.101    |\n",
      "|    n_updates        | 4141     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.9     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 4434     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.363    |\n",
      "|    n_updates        | 4233     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.2     |\n",
      "|    ep_rew_mean      | 13.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 4536     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.264    |\n",
      "|    n_updates        | 4335     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.8     |\n",
      "|    ep_rew_mean      | 14.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 4646     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.336    |\n",
      "|    n_updates        | 4445     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.8     |\n",
      "|    ep_rew_mean      | 14.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 4718     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.227    |\n",
      "|    n_updates        | 4517     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.4     |\n",
      "|    ep_rew_mean      | 13.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 4776     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.176    |\n",
      "|    n_updates        | 4575     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.4     |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 4856     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0659   |\n",
      "|    n_updates        | 4655     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.7     |\n",
      "|    ep_rew_mean      | 14.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 4949     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.161    |\n",
      "|    n_updates        | 4748     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.9     |\n",
      "|    ep_rew_mean      | 14.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total_timesteps  | 5012     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0792   |\n",
      "|    n_updates        | 4811     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.1     |\n",
      "|    ep_rew_mean      | 14.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 5090     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 4889     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.1     |\n",
      "|    ep_rew_mean      | 14.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 5136     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.413    |\n",
      "|    n_updates        | 4935     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.1     |\n",
      "|    ep_rew_mean      | 14.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 5211     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.114    |\n",
      "|    n_updates        | 5010     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.2     |\n",
      "|    ep_rew_mean      | 14.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 5282     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.247    |\n",
      "|    n_updates        | 5081     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.7     |\n",
      "|    ep_rew_mean      | 14.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 5379     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.094    |\n",
      "|    n_updates        | 5178     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.6     |\n",
      "|    ep_rew_mean      | 14.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 5456     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.546    |\n",
      "|    n_updates        | 5255     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.9     |\n",
      "|    ep_rew_mean      | 14.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 5536     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.241    |\n",
      "|    n_updates        | 5335     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.7     |\n",
      "|    ep_rew_mean      | 14.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 5616     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.082    |\n",
      "|    n_updates        | 5415     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.6     |\n",
      "|    ep_rew_mean      | 14.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 5679     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0916   |\n",
      "|    n_updates        | 5478     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.2     |\n",
      "|    ep_rew_mean      | 15.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 5769     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 5568     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.2     |\n",
      "|    ep_rew_mean      | 15.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 5827     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0295   |\n",
      "|    n_updates        | 5626     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.2     |\n",
      "|    ep_rew_mean      | 15.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 5893     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0937   |\n",
      "|    n_updates        | 5692     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.1     |\n",
      "|    ep_rew_mean      | 15.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 5992     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0497   |\n",
      "|    n_updates        | 5791     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.9     |\n",
      "|    ep_rew_mean      | 15.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 6059     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.102    |\n",
      "|    n_updates        | 5858     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.1     |\n",
      "|    ep_rew_mean      | 15.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 6127     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 5926     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.3     |\n",
      "|    ep_rew_mean      | 15.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 6221     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.241    |\n",
      "|    n_updates        | 6020     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.5     |\n",
      "|    ep_rew_mean      | 15.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 6291     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.222    |\n",
      "|    n_updates        | 6090     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.1     |\n",
      "|    ep_rew_mean      | 15.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 104      |\n",
      "|    total_timesteps  | 6346     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.236    |\n",
      "|    n_updates        | 6145     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.9     |\n",
      "|    ep_rew_mean      | 15.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 6428     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0908   |\n",
      "|    n_updates        | 6227     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.5     |\n",
      "|    ep_rew_mean      | 15       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 6497     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0953   |\n",
      "|    n_updates        | 6296     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.6     |\n",
      "|    ep_rew_mean      | 15.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total_timesteps  | 6576     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.146    |\n",
      "|    n_updates        | 6375     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.6     |\n",
      "|    ep_rew_mean      | 15.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 6641     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.243    |\n",
      "|    n_updates        | 6440     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.7     |\n",
      "|    ep_rew_mean      | 15.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 6725     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.263    |\n",
      "|    n_updates        | 6524     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.7     |\n",
      "|    ep_rew_mean      | 15.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 6817     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.263    |\n",
      "|    n_updates        | 6616     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.9     |\n",
      "|    ep_rew_mean      | 15.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total_timesteps  | 6897     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0809   |\n",
      "|    n_updates        | 6696     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.8     |\n",
      "|    ep_rew_mean      | 15.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total_timesteps  | 6967     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.148    |\n",
      "|    n_updates        | 6766     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.1     |\n",
      "|    ep_rew_mean      | 15.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 116      |\n",
      "|    total_timesteps  | 7045     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.155    |\n",
      "|    n_updates        | 6844     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.1     |\n",
      "|    ep_rew_mean      | 15.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 117      |\n",
      "|    total_timesteps  | 7121     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00797  |\n",
      "|    n_updates        | 6920     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.8     |\n",
      "|    ep_rew_mean      | 15.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 118      |\n",
      "|    total_timesteps  | 7161     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0837   |\n",
      "|    n_updates        | 6960     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.3     |\n",
      "|    ep_rew_mean      | 14.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 119      |\n",
      "|    total_timesteps  | 7212     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.119    |\n",
      "|    n_updates        | 7011     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.2     |\n",
      "|    ep_rew_mean      | 14.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 120      |\n",
      "|    total_timesteps  | 7280     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.19     |\n",
      "|    n_updates        | 7079     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18       |\n",
      "|    ep_rew_mean      | 14.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 121      |\n",
      "|    total_timesteps  | 7335     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.079    |\n",
      "|    n_updates        | 7134     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.9     |\n",
      "|    ep_rew_mean      | 14.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 122      |\n",
      "|    total_timesteps  | 7406     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.24     |\n",
      "|    n_updates        | 7205     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.1     |\n",
      "|    ep_rew_mean      | 14.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 123      |\n",
      "|    total_timesteps  | 7490     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0864   |\n",
      "|    n_updates        | 7289     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.5     |\n",
      "|    ep_rew_mean      | 14.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 124      |\n",
      "|    total_timesteps  | 7523     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0353   |\n",
      "|    n_updates        | 7322     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.5     |\n",
      "|    ep_rew_mean      | 14.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 125      |\n",
      "|    total_timesteps  | 7580     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0251   |\n",
      "|    n_updates        | 7379     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.8     |\n",
      "|    ep_rew_mean      | 14.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 126      |\n",
      "|    total_timesteps  | 7669     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.103    |\n",
      "|    n_updates        | 7468     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | 14.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 127      |\n",
      "|    total_timesteps  | 7747     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.147    |\n",
      "|    n_updates        | 7546     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.7     |\n",
      "|    ep_rew_mean      | 14.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 504      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 129      |\n",
      "|    total_timesteps  | 7825     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.238    |\n",
      "|    n_updates        | 7624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.7     |\n",
      "|    ep_rew_mean      | 14.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 508      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 130      |\n",
      "|    total_timesteps  | 7893     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0182   |\n",
      "|    n_updates        | 7692     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.4     |\n",
      "|    ep_rew_mean      | 14.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 512      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 131      |\n",
      "|    total_timesteps  | 7962     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.12     |\n",
      "|    n_updates        | 7761     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | 14.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 516      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 133      |\n",
      "|    total_timesteps  | 8049     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.103    |\n",
      "|    n_updates        | 7848     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.8     |\n",
      "|    ep_rew_mean      | 14.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 520      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total_timesteps  | 8129     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0769   |\n",
      "|    n_updates        | 7928     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18       |\n",
      "|    ep_rew_mean      | 14.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 524      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 135      |\n",
      "|    total_timesteps  | 8231     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.11     |\n",
      "|    n_updates        | 8030     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.9     |\n",
      "|    ep_rew_mean      | 14.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 528      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 136      |\n",
      "|    total_timesteps  | 8288     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.263    |\n",
      "|    n_updates        | 8087     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18       |\n",
      "|    ep_rew_mean      | 14.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 532      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 138      |\n",
      "|    total_timesteps  | 8372     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0979   |\n",
      "|    n_updates        | 8171     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.2     |\n",
      "|    ep_rew_mean      | 14.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 536      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 139      |\n",
      "|    total_timesteps  | 8458     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.188    |\n",
      "|    n_updates        | 8257     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.1     |\n",
      "|    ep_rew_mean      | 14.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 540      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 140      |\n",
      "|    total_timesteps  | 8534     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.101    |\n",
      "|    n_updates        | 8333     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.9     |\n",
      "|    ep_rew_mean      | 14.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 544      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 142      |\n",
      "|    total_timesteps  | 8607     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.261    |\n",
      "|    n_updates        | 8406     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.9     |\n",
      "|    ep_rew_mean      | 14.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 548      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 143      |\n",
      "|    total_timesteps  | 8684     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.244    |\n",
      "|    n_updates        | 8483     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.7     |\n",
      "|    ep_rew_mean      | 14.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 552      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total_timesteps  | 8740     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.135    |\n",
      "|    n_updates        | 8539     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | 14.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 556      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 145      |\n",
      "|    total_timesteps  | 8803     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.119    |\n",
      "|    n_updates        | 8602     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.5     |\n",
      "|    ep_rew_mean      | 14       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 560      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 146      |\n",
      "|    total_timesteps  | 8872     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.229    |\n",
      "|    n_updates        | 8671     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.2     |\n",
      "|    ep_rew_mean      | 14.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 564      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 148      |\n",
      "|    total_timesteps  | 8983     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0321   |\n",
      "|    n_updates        | 8782     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.8     |\n",
      "|    ep_rew_mean      | 15.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 568      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 150      |\n",
      "|    total_timesteps  | 9092     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.235    |\n",
      "|    n_updates        | 8891     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.8     |\n",
      "|    ep_rew_mean      | 15.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 572      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 151      |\n",
      "|    total_timesteps  | 9162     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.129    |\n",
      "|    n_updates        | 8961     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19       |\n",
      "|    ep_rew_mean      | 15.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 576      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 152      |\n",
      "|    total_timesteps  | 9234     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0598   |\n",
      "|    n_updates        | 9033     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.1     |\n",
      "|    ep_rew_mean      | 15.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 580      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 153      |\n",
      "|    total_timesteps  | 9314     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0968   |\n",
      "|    n_updates        | 9113     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.2     |\n",
      "|    ep_rew_mean      | 15.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 584      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 155      |\n",
      "|    total_timesteps  | 9413     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.203    |\n",
      "|    n_updates        | 9212     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.5     |\n",
      "|    ep_rew_mean      | 15.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 588      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 156      |\n",
      "|    total_timesteps  | 9471     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.283    |\n",
      "|    n_updates        | 9270     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.1     |\n",
      "|    ep_rew_mean      | 16.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 592      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 158      |\n",
      "|    total_timesteps  | 9591     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0631   |\n",
      "|    n_updates        | 9390     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.1     |\n",
      "|    ep_rew_mean      | 16.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 596      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 159      |\n",
      "|    total_timesteps  | 9682     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0962   |\n",
      "|    n_updates        | 9481     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.3     |\n",
      "|    ep_rew_mean      | 16.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 161      |\n",
      "|    total_timesteps  | 9778     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.176    |\n",
      "|    n_updates        | 9577     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.6     |\n",
      "|    ep_rew_mean      | 16.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 604      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 163      |\n",
      "|    total_timesteps  | 9883     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.225    |\n",
      "|    n_updates        | 9682     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.5     |\n",
      "|    ep_rew_mean      | 16.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 608      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 164      |\n",
      "|    total_timesteps  | 9947     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.242    |\n",
      "|    n_updates        | 9746     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.6     |\n",
      "|    ep_rew_mean      | 16.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 612      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 165      |\n",
      "|    total_timesteps  | 10021    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0946   |\n",
      "|    n_updates        | 9820     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.7     |\n",
      "|    ep_rew_mean      | 16.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 616      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 167      |\n",
      "|    total_timesteps  | 10115    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.155    |\n",
      "|    n_updates        | 9914     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.6     |\n",
      "|    ep_rew_mean      | 16.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 620      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 168      |\n",
      "|    total_timesteps  | 10191    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.103    |\n",
      "|    n_updates        | 9990     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.6     |\n",
      "|    ep_rew_mean      | 16.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 624      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 170      |\n",
      "|    total_timesteps  | 10291    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.113    |\n",
      "|    n_updates        | 10090    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21       |\n",
      "|    ep_rew_mean      | 16.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 628      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 171      |\n",
      "|    total_timesteps  | 10385    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.104    |\n",
      "|    n_updates        | 10184    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21       |\n",
      "|    ep_rew_mean      | 16.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 632      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 173      |\n",
      "|    total_timesteps  | 10476    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0929   |\n",
      "|    n_updates        | 10275    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21       |\n",
      "|    ep_rew_mean      | 16.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 636      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 174      |\n",
      "|    total_timesteps  | 10554    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0441   |\n",
      "|    n_updates        | 10353    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 16.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 640      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 176      |\n",
      "|    total_timesteps  | 10654    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.237    |\n",
      "|    n_updates        | 10453    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 16.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 644      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 177      |\n",
      "|    total_timesteps  | 10732    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0325   |\n",
      "|    n_updates        | 10531    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.3     |\n",
      "|    ep_rew_mean      | 16.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 648      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 178      |\n",
      "|    total_timesteps  | 10811    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 10610    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.7     |\n",
      "|    ep_rew_mean      | 17.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 652      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 180      |\n",
      "|    total_timesteps  | 10911    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0778   |\n",
      "|    n_updates        | 10710    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.3     |\n",
      "|    ep_rew_mean      | 17.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 656      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 182      |\n",
      "|    total_timesteps  | 11031    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.1      |\n",
      "|    n_updates        | 10830    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.6     |\n",
      "|    ep_rew_mean      | 17.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 660      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 184      |\n",
      "|    total_timesteps  | 11129    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0251   |\n",
      "|    n_updates        | 10928    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 17.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 664      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 185      |\n",
      "|    total_timesteps  | 11206    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.193    |\n",
      "|    n_updates        | 11005    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.5     |\n",
      "|    ep_rew_mean      | 16.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 668      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 186      |\n",
      "|    total_timesteps  | 11246    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.1      |\n",
      "|    n_updates        | 11045    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 17.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 672      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 188      |\n",
      "|    total_timesteps  | 11366    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.242    |\n",
      "|    n_updates        | 11165    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.3     |\n",
      "|    ep_rew_mean      | 17.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 676      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 189      |\n",
      "|    total_timesteps  | 11463    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.1      |\n",
      "|    n_updates        | 11262    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.5     |\n",
      "|    ep_rew_mean      | 17.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 680      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 191      |\n",
      "|    total_timesteps  | 11561    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0679   |\n",
      "|    n_updates        | 11360    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.7     |\n",
      "|    ep_rew_mean      | 17.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 684      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 193      |\n",
      "|    total_timesteps  | 11680    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.11     |\n",
      "|    n_updates        | 11479    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.3     |\n",
      "|    ep_rew_mean      | 18       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 688      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 195      |\n",
      "|    total_timesteps  | 11800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.178    |\n",
      "|    n_updates        | 11599    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.3     |\n",
      "|    ep_rew_mean      | 18       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 692      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 197      |\n",
      "|    total_timesteps  | 11919    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0798   |\n",
      "|    n_updates        | 11718    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 18.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 696      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 199      |\n",
      "|    total_timesteps  | 12025    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0329   |\n",
      "|    n_updates        | 11824    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.6     |\n",
      "|    ep_rew_mean      | 18.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 700      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 201      |\n",
      "|    total_timesteps  | 12135    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 11934    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.5     |\n",
      "|    ep_rew_mean      | 18.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 704      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 202      |\n",
      "|    total_timesteps  | 12234    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.301    |\n",
      "|    n_updates        | 12033    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.9     |\n",
      "|    ep_rew_mean      | 18.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 708      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 204      |\n",
      "|    total_timesteps  | 12337    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0181   |\n",
      "|    n_updates        | 12136    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.2     |\n",
      "|    ep_rew_mean      | 18.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 712      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 206      |\n",
      "|    total_timesteps  | 12440    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.262    |\n",
      "|    n_updates        | 12239    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.4     |\n",
      "|    ep_rew_mean      | 18.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 716      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 207      |\n",
      "|    total_timesteps  | 12552    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 12351    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.6     |\n",
      "|    ep_rew_mean      | 19.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 720      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 209      |\n",
      "|    total_timesteps  | 12655    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.104    |\n",
      "|    n_updates        | 12454    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.4     |\n",
      "|    ep_rew_mean      | 19       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 724      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 210      |\n",
      "|    total_timesteps  | 12732    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0929   |\n",
      "|    n_updates        | 12531    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.7     |\n",
      "|    ep_rew_mean      | 19.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 728      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 212      |\n",
      "|    total_timesteps  | 12852    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.152    |\n",
      "|    n_updates        | 12651    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.7     |\n",
      "|    ep_rew_mean      | 19.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 732      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 214      |\n",
      "|    total_timesteps  | 12948    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.304    |\n",
      "|    n_updates        | 12747    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.1     |\n",
      "|    ep_rew_mean      | 19.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 736      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 215      |\n",
      "|    total_timesteps  | 13061    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0928   |\n",
      "|    n_updates        | 12860    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25       |\n",
      "|    ep_rew_mean      | 19.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 740      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 217      |\n",
      "|    total_timesteps  | 13158    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.114    |\n",
      "|    n_updates        | 12957    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.4     |\n",
      "|    ep_rew_mean      | 19.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 744      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 219      |\n",
      "|    total_timesteps  | 13270    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 13069    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.8     |\n",
      "|    ep_rew_mean      | 20       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 748      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 221      |\n",
      "|    total_timesteps  | 13390    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 13189    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.5     |\n",
      "|    ep_rew_mean      | 19.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 752      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 222      |\n",
      "|    total_timesteps  | 13465    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.132    |\n",
      "|    n_updates        | 13264    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.4     |\n",
      "|    ep_rew_mean      | 19.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 756      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 224      |\n",
      "|    total_timesteps  | 13571    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0558   |\n",
      "|    n_updates        | 13370    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.3     |\n",
      "|    ep_rew_mean      | 19.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 760      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 225      |\n",
      "|    total_timesteps  | 13658    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0845   |\n",
      "|    n_updates        | 13457    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.4     |\n",
      "|    ep_rew_mean      | 19.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 764      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 227      |\n",
      "|    total_timesteps  | 13744    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.159    |\n",
      "|    n_updates        | 13543    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.9     |\n",
      "|    ep_rew_mean      | 20.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 768      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 228      |\n",
      "|    total_timesteps  | 13841    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.086    |\n",
      "|    n_updates        | 13640    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.7     |\n",
      "|    ep_rew_mean      | 20       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 772      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 230      |\n",
      "|    total_timesteps  | 13940    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.132    |\n",
      "|    n_updates        | 13739    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 26       |\n",
      "|    ep_rew_mean      | 20.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 776      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 232      |\n",
      "|    total_timesteps  | 14060    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0641   |\n",
      "|    n_updates        | 13859    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 26       |\n",
      "|    ep_rew_mean      | 20.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 780      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 234      |\n",
      "|    total_timesteps  | 14164    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.116    |\n",
      "|    n_updates        | 13963    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.8     |\n",
      "|    ep_rew_mean      | 20.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 784      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 235      |\n",
      "|    total_timesteps  | 14259    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.123    |\n",
      "|    n_updates        | 14058    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.3     |\n",
      "|    ep_rew_mean      | 19.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 788      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 237      |\n",
      "|    total_timesteps  | 14333    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.245    |\n",
      "|    n_updates        | 14132    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.9     |\n",
      "|    ep_rew_mean      | 19.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 792      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 238      |\n",
      "|    total_timesteps  | 14406    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0349   |\n",
      "|    n_updates        | 14205    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.9     |\n",
      "|    ep_rew_mean      | 19.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 796      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 240      |\n",
      "|    total_timesteps  | 14518    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0314   |\n",
      "|    n_updates        | 14317    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.6     |\n",
      "|    ep_rew_mean      | 19.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 800      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 241      |\n",
      "|    total_timesteps  | 14600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0192   |\n",
      "|    n_updates        | 14399    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.5     |\n",
      "|    ep_rew_mean      | 19.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 804      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 242      |\n",
      "|    total_timesteps  | 14683    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0958   |\n",
      "|    n_updates        | 14482    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.1     |\n",
      "|    ep_rew_mean      | 18.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 808      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 244      |\n",
      "|    total_timesteps  | 14751    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0848   |\n",
      "|    n_updates        | 14550    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.9     |\n",
      "|    ep_rew_mean      | 18.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 812      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 245      |\n",
      "|    total_timesteps  | 14833    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0891   |\n",
      "|    n_updates        | 14632    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.6     |\n",
      "|    ep_rew_mean      | 18.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 816      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 246      |\n",
      "|    total_timesteps  | 14910    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0825   |\n",
      "|    n_updates        | 14709    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.5     |\n",
      "|    ep_rew_mean      | 18.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 820      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 248      |\n",
      "|    total_timesteps  | 15002    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 14801    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.9     |\n",
      "|    ep_rew_mean      | 18.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 824      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 250      |\n",
      "|    total_timesteps  | 15122    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.188    |\n",
      "|    n_updates        | 14921    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.8     |\n",
      "|    ep_rew_mean      | 18.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 828      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 252      |\n",
      "|    total_timesteps  | 15227    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.102    |\n",
      "|    n_updates        | 15026    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.8     |\n",
      "|    ep_rew_mean      | 18.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 832      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 253      |\n",
      "|    total_timesteps  | 15323    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.155    |\n",
      "|    n_updates        | 15122    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.5     |\n",
      "|    ep_rew_mean      | 18.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 836      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 255      |\n",
      "|    total_timesteps  | 15408    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0202   |\n",
      "|    n_updates        | 15207    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.7     |\n",
      "|    ep_rew_mean      | 18.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 840      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 257      |\n",
      "|    total_timesteps  | 15528    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.023    |\n",
      "|    n_updates        | 15327    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 18.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 844      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 258      |\n",
      "|    total_timesteps  | 15608    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0521   |\n",
      "|    n_updates        | 15407    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.2     |\n",
      "|    ep_rew_mean      | 18.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 848      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 260      |\n",
      "|    total_timesteps  | 15715    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0582   |\n",
      "|    n_updates        | 15514    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.5     |\n",
      "|    ep_rew_mean      | 18.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 852      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 261      |\n",
      "|    total_timesteps  | 15811    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.119    |\n",
      "|    n_updates        | 15610    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.5     |\n",
      "|    ep_rew_mean      | 18.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 856      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 263      |\n",
      "|    total_timesteps  | 15922    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.111    |\n",
      "|    n_updates        | 15721    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.6     |\n",
      "|    ep_rew_mean      | 18.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 860      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 265      |\n",
      "|    total_timesteps  | 16020    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0538   |\n",
      "|    n_updates        | 15819    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.7     |\n",
      "|    ep_rew_mean      | 18.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 864      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 266      |\n",
      "|    total_timesteps  | 16118    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 15917    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24       |\n",
      "|    ep_rew_mean      | 18.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 868      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 268      |\n",
      "|    total_timesteps  | 16238    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 16037    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.8     |\n",
      "|    ep_rew_mean      | 18.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 872      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 270      |\n",
      "|    total_timesteps  | 16324    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.156    |\n",
      "|    n_updates        | 16123    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.8     |\n",
      "|    ep_rew_mean      | 18.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 876      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 272      |\n",
      "|    total_timesteps  | 16436    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 16235    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.6     |\n",
      "|    ep_rew_mean      | 18.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 880      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 273      |\n",
      "|    total_timesteps  | 16519    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 16318    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.6     |\n",
      "|    ep_rew_mean      | 18.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 884      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 275      |\n",
      "|    total_timesteps  | 16620    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0775   |\n",
      "|    n_updates        | 16419    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24       |\n",
      "|    ep_rew_mean      | 18.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 888      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 277      |\n",
      "|    total_timesteps  | 16730    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0539   |\n",
      "|    n_updates        | 16529    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.2     |\n",
      "|    ep_rew_mean      | 19       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 892      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 278      |\n",
      "|    total_timesteps  | 16822    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 16621    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.2     |\n",
      "|    ep_rew_mean      | 19.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 896      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 280      |\n",
      "|    total_timesteps  | 16942    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.019    |\n",
      "|    n_updates        | 16741    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.5     |\n",
      "|    ep_rew_mean      | 19.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 900      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 282      |\n",
      "|    total_timesteps  | 17053    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0718   |\n",
      "|    n_updates        | 16852    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.7     |\n",
      "|    ep_rew_mean      | 19.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 904      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 284      |\n",
      "|    total_timesteps  | 17151    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0267   |\n",
      "|    n_updates        | 16950    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.1     |\n",
      "|    ep_rew_mean      | 19.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 908      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 286      |\n",
      "|    total_timesteps  | 17260    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 17059    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.3     |\n",
      "|    ep_rew_mean      | 19.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 912      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 287      |\n",
      "|    total_timesteps  | 17361    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 17160    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.3     |\n",
      "|    ep_rew_mean      | 20       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 916      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 289      |\n",
      "|    total_timesteps  | 17444    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0179   |\n",
      "|    n_updates        | 17243    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.2     |\n",
      "|    ep_rew_mean      | 19.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 920      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 290      |\n",
      "|    total_timesteps  | 17527    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0463   |\n",
      "|    n_updates        | 17326    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.8     |\n",
      "|    ep_rew_mean      | 19.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 924      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 291      |\n",
      "|    total_timesteps  | 17598    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.11     |\n",
      "|    n_updates        | 17397    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.9     |\n",
      "|    ep_rew_mean      | 19.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 928      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 293      |\n",
      "|    total_timesteps  | 17718    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0526   |\n",
      "|    n_updates        | 17517    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.1     |\n",
      "|    ep_rew_mean      | 19.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 932      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 295      |\n",
      "|    total_timesteps  | 17838    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.173    |\n",
      "|    n_updates        | 17637    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.2     |\n",
      "|    ep_rew_mean      | 20       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 936      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 297      |\n",
      "|    total_timesteps  | 17929    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.15     |\n",
      "|    n_updates        | 17728    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.2     |\n",
      "|    ep_rew_mean      | 20       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 940      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 299      |\n",
      "|    total_timesteps  | 18049    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.147    |\n",
      "|    n_updates        | 17848    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.4     |\n",
      "|    ep_rew_mean      | 20.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 944      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 301      |\n",
      "|    total_timesteps  | 18152    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.102    |\n",
      "|    n_updates        | 17951    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.4     |\n",
      "|    ep_rew_mean      | 20.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 948      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 302      |\n",
      "|    total_timesteps  | 18250    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0184   |\n",
      "|    n_updates        | 18049    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.6     |\n",
      "|    ep_rew_mean      | 20.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 952      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 304      |\n",
      "|    total_timesteps  | 18370    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0496   |\n",
      "|    n_updates        | 18169    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.6     |\n",
      "|    ep_rew_mean      | 20.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 956      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 306      |\n",
      "|    total_timesteps  | 18483    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0348   |\n",
      "|    n_updates        | 18282    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.7     |\n",
      "|    ep_rew_mean      | 20.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 960      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 308      |\n",
      "|    total_timesteps  | 18594    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 18393    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 26       |\n",
      "|    ep_rew_mean      | 20.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 964      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 310      |\n",
      "|    total_timesteps  | 18714    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.145    |\n",
      "|    n_updates        | 18513    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.9     |\n",
      "|    ep_rew_mean      | 20.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 968      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 312      |\n",
      "|    total_timesteps  | 18828    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0999   |\n",
      "|    n_updates        | 18627    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.6     |\n",
      "|    ep_rew_mean      | 20.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 972      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 313      |\n",
      "|    total_timesteps  | 18880    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0352   |\n",
      "|    n_updates        | 18679    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.4     |\n",
      "|    ep_rew_mean      | 20.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 976      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 314      |\n",
      "|    total_timesteps  | 18972    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0277   |\n",
      "|    n_updates        | 18771    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.6     |\n",
      "|    ep_rew_mean      | 20.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 980      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 316      |\n",
      "|    total_timesteps  | 19081    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.15     |\n",
      "|    n_updates        | 18880    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.7     |\n",
      "|    ep_rew_mean      | 20.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 984      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 318      |\n",
      "|    total_timesteps  | 19189    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00514  |\n",
      "|    n_updates        | 18988    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.5     |\n",
      "|    ep_rew_mean      | 20.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 988      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 319      |\n",
      "|    total_timesteps  | 19284    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0892   |\n",
      "|    n_updates        | 19083    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.7     |\n",
      "|    ep_rew_mean      | 20.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 992      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 321      |\n",
      "|    total_timesteps  | 19393    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0166   |\n",
      "|    n_updates        | 19192    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.5     |\n",
      "|    ep_rew_mean      | 20.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 996      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 323      |\n",
      "|    total_timesteps  | 19489    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0252   |\n",
      "|    n_updates        | 19288    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.3     |\n",
      "|    ep_rew_mean      | 20.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1000     |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 324      |\n",
      "|    total_timesteps  | 19584    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.115    |\n",
      "|    n_updates        | 19383    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.5     |\n",
      "|    ep_rew_mean      | 20.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1004     |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 326      |\n",
      "|    total_timesteps  | 19704    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 19503    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.6     |\n",
      "|    ep_rew_mean      | 20.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1008     |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 328      |\n",
      "|    total_timesteps  | 19824    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0231   |\n",
      "|    n_updates        | 19623    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.8     |\n",
      "|    ep_rew_mean      | 20.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1012     |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 330      |\n",
      "|    total_timesteps  | 19944    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.127    |\n",
      "|    n_updates        | 19743    |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import DQN\n",
    "\n",
    "model = DQN('MlpPolicy', env,\n",
    "              policy_kwargs=dict(net_arch=[256, 256]),\n",
    "              learning_rate=5e-4,\n",
    "              buffer_size=15000,\n",
    "              learning_starts=200,\n",
    "              batch_size=32,\n",
    "              gamma=0.8,\n",
    "              train_freq=1,\n",
    "              gradient_steps=1,\n",
    "              target_update_interval=50,\n",
    "              verbose=1,\n",
    "              tensorboard_log=\"logs/highway_dqn_baseline\")\n",
    "model.learn(int(2e4))\n",
    "model.save(\"models/highway_dqn_baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 13726), started 13:37:59 ago. (Use '!kill 13726' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4a8ee53495ec920d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4a8ee53495ec920d\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir ./logs/highway_dqn_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TensorBoard graphs display the performance of two separate training runs of a baseline model using a Deep Q-Network (DQN) algorithm. The runs are labeled as DQN_1 and DQN_2, and the plots show three different metrics: episode length mean, episode reward mean, and frames per second (fps), which can be indicative of training efficiency.\n",
    "\n",
    "From the first graph, the mean episode length for both runs increases over time, suggesting that the agent is learning to sustain longer episodes through its interactions with the environment. Both runs appear to converge towards similar performance, with DQN_1 showing a slightly higher mean episode length. The second graph shows the mean episode reward increasing over time, indicating that the agent is learning to maximize rewards. Similar to episode length, both runs show converging trends, with DQN_1 marginally outperforming DQN_2 by the end of the training.\n",
    "\n",
    "The third graph displays the fps, which remain relatively consistent throughout training for both runs, with minor initial fluctuations. The fps measure how quickly the model is processing frames, and it seems to stabilize quickly, implying a steady computational performance.\n",
    "\n",
    "Considering the final report, since the difference in performance between DQN_1 and DQN_2 is not statistically significant, and the two runs are part of a baseline before fine-tuning, it may be appropriate to report aggregated results or choose the one with the slightly better performance, which in this case would be DQN_1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Model Prediction - Creating frames from each episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = 23.500006081055453, Steps = 30\n",
      "Episode 2: Total Reward = 23.486887835703005, Steps = 30\n",
      "Episode 3: Total Reward = 23.65231596620102, Steps = 30\n",
      "Episode 4: Total Reward = 22.653207248099772, Steps = 30\n",
      "Episode 5: Total Reward = 16.902661979455726, Steps = 22\n",
      "Episode 6: Total Reward = 24.785649286899023, Steps = 30\n",
      "Episode 7: Total Reward = 23.219610652632348, Steps = 30\n",
      "Episode 8: Total Reward = 25.901320683983528, Steps = 30\n",
      "Episode 9: Total Reward = 9.486887716361112, Steps = 13\n",
      "Episode 10: Total Reward = 24.118932739240602, Steps = 30\n",
      "Episode 11: Total Reward = 6.098602219269405, Steps = 8\n",
      "Episode 12: Total Reward = 22.88688141957536, Steps = 30\n",
      "Episode 13: Total Reward = 25.62022116903626, Steps = 30\n",
      "Episode 14: Total Reward = 23.882577672449397, Steps = 30\n",
      "Episode 15: Total Reward = 23.98564109022169, Steps = 30\n",
      "Episode 16: Total Reward = 22.61843625110848, Steps = 30\n",
      "Episode 17: Total Reward = 23.483767843659518, Steps = 30\n",
      "Episode 18: Total Reward = 25.35293221979073, Steps = 30\n",
      "Episode 19: Total Reward = 25.11634807188066, Steps = 30\n",
      "Episode 20: Total Reward = 22.820221169036344, Steps = 30\n",
      "Episode 21: Total Reward = 7.017239717314708, Steps = 9\n",
      "Episode 22: Total Reward = 27.086887716632614, Steps = 30\n",
      "Episode 23: Total Reward = 25.109804534529097, Steps = 30\n",
      "Episode 24: Total Reward = 22.653554486654265, Steps = 30\n",
      "Episode 25: Total Reward = 23.486583347934932, Steps = 30\n",
      "Episode 26: Total Reward = 25.08519186372777, Steps = 30\n",
      "Episode 27: Total Reward = 22.953554502369677, Steps = 30\n",
      "Episode 28: Total Reward = 7.119752048328283, Steps = 9\n",
      "Episode 29: Total Reward = 23.883953349135275, Steps = 30\n",
      "Episode 30: Total Reward = 24.119587135839364, Steps = 30\n",
      "Episode 31: Total Reward = 23.452266072573934, Steps = 30\n",
      "Episode 32: Total Reward = 15.415306874832845, Steps = 19\n",
      "Episode 33: Total Reward = 26.550231634152144, Steps = 30\n",
      "Episode 34: Total Reward = 22.251657407164593, Steps = 30\n",
      "Episode 35: Total Reward = 24.875726120898186, Steps = 30\n",
      "Episode 36: Total Reward = 23.58569500870977, Steps = 30\n",
      "Episode 37: Total Reward = 24.78549676864251, Steps = 30\n",
      "Episode 38: Total Reward = 23.11895563867714, Steps = 30\n",
      "Episode 39: Total Reward = 23.735995300990336, Steps = 30\n",
      "Episode 40: Total Reward = 22.553554502369582, Steps = 30\n",
      "Episode 41: Total Reward = 9.179156548625556, Steps = 11\n",
      "Episode 42: Total Reward = 23.88626555312406, Steps = 30\n",
      "Episode 43: Total Reward = 24.95355371545498, Steps = 30\n",
      "Episode 44: Total Reward = 25.07763241506044, Steps = 30\n",
      "Episode 45: Total Reward = 22.186264344247963, Steps = 30\n",
      "Episode 46: Total Reward = 22.619595826255495, Steps = 30\n",
      "Episode 47: Total Reward = 6.752925351791462, Steps = 9\n",
      "Episode 48: Total Reward = 23.78558476291715, Steps = 30\n",
      "Episode 49: Total Reward = 20.286887835703006, Steps = 30\n",
      "Episode 50: Total Reward = 22.819598886457406, Steps = 30\n",
      "Episode 51: Total Reward = 25.753554502369667, Steps = 30\n",
      "Episode 52: Total Reward = 24.51893273923649, Steps = 30\n",
      "Episode 53: Total Reward = 25.385266315260363, Steps = 30\n",
      "Episode 54: Total Reward = 15.886880953816611, Steps = 19\n",
      "Episode 55: Total Reward = 25.719867534277135, Steps = 30\n",
      "Episode 56: Total Reward = 13.418931377889313, Steps = 19\n",
      "Episode 57: Total Reward = 22.91893273917831, Steps = 30\n",
      "Episode 58: Total Reward = 23.1517681925449, Steps = 30\n",
      "Episode 59: Total Reward = 22.751740481234364, Steps = 30\n",
      "Episode 60: Total Reward = 21.85235246472588, Steps = 30\n",
      "Episode 61: Total Reward = 25.719262661639174, Steps = 30\n",
      "Episode 62: Total Reward = 21.719758751592902, Steps = 30\n",
      "Episode 63: Total Reward = 21.58688586041627, Steps = 30\n",
      "Episode 64: Total Reward = 21.986425418260563, Steps = 30\n",
      "Episode 65: Total Reward = 22.586422968535054, Steps = 30\n",
      "Episode 66: Total Reward = 24.21831647561026, Steps = 30\n",
      "Episode 67: Total Reward = 25.55180628966438, Steps = 30\n",
      "Episode 68: Total Reward = 14.766101335270315, Steps = 17\n",
      "Episode 69: Total Reward = 23.453552413140407, Steps = 30\n",
      "Episode 70: Total Reward = 24.019598886457405, Steps = 30\n",
      "Episode 71: Total Reward = 25.11817627118578, Steps = 30\n",
      "Episode 72: Total Reward = 22.652266072539184, Steps = 30\n",
      "Episode 73: Total Reward = 22.78625069743766, Steps = 30\n",
      "Episode 74: Total Reward = 25.351242206812692, Steps = 30\n",
      "Episode 75: Total Reward = 21.320221169036344, Steps = 30\n",
      "Episode 76: Total Reward = 10.486425596368147, Steps = 14\n",
      "Episode 77: Total Reward = 22.686887835703008, Steps = 30\n",
      "Episode 78: Total Reward = 12.613039142990253, Steps = 15\n",
      "Episode 79: Total Reward = 21.502660898878005, Steps = 30\n",
      "Episode 80: Total Reward = 11.886887819987134, Steps = 16\n",
      "Episode 81: Total Reward = 12.717945151280405, Steps = 16\n",
      "Episode 82: Total Reward = 14.020169016995638, Steps = 20\n",
      "Episode 83: Total Reward = 20.24876458350549, Steps = 26\n",
      "Episode 84: Total Reward = 22.519555039459267, Steps = 30\n",
      "Episode 85: Total Reward = 12.177532070489127, Steps = 14\n",
      "Episode 86: Total Reward = 23.486583347934925, Steps = 30\n",
      "Episode 87: Total Reward = 23.251077665238657, Steps = 30\n",
      "Episode 88: Total Reward = 16.03205728169731, Steps = 20\n",
      "Episode 89: Total Reward = 5.420168923598683, Steps = 7\n",
      "Episode 90: Total Reward = 14.098146140977757, Steps = 19\n",
      "Episode 91: Total Reward = 22.152931524441094, Steps = 30\n",
      "Episode 92: Total Reward = 25.429599876992718, Steps = 30\n",
      "Episode 93: Total Reward = 14.931066401327621, Steps = 18\n",
      "Episode 94: Total Reward = 25.729435488813568, Steps = 30\n",
      "Episode 95: Total Reward = 22.63368049564197, Steps = 30\n",
      "Episode 96: Total Reward = 22.3198282060971, Steps = 30\n",
      "Episode 97: Total Reward = 24.185642178760986, Steps = 30\n",
      "Episode 98: Total Reward = 23.48688783570301, Steps = 30\n",
      "Episode 99: Total Reward = 23.617695679180773, Steps = 30\n",
      "Episode 100: Total Reward = 24.820221169036333, Steps = 30\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import DQN\n",
    "\n",
    "model = DQN.load(\"models/highway_dqn_baseline\")\n",
    "\n",
    "\n",
    "def evaluate_model(env, model, num_episodes=100):\n",
    "    frames = []  # Store frames for each episode\n",
    "    for episode in range(num_episodes):\n",
    "        done = truncated = False\n",
    "        obs, info = env.reset()\n",
    "        total_reward = 0\n",
    "        steps = 0\n",
    "        \n",
    "        while not (done or truncated):\n",
    "            action, _states = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, truncated, info = env.step(action)\n",
    "            frame = env.render()\n",
    "            frames.append(frame)\n",
    "            total_reward += reward\n",
    "            steps += 1\n",
    "        \n",
    "        print(f\"Episode {episode + 1}: Total Reward = {total_reward}, Steps = {steps}\")\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    return frames\n",
    "\n",
    "highway_dqn_baseline_frames = evaluate_model(env, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model - Test Visual Inspection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video highway_baseline_performance.mp4.\n",
      "Moviepy - Writing video highway_baseline_performance.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready highway_baseline_performance.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"highway_baseline_performance.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "\n",
    "# Specify the frame rate (frames per second)\n",
    "fps = 20\n",
    "\n",
    "# Create a video clip from the frames\n",
    "clip = ImageSequenceClip(highway_dqn_baseline_frames, fps=fps)\n",
    "clip.write_videofile('videos/highway_baseline_performance.mp4', codec='libx264')\n",
    "\n",
    "Video(\"videos/highway_baseline_performance.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model - Hyperparameter fine tuning\n",
    "\n",
    "The fine-tuning process for the DQN model is conducted using Bayesian optimization via Optuna, which methodically searched for the optimal combination of hyperparameters within defined ranges. This approach systematically adjusts and evaluates the hyperparameters to maximize the expected outcome—here, the mean reward from the policy evaluation. The parameters explored include learning rate, batch size, gamma (discount factor), and network architecture.\n",
    "\n",
    "The fine-tuning focus on expanding the search space for gamma and altering the network architecture options. The learning rate was adjusted to lie between 1e-5 and 1e-3, and batch size variants were considered at 32, 64, and 128. The discount factor gamma's range was broadened from 0.8-0.99 in the baseline to 0.5-0.99 in the fine-tuning, allowing more exploration of the agent's long-term reward expectations. Network architecture choices were among single-layer [128], dual-layer [256, 256], and triple-layer [128, 128, 128]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-20 20:21:37,764] A new study created in memory with name: no-name-4bc95848-0f9e-424f-8247-8d39f74ae754\n",
      "[I 2024-04-20 20:27:33,047] Trial 0 finished with value: 20.104343913197518 and parameters: {'learning_rate': 0.0005170963465495028, 'batch_size': 64, 'gamma': 0.7482520915339761, 'net_arch': [128, 128, 128]}. Best is trial 0 with value: 20.104343913197518.\n",
      "[I 2024-04-20 20:33:27,169] Trial 1 finished with value: 19.475283718556167 and parameters: {'learning_rate': 0.00018556917294933184, 'batch_size': 32, 'gamma': 0.9163504464688864, 'net_arch': [128, 128, 128]}. Best is trial 0 with value: 20.104343913197518.\n",
      "[I 2024-04-20 20:39:21,235] Trial 2 finished with value: 11.769020607098938 and parameters: {'learning_rate': 1.4026570703885657e-05, 'batch_size': 32, 'gamma': 0.9171465040561244, 'net_arch': [256, 256]}. Best is trial 0 with value: 20.104343913197518.\n",
      "[I 2024-04-20 20:45:01,211] Trial 3 finished with value: 8.334700427874923 and parameters: {'learning_rate': 5.5734266784752756e-05, 'batch_size': 32, 'gamma': 0.6211077863720205, 'net_arch': [128]}. Best is trial 0 with value: 20.104343913197518.\n",
      "[I 2024-04-20 20:50:52,908] Trial 4 finished with value: 16.738425655141473 and parameters: {'learning_rate': 0.0005657273011624016, 'batch_size': 32, 'gamma': 0.7526535083841008, 'net_arch': [128, 128, 128]}. Best is trial 0 with value: 20.104343913197518.\n",
      "[I 2024-04-20 20:56:30,694] Trial 5 finished with value: 10.885256605041214 and parameters: {'learning_rate': 0.0003770549917138347, 'batch_size': 32, 'gamma': 0.7132458973449161, 'net_arch': [128]}. Best is trial 0 with value: 20.104343913197518.\n",
      "[I 2024-04-20 21:02:12,818] Trial 6 finished with value: 10.058362133800983 and parameters: {'learning_rate': 3.89314936984574e-05, 'batch_size': 128, 'gamma': 0.9008912128462754, 'net_arch': [128]}. Best is trial 0 with value: 20.104343913197518.\n",
      "[I 2024-04-20 21:08:02,076] Trial 7 finished with value: 14.226767831593753 and parameters: {'learning_rate': 0.00017455558544313954, 'batch_size': 64, 'gamma': 0.8817208586337737, 'net_arch': [128, 128, 128]}. Best is trial 0 with value: 20.104343913197518.\n",
      "[I 2024-04-20 21:14:01,055] Trial 8 finished with value: 21.801490084007384 and parameters: {'learning_rate': 0.0007551062542275508, 'batch_size': 64, 'gamma': 0.6123696099516621, 'net_arch': [256, 256]}. Best is trial 8 with value: 21.801490084007384.\n",
      "[I 2024-04-20 21:19:58,123] Trial 9 finished with value: 17.179446616619824 and parameters: {'learning_rate': 0.00043620563307071467, 'batch_size': 64, 'gamma': 0.6222554180465528, 'net_arch': [256, 256]}. Best is trial 8 with value: 21.801490084007384.\n",
      "[I 2024-04-20 21:26:03,111] Trial 10 finished with value: 21.9598880429618 and parameters: {'learning_rate': 0.0009781407348947153, 'batch_size': 128, 'gamma': 0.5110216087919963, 'net_arch': [256, 256]}. Best is trial 10 with value: 21.9598880429618.\n",
      "[I 2024-04-20 21:32:10,181] Trial 11 finished with value: 22.9408059386909 and parameters: {'learning_rate': 0.0009203206275040492, 'batch_size': 128, 'gamma': 0.5020368282453737, 'net_arch': [256, 256]}. Best is trial 11 with value: 22.9408059386909.\n",
      "[I 2024-04-20 21:38:16,039] Trial 12 finished with value: 19.60404224127531 and parameters: {'learning_rate': 0.0009554095172376008, 'batch_size': 128, 'gamma': 0.5174795382242334, 'net_arch': [256, 256]}. Best is trial 11 with value: 22.9408059386909.\n",
      "[I 2024-04-20 21:44:24,408] Trial 13 finished with value: 20.564380304589868 and parameters: {'learning_rate': 0.0002579874729103095, 'batch_size': 128, 'gamma': 0.5053137297277718, 'net_arch': [256, 256]}. Best is trial 11 with value: 22.9408059386909.\n",
      "[I 2024-04-20 21:50:27,595] Trial 14 finished with value: 14.006683790236712 and parameters: {'learning_rate': 9.498690037172405e-05, 'batch_size': 128, 'gamma': 0.5626739265129435, 'net_arch': [256, 256]}. Best is trial 11 with value: 22.9408059386909.\n",
      "[I 2024-04-20 21:56:35,398] Trial 15 finished with value: 23.340910299792885 and parameters: {'learning_rate': 0.0009537108481166637, 'batch_size': 128, 'gamma': 0.661526895125826, 'net_arch': [256, 256]}. Best is trial 15 with value: 23.340910299792885.\n",
      "[I 2024-04-20 22:02:39,993] Trial 16 finished with value: 12.873527001962065 and parameters: {'learning_rate': 1.5370688300145226e-05, 'batch_size': 128, 'gamma': 0.6852707035079287, 'net_arch': [256, 256]}. Best is trial 15 with value: 23.340910299792885.\n",
      "[I 2024-04-20 22:08:43,051] Trial 17 finished with value: 17.995509631484747 and parameters: {'learning_rate': 0.00028256936623663497, 'batch_size': 128, 'gamma': 0.7805248086587414, 'net_arch': [256, 256]}. Best is trial 15 with value: 23.340910299792885.\n",
      "[I 2024-04-20 22:14:46,791] Trial 18 finished with value: 18.68106144552119 and parameters: {'learning_rate': 0.00011263252096866826, 'batch_size': 128, 'gamma': 0.8337573727880704, 'net_arch': [256, 256]}. Best is trial 15 with value: 23.340910299792885.\n",
      "[I 2024-04-20 22:20:29,932] Trial 19 finished with value: 16.022095787525178 and parameters: {'learning_rate': 0.000650043549324489, 'batch_size': 128, 'gamma': 0.656577372518144, 'net_arch': [128]}. Best is trial 15 with value: 23.340910299792885.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'learning_rate': 0.0009537108481166637, 'batch_size': 128, 'gamma': 0.661526895125826, 'net_arch': [256, 256]}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "\n",
    "def optimize_agent(trial):\n",
    "    # Define hyperparameters to tune\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    gamma = trial.suggest_uniform('gamma', 0.5, 0.99)\n",
    "    net_arch = trial.suggest_categorical('net_arch', [[128], [256, 256], [128, 128, 128]])\n",
    "\n",
    "    # Create the model with these hyperparameters\n",
    "    model = DQN('MlpPolicy', env,\n",
    "                policy_kwargs=dict(net_arch=net_arch),\n",
    "                learning_rate=learning_rate,\n",
    "                buffer_size=15000,\n",
    "                learning_starts=200,\n",
    "                batch_size=batch_size,\n",
    "                gamma=gamma,\n",
    "                train_freq=1,\n",
    "                gradient_steps=1,\n",
    "                target_update_interval=50,\n",
    "                verbose=0,\n",
    "                tensorboard_log=\"./logs/highway_dqn_optuna\")\n",
    "\n",
    "    # Train the model\n",
    "    model.learn(int(2e4))\n",
    "    \n",
    "    # Evaluate the model, here using mean reward\n",
    "    mean_reward, _ = evaluate_policy(model.policy, env, n_eval_episodes=50)\n",
    "    \n",
    "    # Clear memory\n",
    "    model.save(f\"models/highway_dqn_optuna/optuna_dqn_{trial.number}\")\n",
    "    model.env.close()\n",
    "    del model\n",
    "\n",
    "    return mean_reward\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(optimize_agent, n_trials=20)\n",
    "\n",
    "print('Best hyperparameters: ', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fine-tuning efforts yielded a best set of hyperparameters with a learning rate of approximately 0.000953, batch size of 128, a gamma of 0.6615, and a network architecture of two 256-unit layers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline model - Re-train after hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to highway_dqn_fine_tuned_baseline/tensorboard_logs/DQN_3\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.5     |\n",
      "|    ep_rew_mean      | 11.9     |\n",
      "|    exploration_rate | 0.971    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 66       |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 62       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.4     |\n",
      "|    ep_rew_mean      | 8.46     |\n",
      "|    exploration_rate | 0.957    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 91       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.2     |\n",
      "|    ep_rew_mean      | 8.31     |\n",
      "|    exploration_rate | 0.936    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 66       |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 135      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.6     |\n",
      "|    ep_rew_mean      | 8.66     |\n",
      "|    exploration_rate | 0.912    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 186      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.1     |\n",
      "|    ep_rew_mean      | 8.29     |\n",
      "|    exploration_rate | 0.895    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 66       |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 222      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.015    |\n",
      "|    n_updates        | 21       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.8     |\n",
      "|    ep_rew_mean      | 8.77     |\n",
      "|    exploration_rate | 0.866    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 64       |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 282      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0729   |\n",
      "|    n_updates        | 81       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.3     |\n",
      "|    ep_rew_mean      | 8.46     |\n",
      "|    exploration_rate | 0.85     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 63       |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 316      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0803   |\n",
      "|    n_updates        | 115      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.8     |\n",
      "|    ep_rew_mean      | 8.94     |\n",
      "|    exploration_rate | 0.821    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 63       |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 377      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0972   |\n",
      "|    n_updates        | 176      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.5     |\n",
      "|    ep_rew_mean      | 8.7      |\n",
      "|    exploration_rate | 0.803    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 414      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.176    |\n",
      "|    n_updates        | 213      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.7     |\n",
      "|    ep_rew_mean      | 8.86     |\n",
      "|    exploration_rate | 0.779    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 466      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0875   |\n",
      "|    n_updates        | 265      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.5     |\n",
      "|    ep_rew_mean      | 8.76     |\n",
      "|    exploration_rate | 0.76     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 505      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.134    |\n",
      "|    n_updates        | 304      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.2     |\n",
      "|    ep_rew_mean      | 8.6      |\n",
      "|    exploration_rate | 0.744    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 538      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.116    |\n",
      "|    n_updates        | 337      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.8     |\n",
      "|    ep_rew_mean      | 8.28     |\n",
      "|    exploration_rate | 0.733    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 562      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.076    |\n",
      "|    n_updates        | 361      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.8     |\n",
      "|    ep_rew_mean      | 8.27     |\n",
      "|    exploration_rate | 0.714    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 602      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.134    |\n",
      "|    n_updates        | 401      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.5     |\n",
      "|    ep_rew_mean      | 8.08     |\n",
      "|    exploration_rate | 0.701    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 629      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.146    |\n",
      "|    n_updates        | 428      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.8     |\n",
      "|    ep_rew_mean      | 8.37     |\n",
      "|    exploration_rate | 0.671    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 692      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.071    |\n",
      "|    n_updates        | 491      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.8     |\n",
      "|    ep_rew_mean      | 8.32     |\n",
      "|    exploration_rate | 0.652    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 732      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.13     |\n",
      "|    n_updates        | 531      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.5     |\n",
      "|    ep_rew_mean      | 8.14     |\n",
      "|    exploration_rate | 0.64     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 758      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0787   |\n",
      "|    n_updates        | 557      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.7     |\n",
      "|    ep_rew_mean      | 8.27     |\n",
      "|    exploration_rate | 0.614    |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 812      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.18     |\n",
      "|    n_updates        | 611      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.5     |\n",
      "|    ep_rew_mean      | 8.1      |\n",
      "|    exploration_rate | 0.601    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 839      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.201    |\n",
      "|    n_updates        | 638      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.5     |\n",
      "|    ep_rew_mean      | 8.08     |\n",
      "|    exploration_rate | 0.582    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 879      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.131    |\n",
      "|    n_updates        | 678      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.8     |\n",
      "|    ep_rew_mean      | 8.35     |\n",
      "|    exploration_rate | 0.548    |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 951      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.141    |\n",
      "|    n_updates        | 750      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.9     |\n",
      "|    ep_rew_mean      | 8.4      |\n",
      "|    exploration_rate | 0.525    |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 1001     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.134    |\n",
      "|    n_updates        | 800      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.8     |\n",
      "|    ep_rew_mean      | 8.4      |\n",
      "|    exploration_rate | 0.506    |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 1041     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.18     |\n",
      "|    n_updates        | 840      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.1     |\n",
      "|    ep_rew_mean      | 8.56     |\n",
      "|    exploration_rate | 0.473    |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 1109     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0531   |\n",
      "|    n_updates        | 908      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.9     |\n",
      "|    ep_rew_mean      | 8.41     |\n",
      "|    exploration_rate | 0.452    |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 1154     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.146    |\n",
      "|    n_updates        | 953      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.2     |\n",
      "|    ep_rew_mean      | 8.66     |\n",
      "|    exploration_rate | 0.426    |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 1209     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.109    |\n",
      "|    n_updates        | 1008     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.2     |\n",
      "|    ep_rew_mean      | 8.75     |\n",
      "|    exploration_rate | 0.402    |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 1259     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.116    |\n",
      "|    n_updates        | 1058     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.1     |\n",
      "|    ep_rew_mean      | 8.62     |\n",
      "|    exploration_rate | 0.386    |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 1292     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.121    |\n",
      "|    n_updates        | 1091     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.2     |\n",
      "|    ep_rew_mean      | 8.76     |\n",
      "|    exploration_rate | 0.364    |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 1339     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0849   |\n",
      "|    n_updates        | 1138     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.1     |\n",
      "|    ep_rew_mean      | 8.68     |\n",
      "|    exploration_rate | 0.341    |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 1387     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.134    |\n",
      "|    n_updates        | 1186     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.2     |\n",
      "|    ep_rew_mean      | 8.83     |\n",
      "|    exploration_rate | 0.316    |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 1439     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.116    |\n",
      "|    n_updates        | 1238     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.2     |\n",
      "|    ep_rew_mean      | 8.78     |\n",
      "|    exploration_rate | 0.29     |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 1495     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.102    |\n",
      "|    n_updates        | 1294     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.3     |\n",
      "|    ep_rew_mean      | 8.92     |\n",
      "|    exploration_rate | 0.265    |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 1547     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.127    |\n",
      "|    n_updates        | 1346     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.3     |\n",
      "|    ep_rew_mean      | 8.94     |\n",
      "|    exploration_rate | 0.24     |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 1601     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.117    |\n",
      "|    n_updates        | 1400     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.5     |\n",
      "|    ep_rew_mean      | 9.04     |\n",
      "|    exploration_rate | 0.216    |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 1651     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.136    |\n",
      "|    n_updates        | 1450     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.8     |\n",
      "|    ep_rew_mean      | 9.25     |\n",
      "|    exploration_rate | 0.186    |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 1713     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0996   |\n",
      "|    n_updates        | 1512     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.9     |\n",
      "|    ep_rew_mean      | 9.41     |\n",
      "|    exploration_rate | 0.167    |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 1753     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0976   |\n",
      "|    n_updates        | 1552     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12       |\n",
      "|    ep_rew_mean      | 9.47     |\n",
      "|    exploration_rate | 0.145    |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 1801     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0667   |\n",
      "|    n_updates        | 1600     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.2     |\n",
      "|    ep_rew_mean      | 9.59     |\n",
      "|    exploration_rate | 0.124    |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 1844     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0979   |\n",
      "|    n_updates        | 1643     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.4     |\n",
      "|    ep_rew_mean      | 9.76     |\n",
      "|    exploration_rate | 0.0828   |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 1931     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.103    |\n",
      "|    n_updates        | 1730     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.9     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 2024     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0929   |\n",
      "|    n_updates        | 1823     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.2     |\n",
      "|    ep_rew_mean      | 10.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 2074     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0713   |\n",
      "|    n_updates        | 1873     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13       |\n",
      "|    ep_rew_mean      | 10.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 2116     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.101    |\n",
      "|    n_updates        | 1915     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 10.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 2171     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0542   |\n",
      "|    n_updates        | 1970     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 10.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 2231     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0739   |\n",
      "|    n_updates        | 2030     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 10.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 2321     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0871   |\n",
      "|    n_updates        | 2120     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14       |\n",
      "|    ep_rew_mean      | 11.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 2404     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0484   |\n",
      "|    n_updates        | 2203     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.3     |\n",
      "|    ep_rew_mean      | 11.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 2473     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.111    |\n",
      "|    n_updates        | 2272     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.4     |\n",
      "|    ep_rew_mean      | 11.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 2548     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0579   |\n",
      "|    n_updates        | 2347     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.9     |\n",
      "|    ep_rew_mean      | 12       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 2646     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0634   |\n",
      "|    n_updates        | 2445     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.5     |\n",
      "|    ep_rew_mean      | 12.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 2759     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0436   |\n",
      "|    n_updates        | 2558     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.9     |\n",
      "|    ep_rew_mean      | 12.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 2845     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0789   |\n",
      "|    n_updates        | 2644     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.2     |\n",
      "|    ep_rew_mean      | 13.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 2908     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0675   |\n",
      "|    n_updates        | 2707     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.4     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 2975     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0866   |\n",
      "|    n_updates        | 2774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.6     |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 3042     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0524   |\n",
      "|    n_updates        | 2841     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.6     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 3101     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0632   |\n",
      "|    n_updates        | 2900     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.7     |\n",
      "|    ep_rew_mean      | 13.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 3163     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.101    |\n",
      "|    n_updates        | 2962     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17       |\n",
      "|    ep_rew_mean      | 13.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 3246     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0983   |\n",
      "|    n_updates        | 3045     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.1     |\n",
      "|    ep_rew_mean      | 14       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 3310     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.089    |\n",
      "|    n_updates        | 3109     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.2     |\n",
      "|    ep_rew_mean      | 14.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 3374     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0372   |\n",
      "|    n_updates        | 3173     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.1     |\n",
      "|    ep_rew_mean      | 14       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 3421     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0425   |\n",
      "|    n_updates        | 3220     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.4     |\n",
      "|    ep_rew_mean      | 14.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 3493     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0438   |\n",
      "|    n_updates        | 3292     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.3     |\n",
      "|    ep_rew_mean      | 14.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 3533     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0257   |\n",
      "|    n_updates        | 3332     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.2     |\n",
      "|    ep_rew_mean      | 14.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 3560     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0479   |\n",
      "|    n_updates        | 3359     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.9     |\n",
      "|    ep_rew_mean      | 14       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 3622     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0701   |\n",
      "|    n_updates        | 3421     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.4     |\n",
      "|    ep_rew_mean      | 13.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 3664     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0862   |\n",
      "|    n_updates        | 3463     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.3     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 3702     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0866   |\n",
      "|    n_updates        | 3501     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.8     |\n",
      "|    ep_rew_mean      | 13.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 3791     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0533   |\n",
      "|    n_updates        | 3590     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.9     |\n",
      "|    ep_rew_mean      | 14       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 3861     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0669   |\n",
      "|    n_updates        | 3660     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.1     |\n",
      "|    ep_rew_mean      | 14.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 3937     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0629   |\n",
      "|    n_updates        | 3736     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.5     |\n",
      "|    ep_rew_mean      | 13.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 3971     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0559   |\n",
      "|    n_updates        | 3770     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.4     |\n",
      "|    ep_rew_mean      | 13.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 4048     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0557   |\n",
      "|    n_updates        | 3847     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.4     |\n",
      "|    ep_rew_mean      | 13.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 4109     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0741   |\n",
      "|    n_updates        | 3908     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.4     |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 4189     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0536   |\n",
      "|    n_updates        | 3988     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.2     |\n",
      "|    ep_rew_mean      | 13.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 4266     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.101    |\n",
      "|    n_updates        | 4065     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.3     |\n",
      "|    ep_rew_mean      | 13.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 4386     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0679   |\n",
      "|    n_updates        | 4185     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.8     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 4430     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0733   |\n",
      "|    n_updates        | 4229     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.6     |\n",
      "|    ep_rew_mean      | 13.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 4466     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0653   |\n",
      "|    n_updates        | 4265     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.6     |\n",
      "|    ep_rew_mean      | 13.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 4536     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.111    |\n",
      "|    n_updates        | 4335     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.4     |\n",
      "|    ep_rew_mean      | 12.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 4581     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0447   |\n",
      "|    n_updates        | 4380     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.8     |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 4676     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0573   |\n",
      "|    n_updates        | 4475     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16       |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 4760     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0512   |\n",
      "|    n_updates        | 4559     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.4     |\n",
      "|    ep_rew_mean      | 13       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 4790     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0536   |\n",
      "|    n_updates        | 4589     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.5     |\n",
      "|    ep_rew_mean      | 13.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 4864     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0461   |\n",
      "|    n_updates        | 4663     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.5     |\n",
      "|    ep_rew_mean      | 13.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 4923     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0472   |\n",
      "|    n_updates        | 4722     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.8     |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 5004     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.103    |\n",
      "|    n_updates        | 4803     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.8     |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 5078     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0535   |\n",
      "|    n_updates        | 4877     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.1     |\n",
      "|    ep_rew_mean      | 13.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 5141     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0625   |\n",
      "|    n_updates        | 4940     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.3     |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 5191     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0588   |\n",
      "|    n_updates        | 4990     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.8     |\n",
      "|    ep_rew_mean      | 14.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 5297     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0712   |\n",
      "|    n_updates        | 5096     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.8     |\n",
      "|    ep_rew_mean      | 14.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 5345     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.066    |\n",
      "|    n_updates        | 5144     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | 14.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 5458     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0955   |\n",
      "|    n_updates        | 5257     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | 14.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 5553     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0827   |\n",
      "|    n_updates        | 5352     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.8     |\n",
      "|    ep_rew_mean      | 15       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 5638     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0349   |\n",
      "|    n_updates        | 5437     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.7     |\n",
      "|    ep_rew_mean      | 15       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 5709     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0605   |\n",
      "|    n_updates        | 5508     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.5     |\n",
      "|    ep_rew_mean      | 15.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 5820     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0311   |\n",
      "|    n_updates        | 5619     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.4     |\n",
      "|    ep_rew_mean      | 15.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 5890     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0667   |\n",
      "|    n_updates        | 5689     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.5     |\n",
      "|    ep_rew_mean      | 15.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 5959     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0404   |\n",
      "|    n_updates        | 5758     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.5     |\n",
      "|    ep_rew_mean      | 15.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 6041     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0686   |\n",
      "|    n_updates        | 5840     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.6     |\n",
      "|    ep_rew_mean      | 15.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 6128     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0411   |\n",
      "|    n_updates        | 5927     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18       |\n",
      "|    ep_rew_mean      | 15.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 6184     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0491   |\n",
      "|    n_updates        | 5983     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.1     |\n",
      "|    ep_rew_mean      | 15.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 104      |\n",
      "|    total_timesteps  | 6244     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0465   |\n",
      "|    n_updates        | 6043     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.3     |\n",
      "|    ep_rew_mean      | 15.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 6294     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0407   |\n",
      "|    n_updates        | 6093     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.1     |\n",
      "|    ep_rew_mean      | 15.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 6344     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0278   |\n",
      "|    n_updates        | 6143     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.4     |\n",
      "|    ep_rew_mean      | 15.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 6425     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0491   |\n",
      "|    n_updates        | 6224     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.1     |\n",
      "|    ep_rew_mean      | 15.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total_timesteps  | 6483     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0492   |\n",
      "|    n_updates        | 6282     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.1     |\n",
      "|    ep_rew_mean      | 15.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 6573     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0909   |\n",
      "|    n_updates        | 6372     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.4     |\n",
      "|    ep_rew_mean      | 15.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 111      |\n",
      "|    total_timesteps  | 6630     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0759   |\n",
      "|    n_updates        | 6429     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.1     |\n",
      "|    ep_rew_mean      | 15.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 6679     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0548   |\n",
      "|    n_updates        | 6478     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.1     |\n",
      "|    ep_rew_mean      | 15.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 6730     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0697   |\n",
      "|    n_updates        | 6529     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.1     |\n",
      "|    ep_rew_mean      | 15.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total_timesteps  | 6814     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.067    |\n",
      "|    n_updates        | 6613     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.3     |\n",
      "|    ep_rew_mean      | 15.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total_timesteps  | 6912     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0356   |\n",
      "|    n_updates        | 6711     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.2     |\n",
      "|    ep_rew_mean      | 15.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 116      |\n",
      "|    total_timesteps  | 6962     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0453   |\n",
      "|    n_updates        | 6761     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.2     |\n",
      "|    ep_rew_mean      | 15.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 117      |\n",
      "|    total_timesteps  | 7016     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0264   |\n",
      "|    n_updates        | 6815     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18       |\n",
      "|    ep_rew_mean      | 15.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 119      |\n",
      "|    total_timesteps  | 7098     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0367   |\n",
      "|    n_updates        | 6897     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.1     |\n",
      "|    ep_rew_mean      | 15.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 120      |\n",
      "|    total_timesteps  | 7156     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0643   |\n",
      "|    n_updates        | 6955     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.9     |\n",
      "|    ep_rew_mean      | 15.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 121      |\n",
      "|    total_timesteps  | 7247     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0314   |\n",
      "|    n_updates        | 7046     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.7     |\n",
      "|    ep_rew_mean      | 15.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 122      |\n",
      "|    total_timesteps  | 7325     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0787   |\n",
      "|    n_updates        | 7124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | 15       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 124      |\n",
      "|    total_timesteps  | 7396     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0461   |\n",
      "|    n_updates        | 7195     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | 15       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 125      |\n",
      "|    total_timesteps  | 7465     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0205   |\n",
      "|    n_updates        | 7264     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.4     |\n",
      "|    ep_rew_mean      | 14.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 126      |\n",
      "|    total_timesteps  | 7556     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0624   |\n",
      "|    n_updates        | 7355     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.2     |\n",
      "|    ep_rew_mean      | 14.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 127      |\n",
      "|    total_timesteps  | 7609     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0597   |\n",
      "|    n_updates        | 7408     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.4     |\n",
      "|    ep_rew_mean      | 14.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 129      |\n",
      "|    total_timesteps  | 7700     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0382   |\n",
      "|    n_updates        | 7499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | 15       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 130      |\n",
      "|    total_timesteps  | 7802     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0747   |\n",
      "|    n_updates        | 7601     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.4     |\n",
      "|    ep_rew_mean      | 14.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 504      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 132      |\n",
      "|    total_timesteps  | 7869     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.033    |\n",
      "|    n_updates        | 7668     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.9     |\n",
      "|    ep_rew_mean      | 15.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 508      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 133      |\n",
      "|    total_timesteps  | 7971     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0705   |\n",
      "|    n_updates        | 7770     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.2     |\n",
      "|    ep_rew_mean      | 15.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 512      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 135      |\n",
      "|    total_timesteps  | 8064     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0437   |\n",
      "|    n_updates        | 7863     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.5     |\n",
      "|    ep_rew_mean      | 15.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 516      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 136      |\n",
      "|    total_timesteps  | 8143     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0457   |\n",
      "|    n_updates        | 7942     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.5     |\n",
      "|    ep_rew_mean      | 15.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 520      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 137      |\n",
      "|    total_timesteps  | 8195     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0358   |\n",
      "|    n_updates        | 7994     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.7     |\n",
      "|    ep_rew_mean      | 16       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 524      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 139      |\n",
      "|    total_timesteps  | 8297     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0707   |\n",
      "|    n_updates        | 8096     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.1     |\n",
      "|    ep_rew_mean      | 16.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 528      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 140      |\n",
      "|    total_timesteps  | 8391     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0542   |\n",
      "|    n_updates        | 8190     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.8     |\n",
      "|    ep_rew_mean      | 16.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 532      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 141      |\n",
      "|    total_timesteps  | 8457     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0522   |\n",
      "|    n_updates        | 8256     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.8     |\n",
      "|    ep_rew_mean      | 16.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 536      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 142      |\n",
      "|    total_timesteps  | 8513     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0491   |\n",
      "|    n_updates        | 8312     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19       |\n",
      "|    ep_rew_mean      | 16.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 540      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 143      |\n",
      "|    total_timesteps  | 8576     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0432   |\n",
      "|    n_updates        | 8375     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.1     |\n",
      "|    ep_rew_mean      | 16.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 544      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total_timesteps  | 8636     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0438   |\n",
      "|    n_updates        | 8435     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19       |\n",
      "|    ep_rew_mean      | 16.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 548      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 146      |\n",
      "|    total_timesteps  | 8710     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.056    |\n",
      "|    n_updates        | 8509     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19       |\n",
      "|    ep_rew_mean      | 16.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 552      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 147      |\n",
      "|    total_timesteps  | 8808     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0584   |\n",
      "|    n_updates        | 8607     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.3     |\n",
      "|    ep_rew_mean      | 16.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 556      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 149      |\n",
      "|    total_timesteps  | 8891     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0795   |\n",
      "|    n_updates        | 8690     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.2     |\n",
      "|    ep_rew_mean      | 16.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 560      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 150      |\n",
      "|    total_timesteps  | 8941     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0457   |\n",
      "|    n_updates        | 8740     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.4     |\n",
      "|    ep_rew_mean      | 16.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 564      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 151      |\n",
      "|    total_timesteps  | 9040     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0451   |\n",
      "|    n_updates        | 8839     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.8     |\n",
      "|    ep_rew_mean      | 17       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 568      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 153      |\n",
      "|    total_timesteps  | 9140     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.061    |\n",
      "|    n_updates        | 8939     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.9     |\n",
      "|    ep_rew_mean      | 17.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 572      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 155      |\n",
      "|    total_timesteps  | 9240     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0507   |\n",
      "|    n_updates        | 9039     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20       |\n",
      "|    ep_rew_mean      | 17.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 576      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 156      |\n",
      "|    total_timesteps  | 9323     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0473   |\n",
      "|    n_updates        | 9122     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20       |\n",
      "|    ep_rew_mean      | 17.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 580      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 157      |\n",
      "|    total_timesteps  | 9393     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0293   |\n",
      "|    n_updates        | 9192     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.2     |\n",
      "|    ep_rew_mean      | 17.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 584      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 159      |\n",
      "|    total_timesteps  | 9489     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0372   |\n",
      "|    n_updates        | 9288     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.9     |\n",
      "|    ep_rew_mean      | 17.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 588      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 160      |\n",
      "|    total_timesteps  | 9542     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0715   |\n",
      "|    n_updates        | 9341     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20       |\n",
      "|    ep_rew_mean      | 17.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 592      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 161      |\n",
      "|    total_timesteps  | 9610     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0395   |\n",
      "|    n_updates        | 9409     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.9     |\n",
      "|    ep_rew_mean      | 17.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 596      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 162      |\n",
      "|    total_timesteps  | 9689     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0567   |\n",
      "|    n_updates        | 9488     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.6     |\n",
      "|    ep_rew_mean      | 16.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 163      |\n",
      "|    total_timesteps  | 9759     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0829   |\n",
      "|    n_updates        | 9558     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.8     |\n",
      "|    ep_rew_mean      | 17.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 604      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 165      |\n",
      "|    total_timesteps  | 9849     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0417   |\n",
      "|    n_updates        | 9648     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.6     |\n",
      "|    ep_rew_mean      | 16.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 608      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 166      |\n",
      "|    total_timesteps  | 9927     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0247   |\n",
      "|    n_updates        | 9726     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.4     |\n",
      "|    ep_rew_mean      | 16.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 612      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 167      |\n",
      "|    total_timesteps  | 10003    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0213   |\n",
      "|    n_updates        | 9802     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.1     |\n",
      "|    ep_rew_mean      | 16.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 616      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 168      |\n",
      "|    total_timesteps  | 10055    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.041    |\n",
      "|    n_updates        | 9854     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.5     |\n",
      "|    ep_rew_mean      | 16.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 620      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 170      |\n",
      "|    total_timesteps  | 10142    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0289   |\n",
      "|    n_updates        | 9941     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.2     |\n",
      "|    ep_rew_mean      | 16.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 624      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 171      |\n",
      "|    total_timesteps  | 10222    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0439   |\n",
      "|    n_updates        | 10021    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.4     |\n",
      "|    ep_rew_mean      | 16.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 628      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 173      |\n",
      "|    total_timesteps  | 10329    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0327   |\n",
      "|    n_updates        | 10128    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.3     |\n",
      "|    ep_rew_mean      | 16.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 632      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 174      |\n",
      "|    total_timesteps  | 10384    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0371   |\n",
      "|    n_updates        | 10183    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.7     |\n",
      "|    ep_rew_mean      | 17.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 636      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 176      |\n",
      "|    total_timesteps  | 10480    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0385   |\n",
      "|    n_updates        | 10279    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.8     |\n",
      "|    ep_rew_mean      | 17.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 640      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 177      |\n",
      "|    total_timesteps  | 10560    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0485   |\n",
      "|    n_updates        | 10359    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.1     |\n",
      "|    ep_rew_mean      | 17.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 644      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 178      |\n",
      "|    total_timesteps  | 10641    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0294   |\n",
      "|    n_updates        | 10440    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.5     |\n",
      "|    ep_rew_mean      | 17.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 648      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 180      |\n",
      "|    total_timesteps  | 10761    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0322   |\n",
      "|    n_updates        | 10560    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.3     |\n",
      "|    ep_rew_mean      | 17.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 652      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 182      |\n",
      "|    total_timesteps  | 10836    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0384   |\n",
      "|    n_updates        | 10635    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.1     |\n",
      "|    ep_rew_mean      | 17.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 656      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 183      |\n",
      "|    total_timesteps  | 10902    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0502   |\n",
      "|    n_updates        | 10701    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.4     |\n",
      "|    ep_rew_mean      | 17.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 660      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 184      |\n",
      "|    total_timesteps  | 10984    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0425   |\n",
      "|    n_updates        | 10783    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.5     |\n",
      "|    ep_rew_mean      | 18       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 664      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 186      |\n",
      "|    total_timesteps  | 11086    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0246   |\n",
      "|    n_updates        | 10885    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.3     |\n",
      "|    ep_rew_mean      | 17.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 668      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 187      |\n",
      "|    total_timesteps  | 11167    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0178   |\n",
      "|    n_updates        | 10966    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.5     |\n",
      "|    ep_rew_mean      | 18       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 672      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 189      |\n",
      "|    total_timesteps  | 11287    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0662   |\n",
      "|    n_updates        | 11086    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.4     |\n",
      "|    ep_rew_mean      | 18       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 676      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 191      |\n",
      "|    total_timesteps  | 11367    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.04     |\n",
      "|    n_updates        | 11166    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.6     |\n",
      "|    ep_rew_mean      | 18.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 680      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 192      |\n",
      "|    total_timesteps  | 11458    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0591   |\n",
      "|    n_updates        | 11257    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.7     |\n",
      "|    ep_rew_mean      | 18.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 684      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 194      |\n",
      "|    total_timesteps  | 11557    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0342   |\n",
      "|    n_updates        | 11356    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21       |\n",
      "|    ep_rew_mean      | 18.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 688      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 195      |\n",
      "|    total_timesteps  | 11638    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0306   |\n",
      "|    n_updates        | 11437    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 18.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 692      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 197      |\n",
      "|    total_timesteps  | 11728    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0283   |\n",
      "|    n_updates        | 11527    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 18.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 696      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 198      |\n",
      "|    total_timesteps  | 11827    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.037    |\n",
      "|    n_updates        | 11626    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 18.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 700      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 200      |\n",
      "|    total_timesteps  | 11895    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0472   |\n",
      "|    n_updates        | 11694    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 18.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 704      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 201      |\n",
      "|    total_timesteps  | 11994    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0305   |\n",
      "|    n_updates        | 11793    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 18.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 708      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 203      |\n",
      "|    total_timesteps  | 12072    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0293   |\n",
      "|    n_updates        | 11871    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 18.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 712      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 203      |\n",
      "|    total_timesteps  | 12121    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0445   |\n",
      "|    n_updates        | 11920    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 19.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 716      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 205      |\n",
      "|    total_timesteps  | 12241    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0364   |\n",
      "|    n_updates        | 12040    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 19.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 720      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 207      |\n",
      "|    total_timesteps  | 12324    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0663   |\n",
      "|    n_updates        | 12123    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 19.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 724      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 208      |\n",
      "|    total_timesteps  | 12385    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0442   |\n",
      "|    n_updates        | 12184    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 19.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 728      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 210      |\n",
      "|    total_timesteps  | 12494    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0304   |\n",
      "|    n_updates        | 12293    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 19.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 732      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 211      |\n",
      "|    total_timesteps  | 12572    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0633   |\n",
      "|    n_updates        | 12371    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 19.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 736      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 213      |\n",
      "|    total_timesteps  | 12668    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0323   |\n",
      "|    n_updates        | 12467    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 19.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 740      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 214      |\n",
      "|    total_timesteps  | 12761    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.062    |\n",
      "|    n_updates        | 12560    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 19.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 744      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 216      |\n",
      "|    total_timesteps  | 12863    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0409   |\n",
      "|    n_updates        | 12662    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.7     |\n",
      "|    ep_rew_mean      | 19.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 748      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 217      |\n",
      "|    total_timesteps  | 12928    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0267   |\n",
      "|    n_updates        | 12727    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 19.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 752      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 218      |\n",
      "|    total_timesteps  | 13001    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0509   |\n",
      "|    n_updates        | 12800    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.5     |\n",
      "|    ep_rew_mean      | 19       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 756      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 219      |\n",
      "|    total_timesteps  | 13052    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0299   |\n",
      "|    n_updates        | 12851    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 19       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 760      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 220      |\n",
      "|    total_timesteps  | 13125    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0313   |\n",
      "|    n_updates        | 12924    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 18.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 764      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 222      |\n",
      "|    total_timesteps  | 13221    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0457   |\n",
      "|    n_updates        | 13020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 18.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 768      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 223      |\n",
      "|    total_timesteps  | 13285    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0213   |\n",
      "|    n_updates        | 13084    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.6     |\n",
      "|    ep_rew_mean      | 18.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 772      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 224      |\n",
      "|    total_timesteps  | 13348    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0328   |\n",
      "|    n_updates        | 13147    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.5     |\n",
      "|    ep_rew_mean      | 18.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 776      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 225      |\n",
      "|    total_timesteps  | 13418    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.018    |\n",
      "|    n_updates        | 13217    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.3     |\n",
      "|    ep_rew_mean      | 18       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 780      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 226      |\n",
      "|    total_timesteps  | 13489    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0458   |\n",
      "|    n_updates        | 13288    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.9     |\n",
      "|    ep_rew_mean      | 17.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 784      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 227      |\n",
      "|    total_timesteps  | 13542    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0411   |\n",
      "|    n_updates        | 13341    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.6     |\n",
      "|    ep_rew_mean      | 17.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 788      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 228      |\n",
      "|    total_timesteps  | 13595    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0494   |\n",
      "|    n_updates        | 13394    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.6     |\n",
      "|    ep_rew_mean      | 17.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 792      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 230      |\n",
      "|    total_timesteps  | 13689    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0216   |\n",
      "|    n_updates        | 13488    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.4     |\n",
      "|    ep_rew_mean      | 17.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 796      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 231      |\n",
      "|    total_timesteps  | 13763    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0373   |\n",
      "|    n_updates        | 13562    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.3     |\n",
      "|    ep_rew_mean      | 17.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 800      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 232      |\n",
      "|    total_timesteps  | 13827    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0415   |\n",
      "|    n_updates        | 13626    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.1     |\n",
      "|    ep_rew_mean      | 17       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 804      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 233      |\n",
      "|    total_timesteps  | 13904    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0346   |\n",
      "|    n_updates        | 13703    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.1     |\n",
      "|    ep_rew_mean      | 16.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 808      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 235      |\n",
      "|    total_timesteps  | 13980    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0423   |\n",
      "|    n_updates        | 13779    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.6     |\n",
      "|    ep_rew_mean      | 17.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 812      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 237      |\n",
      "|    total_timesteps  | 14078    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0612   |\n",
      "|    n_updates        | 13877    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.4     |\n",
      "|    ep_rew_mean      | 17.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 816      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 238      |\n",
      "|    total_timesteps  | 14177    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0437   |\n",
      "|    n_updates        | 13976    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.7     |\n",
      "|    ep_rew_mean      | 17.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 820      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 240      |\n",
      "|    total_timesteps  | 14297    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0223   |\n",
      "|    n_updates        | 14096    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.1     |\n",
      "|    ep_rew_mean      | 17.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 824      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 242      |\n",
      "|    total_timesteps  | 14398    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0382   |\n",
      "|    n_updates        | 14197    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20       |\n",
      "|    ep_rew_mean      | 17.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 828      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 244      |\n",
      "|    total_timesteps  | 14498    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0336   |\n",
      "|    n_updates        | 14297    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20       |\n",
      "|    ep_rew_mean      | 17.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 832      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 245      |\n",
      "|    total_timesteps  | 14576    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0266   |\n",
      "|    n_updates        | 14375    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.9     |\n",
      "|    ep_rew_mean      | 17.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 836      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 247      |\n",
      "|    total_timesteps  | 14659    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0332   |\n",
      "|    n_updates        | 14458    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.4     |\n",
      "|    ep_rew_mean      | 17.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 840      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 247      |\n",
      "|    total_timesteps  | 14705    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0424   |\n",
      "|    n_updates        | 14504    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.4     |\n",
      "|    ep_rew_mean      | 17.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 844      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 249      |\n",
      "|    total_timesteps  | 14804    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0314   |\n",
      "|    n_updates        | 14603    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.7     |\n",
      "|    ep_rew_mean      | 17.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 848      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 251      |\n",
      "|    total_timesteps  | 14895    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0462   |\n",
      "|    n_updates        | 14694    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.7     |\n",
      "|    ep_rew_mean      | 17.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 852      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 252      |\n",
      "|    total_timesteps  | 14970    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0316   |\n",
      "|    n_updates        | 14769    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.3     |\n",
      "|    ep_rew_mean      | 18.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 856      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 254      |\n",
      "|    total_timesteps  | 15078    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0318   |\n",
      "|    n_updates        | 14877    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.8     |\n",
      "|    ep_rew_mean      | 17.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 860      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 254      |\n",
      "|    total_timesteps  | 15102    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0342   |\n",
      "|    n_updates        | 14901    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.8     |\n",
      "|    ep_rew_mean      | 17.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 864      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 256      |\n",
      "|    total_timesteps  | 15198    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0263   |\n",
      "|    n_updates        | 14997    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.9     |\n",
      "|    ep_rew_mean      | 17.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 868      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 257      |\n",
      "|    total_timesteps  | 15278    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0651   |\n",
      "|    n_updates        | 15077    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.1     |\n",
      "|    ep_rew_mean      | 17.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 872      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 259      |\n",
      "|    total_timesteps  | 15355    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0463   |\n",
      "|    n_updates        | 15154    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.2     |\n",
      "|    ep_rew_mean      | 17.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 876      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 260      |\n",
      "|    total_timesteps  | 15434    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0446   |\n",
      "|    n_updates        | 15233    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.3     |\n",
      "|    ep_rew_mean      | 18       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 880      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 261      |\n",
      "|    total_timesteps  | 15518    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0267   |\n",
      "|    n_updates        | 15317    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.5     |\n",
      "|    ep_rew_mean      | 18.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 884      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 263      |\n",
      "|    total_timesteps  | 15594    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0257   |\n",
      "|    n_updates        | 15393    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 18.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 888      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 265      |\n",
      "|    total_timesteps  | 15711    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0443   |\n",
      "|    n_updates        | 15510    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.9     |\n",
      "|    ep_rew_mean      | 18.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 892      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 266      |\n",
      "|    total_timesteps  | 15784    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0288   |\n",
      "|    n_updates        | 15583    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | 18.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 896      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 267      |\n",
      "|    total_timesteps  | 15875    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.063    |\n",
      "|    n_updates        | 15674    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 18.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 900      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 269      |\n",
      "|    total_timesteps  | 15945    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.051    |\n",
      "|    n_updates        | 15744    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.3     |\n",
      "|    ep_rew_mean      | 18.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 904      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 270      |\n",
      "|    total_timesteps  | 16036    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0339   |\n",
      "|    n_updates        | 15835    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.3     |\n",
      "|    ep_rew_mean      | 18.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 908      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 271      |\n",
      "|    total_timesteps  | 16110    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 15909    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 18.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 912      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 273      |\n",
      "|    total_timesteps  | 16196    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0228   |\n",
      "|    n_updates        | 15995    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 18.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 916      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 274      |\n",
      "|    total_timesteps  | 16293    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0356   |\n",
      "|    n_updates        | 16092    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.8     |\n",
      "|    ep_rew_mean      | 18.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 920      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 276      |\n",
      "|    total_timesteps  | 16373    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 16172    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.8     |\n",
      "|    ep_rew_mean      | 18.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 924      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 277      |\n",
      "|    total_timesteps  | 16475    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0287   |\n",
      "|    n_updates        | 16274    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.7     |\n",
      "|    ep_rew_mean      | 18.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 928      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 279      |\n",
      "|    total_timesteps  | 16567    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0275   |\n",
      "|    n_updates        | 16366    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.9     |\n",
      "|    ep_rew_mean      | 18.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 932      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 281      |\n",
      "|    total_timesteps  | 16666    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0291   |\n",
      "|    n_updates        | 16465    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.9     |\n",
      "|    ep_rew_mean      | 18.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 936      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 282      |\n",
      "|    total_timesteps  | 16749    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0438   |\n",
      "|    n_updates        | 16548    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.3     |\n",
      "|    ep_rew_mean      | 19       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 940      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 283      |\n",
      "|    total_timesteps  | 16839    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0185   |\n",
      "|    n_updates        | 16638    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 18.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 944      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 285      |\n",
      "|    total_timesteps  | 16940    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0192   |\n",
      "|    n_updates        | 16739    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 18.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 948      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 286      |\n",
      "|    total_timesteps  | 17015    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0332   |\n",
      "|    n_updates        | 16814    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21       |\n",
      "|    ep_rew_mean      | 18.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 952      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 287      |\n",
      "|    total_timesteps  | 17068    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0564   |\n",
      "|    n_updates        | 16867    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.7     |\n",
      "|    ep_rew_mean      | 18.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 956      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 289      |\n",
      "|    total_timesteps  | 17145    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0183   |\n",
      "|    n_updates        | 16944    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 18.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 960      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 290      |\n",
      "|    total_timesteps  | 17239    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.015    |\n",
      "|    n_updates        | 17038    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.3     |\n",
      "|    ep_rew_mean      | 18.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 964      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 292      |\n",
      "|    total_timesteps  | 17330    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0201   |\n",
      "|    n_updates        | 17129    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 18.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 968      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 293      |\n",
      "|    total_timesteps  | 17403    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0516   |\n",
      "|    n_updates        | 17202    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 19.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 972      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 295      |\n",
      "|    total_timesteps  | 17511    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0156   |\n",
      "|    n_updates        | 17310    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 19.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 976      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 296      |\n",
      "|    total_timesteps  | 17595    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0167   |\n",
      "|    n_updates        | 17394    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 19.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 980      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 297      |\n",
      "|    total_timesteps  | 17674    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.037    |\n",
      "|    n_updates        | 17473    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.7     |\n",
      "|    ep_rew_mean      | 19.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 984      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 299      |\n",
      "|    total_timesteps  | 17768    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0352   |\n",
      "|    n_updates        | 17567    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.7     |\n",
      "|    ep_rew_mean      | 19.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 988      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 301      |\n",
      "|    total_timesteps  | 17881    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.021    |\n",
      "|    n_updates        | 17680    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.7     |\n",
      "|    ep_rew_mean      | 19.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 992      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 302      |\n",
      "|    total_timesteps  | 17953    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0335   |\n",
      "|    n_updates        | 17752    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 19.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 996      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 304      |\n",
      "|    total_timesteps  | 18066    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0294   |\n",
      "|    n_updates        | 17865    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 19.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1000     |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 305      |\n",
      "|    total_timesteps  | 18157    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0268   |\n",
      "|    n_updates        | 17956    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 19.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1004     |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 307      |\n",
      "|    total_timesteps  | 18252    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0266   |\n",
      "|    n_updates        | 18051    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.6     |\n",
      "|    ep_rew_mean      | 20.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1008     |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 309      |\n",
      "|    total_timesteps  | 18367    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0402   |\n",
      "|    n_updates        | 18166    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.7     |\n",
      "|    ep_rew_mean      | 20.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1012     |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 311      |\n",
      "|    total_timesteps  | 18469    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0207   |\n",
      "|    n_updates        | 18268    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.8     |\n",
      "|    ep_rew_mean      | 20.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1016     |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 312      |\n",
      "|    total_timesteps  | 18571    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0343   |\n",
      "|    n_updates        | 18370    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23       |\n",
      "|    ep_rew_mean      | 20.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1020     |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 314      |\n",
      "|    total_timesteps  | 18671    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 18470    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.8     |\n",
      "|    ep_rew_mean      | 20.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1024     |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 315      |\n",
      "|    total_timesteps  | 18751    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.015    |\n",
      "|    n_updates        | 18550    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.7     |\n",
      "|    ep_rew_mean      | 20.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1028     |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 317      |\n",
      "|    total_timesteps  | 18837    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0388   |\n",
      "|    n_updates        | 18636    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.6     |\n",
      "|    ep_rew_mean      | 20.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1032     |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 318      |\n",
      "|    total_timesteps  | 18921    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0452   |\n",
      "|    n_updates        | 18720    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 20.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1036     |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 319      |\n",
      "|    total_timesteps  | 18993    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0167   |\n",
      "|    n_updates        | 18792    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.6     |\n",
      "|    ep_rew_mean      | 20.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1040     |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 321      |\n",
      "|    total_timesteps  | 19100    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0309   |\n",
      "|    n_updates        | 18899    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 20.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1044     |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 323      |\n",
      "|    total_timesteps  | 19175    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0194   |\n",
      "|    n_updates        | 18974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.8     |\n",
      "|    ep_rew_mean      | 20.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1048     |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 324      |\n",
      "|    total_timesteps  | 19292    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0347   |\n",
      "|    n_updates        | 19091    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.2     |\n",
      "|    ep_rew_mean      | 20.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1052     |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 326      |\n",
      "|    total_timesteps  | 19387    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0253   |\n",
      "|    n_updates        | 19186    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.6     |\n",
      "|    ep_rew_mean      | 21.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1056     |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 328      |\n",
      "|    total_timesteps  | 19507    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 19306    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.5     |\n",
      "|    ep_rew_mean      | 21.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1060     |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 329      |\n",
      "|    total_timesteps  | 19586    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0313   |\n",
      "|    n_updates        | 19385    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.5     |\n",
      "|    ep_rew_mean      | 21.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1064     |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 331      |\n",
      "|    total_timesteps  | 19679    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0394   |\n",
      "|    n_updates        | 19478    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.6     |\n",
      "|    ep_rew_mean      | 21.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1068     |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 332      |\n",
      "|    total_timesteps  | 19760    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0362   |\n",
      "|    n_updates        | 19559    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.7     |\n",
      "|    ep_rew_mean      | 21.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1072     |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 334      |\n",
      "|    total_timesteps  | 19880    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0261   |\n",
      "|    n_updates        | 19679    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.8     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1076     |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 336      |\n",
      "|    total_timesteps  | 19976    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000953 |\n",
      "|    loss             | 0.0182   |\n",
      "|    n_updates        | 19775    |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import DQN\n",
    "\n",
    "model = DQN('MlpPolicy', env,\n",
    "              policy_kwargs=dict(net_arch=[256, 256]),\n",
    "              learning_rate=0.000953,\n",
    "              buffer_size=15000,\n",
    "              learning_starts=200,\n",
    "              batch_size=128,\n",
    "              gamma=0.6615,\n",
    "              train_freq=1,\n",
    "              gradient_steps=1,\n",
    "              target_update_interval=50,\n",
    "              verbose=1,\n",
    "              tensorboard_log=\"./logs/highway_dqn_fine_tuned_baseline\")\n",
    "model.learn(int(2e4))\n",
    "model.save(\"./models/highway_dqn_fine_tuned_baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation - After tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-906c18d60131b383\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-906c18d60131b383\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%reload_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir ./logs/highway_dqn_fine_tuned_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The achieved results from this fine-tuning process exhibit significant improvements, as indicated by the best trial achieving a mean reward of 23.34, which surpasses the baseline results prior to fine-tuning. The increase in the mean episode length and mean episode reward, along with consistent frames per second, reflects an enhanced learning ability and potentially a more stable and efficient policy.\n",
    "\n",
    "When comparing these fine-tuned results to the previous baseline model, the adjustments in hyperparameters appear to have led to a more proficient agent. The exploration rate's decline suggests that as training progressed, the agent became more confident in its strategy and less reliant on exploration. This balance between exploration and exploitation is crucial for the agent's performance, as evidenced by the improved mean reward and episode length. It is important to note that the increase in batch size and the adjustment in network architecture may have contributed significantly to these improvements by providing more robust and frequent updates during learning, as well as a network capacity more suited to the complexity of the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuned Baseline model - Test Visual Inspection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = 27.384857012362403, Steps = 30\n",
      "Episode 2: Total Reward = 8.267515452624355, Steps = 10\n",
      "Episode 3: Total Reward = 26.09874733095471, Steps = 30\n",
      "Episode 4: Total Reward = 28.374905191930093, Steps = 30\n",
      "Episode 5: Total Reward = 20.729516090447255, Steps = 22\n",
      "Episode 6: Total Reward = 28.67694621977947, Steps = 30\n",
      "Episode 7: Total Reward = 12.446866391137508, Steps = 14\n",
      "Episode 8: Total Reward = 12.617457649010083, Steps = 14\n",
      "Episode 9: Total Reward = 28.709306895206076, Steps = 30\n",
      "Episode 10: Total Reward = 19.33238913183402, Steps = 22\n",
      "Episode 11: Total Reward = 4.778845409167895, Steps = 6\n",
      "Episode 12: Total Reward = 23.151793926602107, Steps = 30\n",
      "Episode 13: Total Reward = 29.2093451644562, Steps = 30\n",
      "Episode 14: Total Reward = 12.280226505133037, Steps = 14\n",
      "Episode 15: Total Reward = 28.641248929884334, Steps = 30\n",
      "Episode 16: Total Reward = 29.329254127762656, Steps = 30\n",
      "Episode 17: Total Reward = 18.384023910882114, Steps = 21\n",
      "Episode 18: Total Reward = 28.07449489941365, Steps = 30\n",
      "Episode 19: Total Reward = 26.416316958893926, Steps = 30\n",
      "Episode 20: Total Reward = 25.13179560840623, Steps = 28\n",
      "Episode 21: Total Reward = 28.742221834004635, Steps = 30\n",
      "Episode 22: Total Reward = 24.045718614739826, Steps = 30\n",
      "Episode 23: Total Reward = 28.44169751575511, Steps = 30\n",
      "Episode 24: Total Reward = 15.515805304168566, Steps = 17\n",
      "Episode 25: Total Reward = 25.617546756188656, Steps = 30\n",
      "Episode 26: Total Reward = 24.74897830075855, Steps = 30\n",
      "Episode 27: Total Reward = 5.712165367235626, Steps = 7\n",
      "Episode 28: Total Reward = 27.60920853139644, Steps = 30\n",
      "Episode 29: Total Reward = 28.675536288387228, Steps = 30\n",
      "Episode 30: Total Reward = 28.51039254063247, Steps = 30\n",
      "Episode 31: Total Reward = 17.160847629199736, Steps = 19\n",
      "Episode 32: Total Reward = 25.850746725959866, Steps = 30\n",
      "Episode 33: Total Reward = 11.545973384250903, Steps = 13\n",
      "Episode 34: Total Reward = 7.7117200456750705, Steps = 9\n",
      "Episode 35: Total Reward = 29.17536860998309, Steps = 30\n",
      "Episode 36: Total Reward = 28.57517199490573, Steps = 30\n",
      "Episode 37: Total Reward = 28.575354871719295, Steps = 30\n",
      "Episode 38: Total Reward = 1.8801294969714422, Steps = 3\n",
      "Episode 39: Total Reward = 23.186415539275888, Steps = 30\n",
      "Episode 40: Total Reward = 8.44505341006576, Steps = 10\n",
      "Episode 41: Total Reward = 29.009807268355374, Steps = 30\n",
      "Episode 42: Total Reward = 8.611711492949349, Steps = 10\n",
      "Episode 43: Total Reward = 28.776473939791455, Steps = 30\n",
      "Episode 44: Total Reward = 27.51578576827923, Steps = 30\n",
      "Episode 45: Total Reward = 27.583901754513864, Steps = 30\n",
      "Episode 46: Total Reward = 27.878290766310396, Steps = 30\n",
      "Episode 47: Total Reward = 28.450197165538913, Steps = 30\n",
      "Episode 48: Total Reward = 25.995989862961306, Steps = 30\n",
      "Episode 49: Total Reward = 8.862129456250612, Steps = 10\n",
      "Episode 50: Total Reward = 28.276307346834212, Steps = 30\n",
      "Episode 51: Total Reward = 10.012182170125524, Steps = 11\n",
      "Episode 52: Total Reward = 26.416940623167374, Steps = 30\n",
      "Episode 53: Total Reward = 16.298955932850053, Steps = 18\n",
      "Episode 54: Total Reward = 10.150826976799364, Steps = 12\n",
      "Episode 55: Total Reward = 25.618804788102196, Steps = 30\n",
      "Episode 56: Total Reward = 9.929726046679747, Steps = 11\n",
      "Episode 57: Total Reward = 24.277950762125666, Steps = 30\n",
      "Episode 58: Total Reward = 15.277443223358063, Steps = 17\n",
      "Episode 59: Total Reward = 20.719276953477227, Steps = 24\n",
      "Episode 60: Total Reward = 17.22971195594015, Steps = 19\n",
      "Episode 61: Total Reward = 2.9307166415764856, Steps = 4\n",
      "Episode 62: Total Reward = 20.01737507062415, Steps = 23\n",
      "Episode 63: Total Reward = 26.616743162623973, Steps = 30\n",
      "Episode 64: Total Reward = 27.497034286522343, Steps = 30\n",
      "Episode 65: Total Reward = 29.3093353284483, Steps = 30\n",
      "Episode 66: Total Reward = 29.375043479849978, Steps = 30\n",
      "Episode 67: Total Reward = 28.17570903785992, Steps = 30\n",
      "Episode 68: Total Reward = 15.364798460557225, Steps = 18\n",
      "Episode 69: Total Reward = 29.19432958872473, Steps = 30\n",
      "Episode 70: Total Reward = 24.394976459261947, Steps = 26\n",
      "Episode 71: Total Reward = 29.243612817793444, Steps = 30\n",
      "Episode 72: Total Reward = 28.475242107304393, Steps = 30\n",
      "Episode 73: Total Reward = 26.816588408207547, Steps = 30\n",
      "Episode 74: Total Reward = 25.777750312559423, Steps = 30\n",
      "Episode 75: Total Reward = 10.795444283392733, Steps = 12\n",
      "Episode 76: Total Reward = 2.046796163638108, Steps = 3\n",
      "Episode 77: Total Reward = 21.64448847951806, Steps = 26\n",
      "Episode 78: Total Reward = 4.712193690313512, Steps = 6\n",
      "Episode 79: Total Reward = 28.341583056785716, Steps = 30\n",
      "Episode 80: Total Reward = 24.618329269462656, Steps = 30\n",
      "Episode 81: Total Reward = 6.611720090378734, Steps = 8\n",
      "Episode 82: Total Reward = 12.377891733642713, Steps = 14\n",
      "Episode 83: Total Reward = 12.66305938876827, Steps = 14\n",
      "Episode 84: Total Reward = 26.51802827444531, Steps = 30\n",
      "Episode 85: Total Reward = 27.946890662714374, Steps = 30\n",
      "Episode 86: Total Reward = 29.643154836830085, Steps = 30\n",
      "Episode 87: Total Reward = 2.046796163638108, Steps = 3\n",
      "Episode 88: Total Reward = 9.711266529642517, Steps = 11\n",
      "Episode 89: Total Reward = 27.38594360410032, Steps = 30\n",
      "Episode 90: Total Reward = 29.241233508622233, Steps = 30\n",
      "Episode 91: Total Reward = 13.59861615555424, Steps = 15\n",
      "Episode 92: Total Reward = 28.50854264244048, Steps = 30\n",
      "Episode 93: Total Reward = 1.2130006968016176, Steps = 2\n",
      "Episode 94: Total Reward = 28.807625948839338, Steps = 30\n",
      "Episode 95: Total Reward = 15.584615641254072, Steps = 18\n",
      "Episode 96: Total Reward = 26.278200430255556, Steps = 30\n",
      "Episode 97: Total Reward = 26.876357190177785, Steps = 30\n",
      "Episode 98: Total Reward = 20.543281901507257, Steps = 23\n",
      "Episode 99: Total Reward = 19.377876099743062, Steps = 21\n",
      "Episode 100: Total Reward = 5.212640325734789, Steps = 6\n",
      "Moviepy - Building video highway_fine_tuned_baseline_performance.mp4.\n",
      "Moviepy - Writing video highway_fine_tuned_baseline_performance.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready highway_fine_tuned_baseline_performance.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"highway_fine_tuned_baseline_performance.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "\n",
    "model = DQN.load(\"./models/highway_dqn_fine_tuned_baseline\")\n",
    "highway_dqn_fine_tuned_baseline_frames = evaluate_model(env, model)\n",
    "\n",
    "# Specify the frame rate (frames per second)\n",
    "fps = 20\n",
    "\n",
    "# Create a video clip from the frames\n",
    "clip = ImageSequenceClip(highway_dqn_baseline_frames, fps=fps)\n",
    "clip.write_videofile('./videos/highway_fine_tuned_baseline_performance.mp4', codec='libx264')\n",
    "\n",
    "Video(\"./videos/highway_fine_tuned_baseline_performance.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Model - Visual Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "\n",
    "model = DQN.load(\"./models/highway_dqn_fine_tuned_baseline\")\n",
    "highway_dqn_fine_tuned_baseline_frames = evaluate_model(env, model)\n",
    "\n",
    "# Specify the frame rate (frames per second)\n",
    "fps = 20\n",
    "\n",
    "# Create a video clip from the frames\n",
    "clip = ImageSequenceClip(highway_dqn_baseline_frames, fps=fps)\n",
    "clip.write_videofile('./videos/highway_fine_tuned_baseline_performance.mp4', codec='libx264')\n",
    "\n",
    "Video(\"./videos/highway_fine_tuned_baseline_performance.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the DQN Model\n",
    "\n",
    "Now that a baseline has been set, let's implement a custom version of the DQN algorithm from scratch using TensorFlow/Keras. A neural network model for approximating Q-values is built, as well as the necessary components of the DQN algorithm like the experience replay buffer and the target network update mechanism.\n",
    "\n",
    "The implementation is outlined as following:\n",
    "\n",
    "- Define the Q-Network using Keras.\n",
    "- Create the experience replay buffer.\n",
    "- Implement the epsilon-greedy policy for action selection.\n",
    "- Define the training procedure, which includes sampling from the buffer and updating the Q-Network.\n",
    "- Periodically update the target network weights.\n",
    "\n",
    "Below is a code snippet with a custom DQN using TensorFlow/Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# warnings.filterwarnings('ignore', category=UserWarning, message='.*tf.config.experimental_run_functions_eagerly*')\n",
    "tf.keras.utils.disable_interactive_logging()\n",
    "# tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# Define the Dueling DQN model\n",
    "class DuelingDQN(tf.keras.Model):\n",
    "    def __init__(self, input_shape, action_space):\n",
    "        super(DuelingDQN, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(256, activation='relu', input_shape=(input_shape,))\n",
    "        self.dense2 = tf.keras.layers.Dense(256, activation='relu')\n",
    "\n",
    "        # Value stream\n",
    "        self.value_dense = tf.keras.layers.Dense(128, activation='relu')\n",
    "        self.value = tf.keras.layers.Dense(1, activation='linear')\n",
    "\n",
    "        # Advantage stream\n",
    "        self.adv_dense = tf.keras.layers.Dense(128, activation='relu')\n",
    "        self.advantages = tf.keras.layers.Dense(action_space, activation='linear')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "\n",
    "        value_stream = self.value_dense(x)\n",
    "        value = self.value(value_stream)\n",
    "\n",
    "        adv_stream = self.adv_dense(x)\n",
    "        advantages = self.advantages(adv_stream)\n",
    "\n",
    "        # Combine streams into Q-values\n",
    "        q_values = value + (advantages - tf.reduce_mean(advantages, axis=1, keepdims=True))\n",
    "        return q_values\n",
    "\n",
    "class PERBuffer:\n",
    "    def __init__(self, buffer_size):\n",
    "        self.buffer = deque(maxlen=buffer_size)\n",
    "        self.priorities = tf.Variable(tf.ones((buffer_size,), dtype=tf.float32))\n",
    "        self.max_priority = tf.Variable(1.0, dtype=tf.float32)\n",
    "        self.buffer_size = buffer_size  # Store the buffer size for checks\n",
    "\n",
    "    def add(self, experience, error):\n",
    "        self.buffer.append(experience)\n",
    "        # Only update if there's enough room\n",
    "        index = len(self.buffer) - 1\n",
    "        if index < self.priorities.shape[0]:\n",
    "            self.priorities[index].assign(tf.maximum(self.priorities[index], error))\n",
    "        self.max_priority.assign(tf.maximum(self.max_priority, tf.reduce_max(self.priorities)))\n",
    "\n",
    "    def sample(self, batch_size, beta=0.4):\n",
    "        current_buffer_size = len(self.buffer)\n",
    "        if current_buffer_size < batch_size:\n",
    "            return None, None, None\n",
    "\n",
    "        probabilities = tf.nn.softmax(self.priorities[:current_buffer_size])\n",
    "        indices = tf.random.categorical(tf.math.log([probabilities]), batch_size)[0]\n",
    "        samples = [self.buffer[i] for i in indices.numpy()]  # Ensure you handle this outside tf.function\n",
    "\n",
    "        # Use tf.gather to index probabilities safely in TensorFlow\n",
    "        selected_probabilities = tf.gather(probabilities, indices)\n",
    "        weights = (current_buffer_size * selected_probabilities) ** (-beta)\n",
    "        weights /= tf.reduce_max(weights)\n",
    "        return samples, indices, weights\n",
    "\n",
    "    def update_priorities(self, indices, errors):\n",
    "        # Extract the indices for updating\n",
    "        indices_for_scatter = tf.expand_dims(indices[:, 0], 1)  # Ensure indices are correct for scatter update\n",
    "\n",
    "        # Compute the maximum between current priorities at the specified indices and the new errors\n",
    "        current_priorities = tf.gather(self.priorities, indices[:, 0])\n",
    "        new_priorities = tf.maximum(current_priorities, errors)\n",
    "\n",
    "        # Update priorities with the new maximum values\n",
    "        self.priorities.scatter_nd_update(indices_for_scatter, tf.reshape(new_priorities, [-1, 1]))\n",
    "\n",
    "        # Update the maximum priority value\n",
    "        self.max_priority.assign(tf.reduce_max(self.priorities))\n",
    "\n",
    "# Define the DQNAgent\n",
    "class DQNAgent:\n",
    "    def __init__(\n",
    "            self, \n",
    "            gym_env: gym.Env,\n",
    "            buffer_size=15000, \n",
    "            learning_rate=5e-4,\n",
    "            batch_size=32,\n",
    "            gamma=0.8,\n",
    "            epsilon: float = 1.0,\n",
    "            epsilon_min: float = 0.01,\n",
    "            epsilon_decay: float = 0.995,\n",
    "        ):\n",
    "        # Initialize and run the agent\n",
    "        self.gym_env = gym_env\n",
    "        action_space = self.gym_env.action_space.n\n",
    "        state_shape = self.gym_env.observation_space.shape\n",
    "        input_space = np.prod(state_shape)  # Flatten the state dimensions for input to the network\n",
    "        self.input_shape = input_space\n",
    "        self.action_space = action_space\n",
    "        self.memory = PERBuffer(buffer_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.model = DuelingDQN(input_space, action_space)\n",
    "        self.target_model = DuelingDQN(input_space, action_space)\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        self.average_loss = tf.keras.metrics.Mean(name='average_loss')\n",
    "\n",
    "    @tf.function\n",
    "    def act(self, state):\n",
    "        # Random action based on epsilon\n",
    "        if tf.random.uniform((), 0, 1) <= self.epsilon:\n",
    "            # tf.random.uniform returns a tf.int32, make sure to cast it if necessary\n",
    "            return tf.random.uniform((), 0, self.action_space, dtype=tf.int32)\n",
    "        else:\n",
    "            # Compute Q-values and use argmax to decide the best action\n",
    "            q_values = self.model(tf.reshape(state, (1, -1)))\n",
    "            return tf.cast(tf.argmax(q_values[0]), tf.int32)\n",
    "\n",
    "    @tf.function\n",
    "    def update_epsilon(self):\n",
    "        self.epsilon = tf.maximum(self.epsilon * self.epsilon_decay, self.epsilon_min)\n",
    "\n",
    "    @tf.function\n",
    "    def replay(self):\n",
    "        if len(self.memory.buffer) < self.batch_size:\n",
    "            return None\n",
    "\n",
    "        batch, indices, weights = self.memory.sample(self.batch_size)\n",
    "        states, actions, rewards, next_states, dones = map(tf.convert_to_tensor, zip(*batch))\n",
    "\n",
    "        states = tf.reshape(states, (self.batch_size, -1))\n",
    "        next_states = tf.reshape(next_states, (self.batch_size, -1))\n",
    "\n",
    "        current_q = self.model(states)\n",
    "        next_q = self.target_model(next_states)\n",
    "        max_next_q = tf.reduce_max(next_q, axis=1)\n",
    "\n",
    "        # Prepare indices for tensor updating\n",
    "        indices = tf.stack([tf.range(self.batch_size), actions], axis=1)\n",
    "\n",
    "        # Compute the updated Q-values for just the actions taken\n",
    "        updates = rewards + self.gamma * max_next_q * (1 - tf.cast(dones, tf.float32))\n",
    "\n",
    "        # Apply updates to the current Q-values\n",
    "        target_q = tf.tensor_scatter_nd_update(current_q, indices, updates)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            q_values = self.model(states)\n",
    "            action_q_values = tf.gather_nd(q_values, indices)\n",
    "\n",
    "            # Reshape weights to apply across all actions\n",
    "            weights = tf.reshape(weights, [-1, 1])  # Reshape weights to match the shape of [batch_size, 1]\n",
    "            loss = tf.reduce_mean(tf.square(target_q - q_values) * weights)  # Apply weights to all actions\n",
    "\n",
    "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "\n",
    "        errors = tf.abs(updates - action_q_values)\n",
    "        self.memory.update_priorities(indices, errors)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def train(self, episodes):\n",
    "        current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        log_dir = './logs/custom_dqn/' + current_time\n",
    "        summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "        for episode in range(episodes):  # Use Python's range to ensure eagerness\n",
    "            initial_state, _ = self.gym_env.reset()\n",
    "            state = tf.convert_to_tensor(initial_state, dtype=tf.float32)\n",
    "            state = tf.reshape(state, (1, -1))\n",
    "            done = truncated = False\n",
    "            total_reward = 0.0\n",
    "            steps = 0\n",
    "\n",
    "            while not (done or truncated):\n",
    "                action = self.get_action(state).numpy()  # Determine action inside a tf.function\n",
    "                next_state, reward, done, truncated, _ = self.gym_env.step(int(action))  # Step executed eagerly\n",
    "                next_state = tf.convert_to_tensor(next_state, dtype=tf.float32)\n",
    "                next_state = tf.reshape(next_state, (1, -1))\n",
    "\n",
    "                # Perform replay and update models\n",
    "                self.perform_replay(state, action, reward, next_state, done)\n",
    "\n",
    "                state = next_state\n",
    "                total_reward += reward\n",
    "                steps += 1\n",
    "\n",
    "            with summary_writer.as_default():\n",
    "                tf.summary.scalar('Total Reward', total_reward, step=episode)\n",
    "                tf.summary.scalar('Average Loss', self.average_loss.result(), step=episode)\n",
    "                tf.summary.scalar('Epsilon', self.epsilon, step=episode)\n",
    "            \n",
    "            summary_writer.flush()\n",
    "            self.average_loss.reset_state()\n",
    "\n",
    "            if episode % 10 == 0:\n",
    "                self.update_target_model()\n",
    "\n",
    "            print(f\"Episode {episode + 1}: Total Reward = {total_reward}, Steps = {steps}\")\n",
    "\n",
    "        summary_writer.close()\n",
    "\n",
    "    @tf.function\n",
    "    def get_action(self, state):\n",
    "        if tf.random.uniform((), 0, 1) < self.epsilon:\n",
    "            # Ensure the random action is cast to tf.int32\n",
    "            return tf.cast(tf.random.uniform((), minval=0, maxval=self.action_space, dtype=tf.int32), tf.int32)\n",
    "        else:\n",
    "            # Compute Q-values and use argmax to decide the best action, ensuring it is also tf.int32\n",
    "            q_values = self.model(tf.reshape(state, (1, -1)))\n",
    "            return tf.cast(tf.argmax(q_values[0], axis=0), tf.int32)\n",
    "\n",
    "    @tf.function\n",
    "    def perform_replay(self, state, action, reward, next_state, done):\n",
    "        self.memory.add((state, action, reward, next_state, done), self.compute_error(state, action, reward, next_state, done))\n",
    "        loss = self.replay()\n",
    "        if loss is not None:\n",
    "            self.average_loss.update_state(loss)\n",
    "\n",
    "    @tf.function\n",
    "    def compute_error(self, state, action, reward, next_state, done):\n",
    "        # Cast reward and done to float32 to ensure type consistency in calculations\n",
    "        reward = tf.cast(reward, tf.float32)\n",
    "        done = tf.cast(done, tf.float32)\n",
    "        \n",
    "        # Make sure that gamma is a float32\n",
    "        gamma = tf.constant(self.gamma, dtype=tf.float32)\n",
    "        \n",
    "        current_q = self.model(state)\n",
    "        next_q = self.target_model(next_state)\n",
    "        \n",
    "        # Compute the target Q-value\n",
    "        target_q_value = reward + gamma * tf.reduce_max(next_q) * (1. - done)\n",
    "        \n",
    "        # Error calculation\n",
    "        error = tf.abs(current_q[0, tf.cast(action, tf.int32)] - target_q_value)\n",
    "        return error\n",
    "\n",
    "    @tf.function\n",
    "    def update_target_model(self):\n",
    "        # Iterate through each variable in the model and target model and assign values directly\n",
    "        for var, target_var in zip(self.model.variables, self.target_model.variables):\n",
    "            target_var.assign(var)\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def predict(self, state):\n",
    "        state = tf.reshape(state, (1, -1))\n",
    "        return self.model.predict(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the custom DQN Model\n",
    "\n",
    "Before we proceed, initialize your model by specifying the input shape and the number of actions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leone/msc/reinforcement-learning/rl_graded_assessment_2/rl-project/.venv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Initialize DQN Agent\n",
    "env.reset()\n",
    "\n",
    "agent = DQNAgent(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the custom DQN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function DQNAgent.perform_replay at 0x338a6a480> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 17 calls to <function DQNAgent.perform_replay at 0x338a6a480> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Episode 1: Total Reward = 4.479491619856836, Steps = 6\n",
      "Episode 2: Total Reward = 4.613000696801617, Steps = 6\n",
      "Episode 3: Total Reward = 7.920176834358118, Steps = 12\n",
      "Episode 4: Total Reward = 2.7123784952428065, Steps = 4\n",
      "Episode 5: Total Reward = 1.68559670781893, Steps = 3\n",
      "Episode 6: Total Reward = 4.317208433833329, Steps = 6\n",
      "Episode 7: Total Reward = 11.916488999630332, Steps = 15\n",
      "Episode 8: Total Reward = 7.868390369315922, Steps = 10\n",
      "Episode 9: Total Reward = 22.18594729317034, Steps = 30\n",
      "Episode 10: Total Reward = 22.29411669069017, Steps = 27\n",
      "Episode 11: Total Reward = 7.153000385157263, Steps = 10\n",
      "Episode 12: Total Reward = 2.5175582990397807, Steps = 4\n",
      "Episode 13: Total Reward = 16.64969721359059, Steps = 24\n",
      "Episode 14: Total Reward = 3.7452032460743023, Steps = 5\n",
      "Episode 15: Total Reward = 3.331026409628295, Steps = 5\n",
      "Episode 16: Total Reward = 7.484987457791448, Steps = 10\n",
      "Episode 17: Total Reward = 1.9463340301349508, Steps = 3\n",
      "Episode 18: Total Reward = 9.619252494761122, Steps = 14\n",
      "Episode 19: Total Reward = 12.019558683606625, Steps = 16\n",
      "Episode 20: Total Reward = 10.080273768527892, Steps = 14\n",
      "Episode 21: Total Reward = 6.352374860989187, Steps = 8\n",
      "Episode 22: Total Reward = 7.611335614678771, Steps = 10\n",
      "Episode 23: Total Reward = 19.929701344318634, Steps = 24\n",
      "Episode 24: Total Reward = 2.450268145806649, Steps = 4\n",
      "Episode 25: Total Reward = 1.1310211293445556, Steps = 2\n",
      "Episode 26: Total Reward = 5.665174544030977, Steps = 8\n",
      "Episode 27: Total Reward = 19.050899003207878, Steps = 25\n",
      "Episode 28: Total Reward = 1.9859680881823618, Steps = 3\n",
      "Episode 29: Total Reward = 2.046796163638108, Steps = 3\n",
      "Episode 30: Total Reward = 6.110864611975196, Steps = 8\n",
      "Episode 31: Total Reward = 10.564235661839135, Steps = 15\n",
      "Episode 32: Total Reward = 5.363382314892505, Steps = 7\n",
      "Episode 33: Total Reward = 24.616858514583832, Steps = 30\n",
      "Episode 34: Total Reward = 5.86701045261681, Steps = 8\n",
      "Episode 35: Total Reward = 1.765378591649179, Steps = 3\n",
      "Episode 36: Total Reward = 4.3478642985464475, Steps = 6\n",
      "Episode 37: Total Reward = 10.977097829637872, Steps = 13\n",
      "Episode 38: Total Reward = 8.910522930257867, Steps = 11\n",
      "Episode 39: Total Reward = 9.79908231637003, Steps = 14\n",
      "Episode 40: Total Reward = 7.231984912645851, Steps = 9\n",
      "Episode 41: Total Reward = 3.315775034293553, Steps = 5\n",
      "Episode 42: Total Reward = 7.866348527409231, Steps = 11\n",
      "Episode 43: Total Reward = 9.595729734281417, Steps = 13\n",
      "Episode 44: Total Reward = 4.563085322685813, Steps = 6\n",
      "Episode 45: Total Reward = 2.812378495242806, Steps = 4\n",
      "Episode 46: Total Reward = 4.278860356980178, Steps = 5\n",
      "Episode 47: Total Reward = 13.06664451994409, Steps = 16\n",
      "Episode 48: Total Reward = 1.2130006968016176, Steps = 2\n",
      "Episode 49: Total Reward = 13.329913338981948, Steps = 16\n",
      "Episode 50: Total Reward = 14.975838031204505, Steps = 19\n",
      "Episode 51: Total Reward = 5.1201802710803666, Steps = 8\n",
      "Episode 52: Total Reward = 9.219018722811027, Steps = 12\n",
      "Episode 53: Total Reward = 4.032131296452061, Steps = 6\n",
      "Episode 54: Total Reward = 21.418630283760905, Steps = 30\n",
      "Episode 55: Total Reward = 9.032093679938658, Steps = 12\n",
      "Episode 56: Total Reward = 23.352773672148874, Steps = 30\n",
      "Episode 57: Total Reward = 2.450268907689913, Steps = 4\n",
      "Episode 58: Total Reward = 6.119028848717804, Steps = 9\n",
      "Episode 59: Total Reward = 2.0675007371641616, Steps = 3\n",
      "Episode 60: Total Reward = 10.38532769734853, Steps = 15\n",
      "Episode 61: Total Reward = 12.518218390350963, Steps = 16\n",
      "Episode 62: Total Reward = 21.684389030205736, Steps = 30\n",
      "Episode 63: Total Reward = 10.811956306086683, Steps = 14\n",
      "Episode 64: Total Reward = 1.8151527517185957, Steps = 3\n",
      "Episode 65: Total Reward = 6.1863852978647165, Steps = 9\n",
      "Episode 66: Total Reward = 9.96459243492841, Steps = 14\n",
      "Episode 67: Total Reward = 5.580944341990045, Steps = 8\n",
      "Episode 68: Total Reward = 1.8675007371641619, Steps = 3\n",
      "Episode 69: Total Reward = 11.710716513337259, Steps = 15\n",
      "Episode 70: Total Reward = 3.286497072540582, Steps = 5\n",
      "Episode 71: Total Reward = 15.431514901425446, Steps = 21\n",
      "Episode 72: Total Reward = 18.651102405350567, Steps = 27\n",
      "Episode 73: Total Reward = 24.277285322653857, Steps = 30\n",
      "Episode 74: Total Reward = 15.842923385907353, Steps = 21\n",
      "Episode 75: Total Reward = 7.213468019020316, Steps = 9\n",
      "Episode 76: Total Reward = 3.31693557435658, Steps = 5\n",
      "Episode 77: Total Reward = 4.411869912740969, Steps = 6\n",
      "Episode 78: Total Reward = 6.5654944399421575, Steps = 9\n",
      "Episode 79: Total Reward = 11.78073487920185, Steps = 15\n",
      "Episode 80: Total Reward = 7.617604358177872, Steps = 10\n",
      "Episode 81: Total Reward = 4.046380700684954, Steps = 6\n",
      "Episode 82: Total Reward = 23.764073516544503, Steps = 30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepisodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[70], line 189\u001b[0m, in \u001b[0;36mDQNAgent.train\u001b[0;34m(self, episodes)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (done \u001b[38;5;129;01mor\u001b[39;00m truncated):\n\u001b[1;32m    188\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_action(state)\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# Determine action inside a tf.function\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m     next_state, reward, done, truncated, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgym_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Step executed eagerly\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     next_state \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(next_state, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    191\u001b[0m     next_state \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(next_state, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/msc/reinforcement-learning/rl_graded_assessment_2/rl-project/.venv/lib/python3.11/site-packages/gymnasium/wrappers/order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/msc/reinforcement-learning/rl_graded_assessment_2/rl-project/.venv/lib/python3.11/site-packages/gymnasium/wrappers/env_checker.py:51\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/msc/reinforcement-learning/rl_graded_assessment_2/rl-project/.venv/lib/python3.11/site-packages/highway_env/envs/common/abstract.py:237\u001b[0m, in \u001b[0;36mAbstractEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolicy_frequency\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulate(action)\n\u001b[0;32m--> 237\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reward(action)\n\u001b[1;32m    239\u001b[0m terminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_terminated()\n",
      "File \u001b[0;32m~/msc/reinforcement-learning/rl_graded_assessment_2/rl-project/.venv/lib/python3.11/site-packages/highway_env/envs/common/observation.py:229\u001b[0m, in \u001b[0;36mKinematicObservation.observe\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39mrows, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures)], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# Reorder\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    230\u001b[0m obs \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morder \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshuffled\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/msc/reinforcement-learning/rl_graded_assessment_2/rl-project/.venv/lib/python3.11/site-packages/pandas/core/frame.py:4117\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(indexer, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m   4115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice(indexer, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 4117\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_single_key:\n\u001b[1;32m   4120\u001b[0m     \u001b[38;5;66;03m# What does looking for a single key in a non-unique index return?\u001b[39;00m\n\u001b[1;32m   4121\u001b[0m     \u001b[38;5;66;03m# The behavior is inconsistent. It returns a Series, except when\u001b[39;00m\n\u001b[1;32m   4122\u001b[0m     \u001b[38;5;66;03m# - the key itself is repeated (test on data.shape, #9519), or\u001b[39;00m\n\u001b[1;32m   4123\u001b[0m     \u001b[38;5;66;03m# - we have a MultiIndex on columns (test on self.columns, #21309)\u001b[39;00m\n\u001b[1;32m   4124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n\u001b[1;32m   4125\u001b[0m         \u001b[38;5;66;03m# GH#26490 using data[key] can cause RecursionError\u001b[39;00m\n",
      "File \u001b[0;32m~/msc/reinforcement-learning/rl_graded_assessment_2/rl-project/.venv/lib/python3.11/site-packages/pandas/core/generic.py:4153\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   4142\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   4143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   4144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4145\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   4146\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4151\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   4152\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4153\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4154\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[1;32m   4155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[0;32m~/msc/reinforcement-learning/rl_graded_assessment_2/rl-project/.venv/lib/python3.11/site-packages/pandas/core/generic.py:4133\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4128\u001b[0m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[1;32m   4129\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[1;32m   4130\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[1;32m   4131\u001b[0m     )\n\u001b[0;32m-> 4133\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4135\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4139\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4140\u001b[0m )\n",
      "File \u001b[0;32m~/msc/reinforcement-learning/rl_graded_assessment_2/rl-project/.venv/lib/python3.11/site-packages/pandas/core/internals/managers.py:894\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[1;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/msc/reinforcement-learning/rl_graded_assessment_2/rl-project/.venv/lib/python3.11/site-packages/pandas/core/internals/managers.py:680\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested axis not found in manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_slice_take_blocks_ax0\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_slice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_slice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_proxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_proxy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    688\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[1;32m    689\u001b[0m             indexer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[1;32m    696\u001b[0m     ]\n",
      "File \u001b[0;32m~/msc/reinforcement-learning/rl_graded_assessment_2/rl-project/.venv/lib/python3.11/site-packages/pandas/core/internals/managers.py:843\u001b[0m, in \u001b[0;36mBaseBlockManager._slice_take_blocks_ax0\u001b[0;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy, ref_inplace_op)\u001b[0m\n\u001b[1;32m    841\u001b[0m                     blocks\u001b[38;5;241m.\u001b[39mappend(nb)\n\u001b[1;32m    842\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 843\u001b[0m                 nb \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_mgr_locs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmgr_locs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m                 blocks\u001b[38;5;241m.\u001b[39mappend(nb)\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m blocks\n",
      "File \u001b[0;32m~/msc/reinforcement-learning/rl_graded_assessment_2/rl-project/.venv/lib/python3.11/site-packages/pandas/core/internals/blocks.py:1307\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m   1304\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[0;32m-> 1307\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[0;32m~/msc/reinforcement-learning/rl_graded_assessment_2/rl-project/.venv/lib/python3.11/site-packages/pandas/core/array_algos/take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[1;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/msc/reinforcement-learning/rl_graded_assessment_2/rl-project/.venv/lib/python3.11/site-packages/pandas/core/array_algos/take.py:147\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    143\u001b[0m     axis \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m axis \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# at this point, it's guaranteed that dtype can hold both the arr values\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# and the fill_value\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m out_shape_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(arr\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    148\u001b[0m out_shape_[axis] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer)\n\u001b[1;32m    149\u001b[0m out_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(out_shape_)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent.train(episodes=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom model - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 27885), started 0:00:02 ago. (Use '!kill 27885' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-194bea67c63e9ef8\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-194bea67c63e9ef8\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%reload_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir ./logs/custom_dqn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e4714ee739adca912176564b3eb00229",
     "grade": false,
     "grade_id": "cell-30ac99abe97e62b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Atari Space Invaders Implementation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cf70e6e3c9fe761473c11366c91f40ff",
     "grade": false,
     "grade_id": "cell-b42bead8118e3c9e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As you can see, `reset()` has returned a valid initial state as a four-tuple. The function `plot()` uses the same colour-scheme as described above, but also includes a yellow grid-square to indicate the current position of the agent.\n",
    "\n",
    "Let's make the agent go upward by using `step(1)`, then inspect the result (recall that action `1` increments the agent's vertical speed while leaving the agent's horizontal speed unchanged)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results: A presentation of your results, showing how quickly and how well your agent(s) learn (i.e., improve their policies). Include informative baselines for comparison (e.g. the best possible performance, the performance of an average human, or the performance of an agent that selects actions randomly).\n",
    "\n",
    "Discussion: An evaluation of how well you solved your chosen problem.\n",
    "\n",
    "Future work: A discussion of potential future work you would complete if you had more time.\n",
    "Personal experience: A discussion of your personal experience with the project, such as difficulties or pleasant surprises you encountered while completing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A. A., Veness, J., Bellemare, M. G. & De Freitas, N. (2015). Human-level control through deep reinforcement learning. Nature, 518(7540), 529-533.\n",
    "\n",
    "Oudeyer, P. Y., & Kaplan, F. (2007). Intrinsic motivation systems for autonomous mental development. IEEE Transactions on Evolutionary Computation, 11(1), 26-50.\n",
    "\n",
    "Schaul, T., Hung, A., Pi-Chang, H., & Sutskever, I. (2015, December). Prioritized experience replay. In Advances in neural information processing systems (pp. 4662-4670).\n",
    "\n",
    "Wang, Z., Schaul, T., Hessel, M., Van Hasselt, H., & Wierstra, D. (2016). Dueling network architectures for deep reinforcement learning. In International conference on machine learning (pp. 1994-2003).\n",
    "\n",
    "\n",
    "- Mnih, V. et al. (2015). Human-level control through deep reinforcement learning. *Nature*, 518(7540), 529-533.\n",
    "- Schulman, J., et al. (2015). Trust Region Policy Optimization. *International Conference on Machine Learning (ICML)*.\n",
    "- Schulman, J., et al. (2017). Proximal Policy Optimization Algorithms. *arXiv preprint arXiv:1707.06347*.\n",
    "- Dosovitskiy, A. et al. (2017). Learning to act by predicting the future. *International Conference on Learning Representations (ICLR)*.\n",
    "- Liang, X., et al. (2018). Deep Reinforcement Learning for Autonomous Driving. *Machine Learning Systems Workshop at NeurIPS*.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
