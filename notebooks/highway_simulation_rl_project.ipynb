{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b48b6a92d8d88e15753faba58c47bae2",
     "grade": false,
     "grade_id": "cell-b0b3b6b4f891b031",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Reinforcement Learning\n",
    "## Graded Assessment: RL Project\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Definition\n",
    "\n",
    "For this reinforcement learning project, the challenge involves developing an RL agent that can proficiently navigate the HighwayEnv, a minimalist simulation environment tailored for autonomous driving decision-making. The primary objective is to construct an RL agent capable of effectively managing the simulated traffic dynamics of HighwayEnv, and subsequently, to benchmark its performance against a pre-existing agent implemented via the [Stable Baselines3](https://github.com/DLR-RM/stable-baselines3) library.\n",
    "\n",
    "### Environment Description\n",
    "**HighwayEnv** simulates the complex scenario where autonomous vehicles are required to navigate traffic on a multi-lane highway. The overarching goal for these agents includes optimizing travel time, executing safe lane changes, maintaining appropriate speeds, and adhering to traffic regulations to avoid collisions.\n",
    "\n",
    "### State Space (Observations)\n",
    "The state space comprises:\n",
    "- **Position and Velocity of the Agent Vehicle:** Longitudinal and lateral positions and velocities are critical for determining the agent's current and projected states.\n",
    "- **Position and Velocity of Other Vehicles:** The relative positions and velocities of nearby vehicles are essential for spatial awareness and collision avoidance.\n",
    "- **Road Geometry:** This includes the number of lanes and lane markings, which are crucial for proper lane adherence and navigation.\n",
    "\n",
    "### Action Space\n",
    "The agent can take several discrete actions:\n",
    "- **Accelerate:** Increase the vehicle's speed.\n",
    "- **Decelerate:** Reduce the vehicle's speed.\n",
    "- **Change Lane to the Left/Right:** Shift to an adjacent left or right lane if it is safe and possible.\n",
    "- **Maintain Current State:** Continue with the present speed and lane.\n",
    "\n",
    "### Transition Dynamics\n",
    "The dynamics of this environment are governed by both the physical laws of vehicle motion and the programmed behavior of other simulated vehicles, which follow basic traffic rules and patterns of lane adherence.\n",
    "\n",
    "### Reward Function\n",
    "The reward system is designed to promote safety, efficiency, comfort, and lane adherence:\n",
    "- **Safety:** Imposes penalties for near-misses and collisions.\n",
    "- **Efficiency:** Rewards are given for maintaining optimal speeds and minimizing travel time to goals.\n",
    "- **Comfort:** Discourages excessive and abrupt vehicular maneuvers.\n",
    "- **Lane Adherence:** Encourages maintaining lane discipline unless overtaking or avoiding an obstacle.\n",
    "\n",
    "### Hypothesis\n",
    "The hypothesis to be tested is whether a custom-implemented Deep Q-Network (DQN) can outperform an established RL agent from the Stable Baselines3 library in terms of cumulative rewards. This will be measured through the agent’s ability to adapt to varying traffic densities and complexities, ensuring both efficient and safe navigation.\n",
    "\n",
    "### Objectives for the DQN Implementation\n",
    "The project aims to implement a DQN that learns an optimal policy based on the defined state and action spaces, adhering to the specified transition dynamics and reward structure. The key objectives for the DQN agent include:\n",
    "- Efficiently navigating through traffic without predefined rules for specific situations.\n",
    "- Developing a balanced driving policy that optimizes speed, safety, and comfort.\n",
    "- Demonstrating superior adaptability and performance in diverse traffic scenarios when compared to the existing solution.\n",
    "\n",
    "This structured approach lays the groundwork for developing and evaluating the reinforcement learning model, focusing on fostering an autonomous driving strategy that can effectively operate within the realistic confines of highway traffic conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Reinforcement Learning (RL) has emerged as a powerful method for solving decision-making problems where an agent learns to act in an environment by performing actions and receiving feedback through rewards. In the context of autonomous driving, particularly in complex environments like those simulated by HighwayEnv, RL can be leveraged to enable vehicles to make intelligent decisions dynamically.\n",
    "\n",
    "**Deep Q-Networks (DQN)**, introduced by Mnih et al. (2015), have been pivotal in applying RL to environments with high-dimensional state spaces, such as video games and, relevantly, driving simulations (Mnih et al., 2015). DQN integrates deep neural networks with Q-learning, where the network approximates the Q-value function. The Q-value function quantifies the expected utility of taking a given action in a particular state, followed by following a certain policy. **Strengths** of DQN include its ability to handle environments with large state and action spaces and its robustness in learning stable policies in complex scenarios. However, **weaknesses** include its sample inefficiency—often requiring numerous interactions with the environment, which can be computationally expensive—and its tendency to overestimate Q-values leading to suboptimal policy decisions.\n",
    "\n",
    "**Proximal Policy Optimization (PPO)** and **Trust Region Policy Optimization (TRPO)** are policy gradient methods that optimize the policy directly. These methods are noted for their stability and efficiency, which come from limiting the steps in policy space to avoid destructive large updates (Schulman et al., 2015; 2017). For autonomous driving, the **strength** of these methods lies in their continuous action space handling, making them suitable for controlling the nuanced actions of a vehicle. The **weakness**, however, is that they can be sensitive to hyperparameter settings and require careful tuning to achieve the best performance.\n",
    "\n",
    "In autonomous driving simulations like those provided by HighwayEnv, several studies have demonstrated the effectiveness of these methods. For example, RL has been used to successfully navigate complex traffic scenarios, demonstrating significant potential in achieving human-like driving capabilities (Dosovitskiy et al., 2017). These environments often simulate realistic traffic conditions and provide a benchmark for evaluating different RL methods, including DQN and PPO, in terms of their ability to learn safe and efficient driving policies.\n",
    "\n",
    "Comparative studies, such as those by Liang et al. (2018), have shown that while DQN can effectively learn policy for discrete action spaces in driving simulations, methods like PPO tend to outperform in terms of achieving smoother control and handling continuous action spaces, which are critical in real-world driving scenarios.\n",
    "\n",
    "In summary, reinforcement learning offers significant promise for developing intelligent autonomous driving systems capable of operating in complex, dynamic environments. Both value-based methods like DQN and policy-based methods like PPO have their merits and limitations, making them suitable for different aspects of the driving problem. Continuous advancements in RL methods and computational resources are likely to further enhance their applicability and performance in autonomous driving tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up the Highway Environment\n",
    "\n",
    "The highway-env environment introduces an exciting domain focused on autonomous driving and decision-making in traffic scenarios. This environment is designed for experimenting with various aspects of vehicle behavior, such as lane following, overtaking, and navigating through intersections, making it rich in learning opportunities for reinforcement learning applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAACsCAYAAABRs1diAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAaYUlEQVR4nO3de3BU9d3H8c9ukt0Eks0SgYRAAlFARC6tXGKqTm3JNF6KWmkLNK1UGRmVWBGsA3UEbDvGaX1aq0WZajV1xorQFrRWMzJBQTREjFBANCY+qQlCEiHmRi6bZH/PHzzu9JiI2XXJniXv18zOsN/zy5ff/nbZfDh7zh6HMcYIAADARpyRngAAAMDnEVAAAIDtEFAAAIDtEFAAAIDtEFAAAIDtEFAAAIDtEFAAAIDtEFAAAIDtEFAAAIDtEFAAAIDtRDSgbNiwQRMmTFB8fLyys7P11ltvRXI6AADAJiIWUJ577jmtXLlS69at0zvvvKOZM2cqLy9PDQ0NkZoSAACwCUekLhaYnZ2tOXPm6I9//KMkye/3KyMjQ7fffrtWr1592p/1+/06evSokpKS5HA4BmO6AADgKzLGqLW1Venp6XI6T7+PJHaQ5mTh8/lUXl6uNWvWBGpOp1O5ubkqLS3tM76rq0tdXV2B+x9//LGmTp06KHMFAADhVVtbq3Hjxp12TEQCyvHjx9Xb26vU1FRLPTU1Ve+//36f8YWFhbrvvvv61BctWiSXy3XG5gkAAMLH5/Np06ZNSkpK+tKxEQkowVqzZo1WrlwZuN/S0qKMjAy5XC4CCgAAUWYgh2dEJKCMHDlSMTExqq+vt9Tr6+uVlpbWZ7zb7Zbb7R6s6QEAgAiLyFk8LpdLs2bNUklJSaDm9/tVUlKinJycSEwJAADYSMQ+4lm5cqWWLFmi2bNna+7cuXrooYd08uRJ3XjjjZGaEgAAsImIBZSFCxfqk08+0dq1a1VXV6evfe1rKi4u7nPgLAAAGHoiepBsQUGBCgoKIjkFAABgQ1yLBwAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2E5UXCzwi0yfPl0JCQmRngYAABiAjo6OAY+N6oAyduxYDRs2LNLTAAAAA9De3j7gsVEdUIqLi+VyuSI9DQAAMAA+n2/AYzkGBQAA2E5U70EBAAyMMUbd3d1npHdsbKycTv6/G4zu7m4ZY8LeNyYmRjExMWHvGwkEFAAYAowx+s/HdRo28aKw9HPGSEkeqbm6WiO6uzV8+PCw9B0qampr5Z40N2z9PCOkzsZGORsaNHLkyLD1jSQCCgAMEbHe0Rp3Y2FYernjpSkzpf0bNqj9jTfC0nMocTicGrvk13I4w7O3Y8Yc6eibu/X+//xPWPrZAfvkAACIhPB/wnNWYQ8KACBoXV3S4X3SiQaJb6OKvPf+LbX8b6RnEV7sQQEABM9I3T7J3xvpiUA69Vz0nJljoCOGgAIACJrTeerATFd8pGcCSfJ4pWGJkZ5FeBFQAABBi3NJWZOl5BGRnkkUc4Sv1YRJUurY8PWzAwIKAACRwEGyp8VBsgAwRHQfP6IP7/9BWHo5HFJVnORrbVVaSkpYeg4pxq//fWBR2Pai1Lqk3q4uJZ4lX9ImEVAAYEhwOByaPPG88DdOTg5/zyEgKysr0lOwPQIKAAwBDkcYD3jAV8bz8eU4BgUAANgOAQUAANhOVH/E43Q6g76Cpt/v/8JeoRiMfqH2Msb0uVqmw+EIeddiOPv110s6O58Hu/cbjOfVzq8TuzwP4e5n5/e6cD+v4X6v6++xhrufHZ6HL+p3Jl/DwfR2mDNxveczrKWlRcnJyfrggw+UlJQU1M/ed9996unpsdS8Xq9WrVoV9Dza29tVWNj3wluTJ0/WT37yk6D7ffTRR3riiScstYkTJ2rJkiVB95KksrIyvfjii5bapZdeqry8vJD6bdu2TeXl5ZbaD3/4Q02fPj3oXi+88IL27t3bp15QUKDU1NSg+/3pT39SbW1tn/ratWsVFxcXdL/7779fHR0dltq9994rl8sVdK/u7m798pe/tNTi4+N1zz33BN1Lkurq6rRhwwZLLSMjQ8uWLQup34EDB7RlyxZLbfbs2br22muD7nXo0CE999xzferXXHON5syZE3S/7du3a9euXX3qN998szIzM4Pu9/TTT6uystJSW7p0qSZMmBB0L0l68MEH1dzcbKmtXr06pCv7+v1+rV+/3vKLNjY2VuvWrQu6lzFG69ev7/PLYtSoUfrZz34WdL/m5mY9+OCDferTpk3TwoULg+5XVVWlv/zlL5ba1KlTtXjx4qB7SdLrr7+uV155xVKbN2+eLr/88pD6bd68WQcPHrTUfvzjH+v8888Pqd8jjzyihoYGS+3OO+9USghnP23YsEF1dXWWmsPh0Pr160MKFr/61a/k8/ksvdatW6eYEM4G6ujo0P3332+pJSUl6e677w7cb21t1eTJk9Xc3CyPx3PaflEdUG644YaQfmEAAIDB5/P59PTTTw8ooHAMCgAAsB0CCgAAsJ2wB5T169cHDib67DZlypTA9s7OTi1fvlznnHOOEhMTtWDBAtXX14d7GgAAIIqdkT0oF154oY4dOxa47d69O7Dtzjvv1D//+U9t2bJFO3fu1NGjR3X99defiWkAAIAodUZOM46NjVVaWlqfenNzs/785z/rr3/9q7797W9Lkp566ildcMEF2rNnjy6++OIzMR0AABBlzsgelMrKSqWnp+vcc89Vfn6+ampqJEnl5eXq7u5Wbm5uYOyUKVOUmZmp0tLSL+zX1dWllpYWyw0AAJy9wh5QsrOzVVRUpOLiYj322GOqrq7WZZddptbWVtXV1cnlcsnr9Vp+JjU1tc953f+tsLBQycnJgVtGRka4pw0AAGwk7B/xXHnllYE/z5gxQ9nZ2Ro/frw2b96shISEkHquWbNGK1euDNxvaWkhpAAAcBY746cZe71eTZ48WVVVVUpLS5PP51NTU5NlTH19fb/HrHzG7XbL4/FYbgAA4Ox1xgNKW1ubPvzwQ40ZM0azZs1SXFycSkpKAtsrKipUU1OjnJycMz0VAAAQJcL+Ec9dd92l+fPna/z48Tp69GjgO/0XL16s5ORkLV26VCtXrlRKSoo8Ho9uv/125eTkcAYPAAAICHtAOXLkiBYvXqwTJ05o1KhRuvTSS7Vnzx6NGjVKkvT73/9eTqdTCxYsUFdXl/Ly8vToo4+GexoAACCKcbFAAAAwKLhYIAAAiGoEFAAAYDsEFAAAYDtRfQzKG2+8ocTExAH/nDFGGzduVE9Pj6WelJSkn/70p0HPo6OjQ0888USf+oQJEzR//vyg+x09elR///vfLbXMzExde+21QfeSpAMHDmjnzp2W2kUXXaRLLrkkpH4lJSU6fPiwpZaXl6fJkycH3evVV1/VoUOH+tR/9KMf6Zxzzgm635YtW/r9NuJbb71VsbHBHwv++OOPq7Oz01K75ZZbFBcXF3Sv7u5ubdy40VJzu91atmxZ0L0k6fjx43r22WcttbS0NP3gBz8IqV9FRYVeeeUVS+3CCy8MXC8rGJWVlSouLu5Tv/zyyzV9+vSg+7355psqLy/vU//+97+vMWPGBN3vhRde0EcffWSpXX/99Ro7dmzQvSSpqKhIra2tltrSpUs1bNiwoHv5/X49+uij+u+35JiYGN16661yOBxB9TLG6NFHH5Xf77fUU1JSlJ+fH/TcWltbVVRU1Kc+ceJEy5dzDlRNTY2ef/55S+28887TVVddFXQv6dRlVN58801LLTs7W3Pnzg2pX3FxsSorKy217373u8rKygqp3zPPPKPGxkZL7YYbblBycnLQvZ599lkdP37cUnM4HLrtttvkdAa/z2Hjxo3q7u621G677TbFxMQE3auzs1OPP/64pTZ8+HDddNNNgfttbW265JJLBnQMSlQHlBUrVsjtdgf1sydOnOhTczqdGjFiRNDz8Pv9+vTTT/vU4+LiQvoyue7u7j7XGQq1l3TqxXLy5ElLLT4+XsOHDw+pX1tbm7q6uiy1xMTEoJ+DL+olScnJySEFiubm5j7BUzr1hhzsm7skNTY26vP/NELtZYzp8+bkcDiUkpISdC9J6unpUXNzs6UWGxsb0puddOpaV21tbZaa2+0OKvyfrpd06k0qPj4+6H7t7e3q6OjoU/d4PCGFxZaWlj5vxqH2kqRPP/20TwgYMWJESL8o+nudSAopsH9Rr5iYmD6XGhmIL3qvc7lcSkpKCrqfz+frE+xC7SWd+s9ie3u7pZaQkBBSUJROBTKfz2epJSUlhXxSRlNTk3p7ey01r9cbUgjor5cU+vtTf78TQ+3V3+vk8+91XV1deuihh87+gMJZPAAARA/O4gEAAFEt7F/UBthBa2trn2NIwiEuLi6kXeRDTVNTU5+PUsIhPj4+5I8BAEQXAgrOSm1tbfrkW+/InxKekJI0XorpjZXjt18joAxAS0uLkq9bpZj44I9j6U/meVLnJ8dU9eSTBBRgiCCg4KzVe26LTPrJLx84ADHTpJjuWPm/fCj+3/BJcxSbFPzB5/1J+7p0sqZKVWHpBiAaEFCAAej1SQ7fl4/DmeHrknysPzCkEFCAAWj+QFKbFPwJnwiHqsNS59FIzwLAYOIsHgAAYDvsQQEGIGm85Oz7vXIYJBnnSe0uqe9XjwE4WxFQgAGIS5Ji4sVBshGS5JGcnLwDDCkEFJy1HE0uydX3K6FDYY5Kpod/LsHo/vSY/F3hOYvq5FGpvaEhLL0ARAfecXFWcrvdGrk5O/x9hwV/3aGhKCEhQSeeXBW2fp9Fk1CvrQIg+hBQcFZKSUkJ+WJ8+OpGjRoV6SkAiHKcxQMAAGyHgAIAAGyHgAIAAGwnqo9BmT59uhISEiI9DQAAMAAdHR0DHhvVAWXs2LEc1Q8AQJRob28f8NioDijFxcVyuVyRngYAABgAXxBX/eQYFAAAYDsEFAAAYDsEFAAAYDsEFAAAYDsEFAAAYDsEFAAAYDsEFAAAYDtBB5Rdu3Zp/vz5Sk9Pl8Ph0LZt2yzbjTFau3atxowZo4SEBOXm5qqystIyprGxUfn5+fJ4PPJ6vVq6dKna2tq+0gMBAABnj6ADysmTJzVz5kxt2LCh3+2/+c1v9PDDD2vjxo0qKyvT8OHDlZeXp87OzsCY/Px8vfvuu9q+fbtefPFF7dq1S8uWLQv9UQAAgLOKwxhjQv5hh0Nbt27VddddJ+nU3pP09HStWrVKd911lySpublZqampKioq0qJFi/Tee+9p6tSp2rt3r2bPni3p1DfCXnXVVTpy5IjS09P7/D1dXV3q6uoK3G9paVFGRoZuuOEGvkkWAIAo4fP59PTTT6u5uVkej+e0Y8N6DEp1dbXq6uqUm5sbqCUnJys7O1ulpaWSpNLSUnm93kA4kaTc3Fw5nU6VlZX127ewsFDJycmBW0ZGRjinDQAAbCasAaWurk6SlJqaaqmnpqYGttXV1Wn06NGW7bGxsUpJSQmM+bw1a9aoubk5cKutrQ3ntAEAgM1ExcUC3W633G53pKcBAAAGSVj3oKSlpUmS6uvrLfX6+vrAtrS0NDU0NFi29/T0qLGxMTAGAAAMbWENKFlZWUpLS1NJSUmg1tLSorKyMuXk5EiScnJy1NTUpPLy8sCYHTt2yO/3Kzs7O5zTAQAAUSroj3ja2tpUVVUVuF9dXa39+/crJSVFmZmZWrFihX79619r0qRJysrK0r333qv09PTAmT4XXHCBrrjiCt18883auHGjuru7VVBQoEWLFvV7Bg8AABh6gg4ob7/9tr71rW8F7q9cuVKStGTJEhUVFenuu+/WyZMntWzZMjU1NenSSy9VcXGx4uPjAz/zzDPPqKCgQPPmzZPT6dSCBQv08MMPh+HhAACAs8FX+h6USGlpaVFycjLfgwIAQBSJ2PegAAAAhAMBBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2A4BBQAA2E5spCcQCmOMJMnn80V4JgAAYKA++7392e/x03GYgYyymSNHjigjIyPS0wAAACGora3VuHHjTjsmKgOK3+9XRUWFpk6dqtraWnk8nkhPKWq1tLQoIyODdQwD1jJ8WMvwYB3Dh7UMD2OMWltblZ6eLqfz9EeZROVHPE6nU2PHjpUkeTweXixhwDqGD2sZPqxleLCO4cNafnXJyckDGsdBsgAAwHYIKAAAwHaiNqC43W6tW7dObrc70lOJaqxj+LCW4cNahgfrGD6s5eCLyoNkAQDA2S1q96AAAICzFwEFAADYDgEFAADYDgEFAADYDgEFAADYTlQGlA0bNmjChAmKj49Xdna23nrrrUhPyXZ27dql+fPnKz09XQ6HQ9u2bbNsN8Zo7dq1GjNmjBISEpSbm6vKykrLmMbGRuXn58vj8cjr9Wrp0qVqa2sbxEcReYWFhZozZ46SkpI0evRoXXfddaqoqLCM6ezs1PLly3XOOecoMTFRCxYsUH19vWVMTU2Nrr76ag0bNkyjR4/Wz3/+c/X09AzmQ4moxx57TDNmzAh8C2dOTo5efvnlwHbWMHQPPPCAHA6HVqxYEaixngOzfv16ORwOy23KlCmB7axjhJkos2nTJuNyucyTTz5p3n33XXPzzTcbr9dr6uvrIz01W3nppZfMPffcY/7xj38YSWbr1q2W7Q888IBJTk4227ZtM//+97/NNddcY7KyskxHR0dgzBVXXGFmzpxp9uzZY15//XUzceJEs3jx4kF+JJGVl5dnnnrqKXPo0CGzf/9+c9VVV5nMzEzT1tYWGHPLLbeYjIwMU1JSYt5++21z8cUXm2984xuB7T09PWbatGkmNzfX7Nu3z7z00ktm5MiRZs2aNZF4SBHxwgsvmH/961/mgw8+MBUVFeYXv/iFiYuLM4cOHTLGsIaheuutt8yECRPMjBkzzB133BGos54Ds27dOnPhhReaY8eOBW6ffPJJYDvrGFlRF1Dmzp1rli9fHrjf29tr0tPTTWFhYQRnZW+fDyh+v9+kpaWZ3/72t4FaU1OTcbvd5tlnnzXGGHP48GEjyezduzcw5uWXXzYOh8N8/PHHgzZ3u2loaDCSzM6dO40xp9YtLi7ObNmyJTDmvffeM5JMaWmpMeZUWHQ6naauri4w5rHHHjMej8d0dXUN7gOwkREjRpgnnniCNQxRa2urmTRpktm+fbv55je/GQgorOfArVu3zsycObPfbaxj5EXVRzw+n0/l5eXKzc0N1JxOp3Jzc1VaWhrBmUWX6upq1dXVWdYxOTlZ2dnZgXUsLS2V1+vV7NmzA2Nyc3PldDpVVlY26HO2i+bmZklSSkqKJKm8vFzd3d2WtZwyZYoyMzMtazl9+nSlpqYGxuTl5amlpUXvvvvuIM7eHnp7e7Vp0yadPHlSOTk5rGGIli9frquvvtqybhKvyWBVVlYqPT1d5557rvLz81VTUyOJdbSDqLqa8fHjx9Xb22t5MUhSamqq3n///QjNKvrU1dVJUr/r+Nm2uro6jR492rI9NjZWKSkpgTFDjd/v14oVK3TJJZdo2rRpkk6tk8vlktfrtYz9/Fr2t9afbRsqDh48qJycHHV2dioxMVFbt27V1KlTtX//ftYwSJs2bdI777yjvXv39tnGa3LgsrOzVVRUpPPPP1/Hjh3Tfffdp8suu0yHDh1iHW0gqgIKEEnLly/XoUOHtHv37khPJSqdf/752r9/v5qbm/W3v/1NS5Ys0c6dOyM9rahTW1urO+64Q9u3b1d8fHykpxPVrrzyysCfZ8yYoezsbI0fP16bN29WQkJCBGcGKcrO4hk5cqRiYmL6HEVdX1+vtLS0CM0q+ny2Vqdbx7S0NDU0NFi29/T0qLGxcUiudUFBgV588UW9+uqrGjduXKCelpYmn8+npqYmy/jPr2V/a/3ZtqHC5XJp4sSJmjVrlgoLCzVz5kz94Q9/YA2DVF5eroaGBl100UWKjY1VbGysdu7cqYcfflixsbFKTU1lPUPk9Xo1efJkVVVV8bq0gagKKC6XS7NmzVJJSUmg5vf7VVJSopycnAjOLLpkZWUpLS3Nso4tLS0qKysLrGNOTo6amppUXl4eGLNjxw75/X5lZ2cP+pwjxRijgoICbd26VTt27FBWVpZl+6xZsxQXF2dZy4qKCtXU1FjW8uDBg5bAt337dnk8Hk2dOnVwHogN+f1+dXV1sYZBmjdvng4ePKj9+/cHbrNnz1Z+fn7gz6xnaNra2vThhx9qzJgxvC7tINJH6QZr06ZNxu12m6KiInP48GGzbNky4/V6LUdR49QR/vv27TP79u0zkszvfvc7s2/fPvPRRx8ZY06dZuz1es3zzz9vDhw4YK699tp+TzP++te/bsrKyszu3bvNpEmThtxpxrfeeqtJTk42r732muVUxPb29sCYW265xWRmZpodO3aYt99+2+Tk5JicnJzA9s9ORfzOd75j9u/fb4qLi82oUaOG1KmIq1evNjt37jTV1dXmwIEDZvXq1cbhcJhXXnnFGMMaflX/fRaPMaznQK1atcq89tprprq62rzxxhsmNzfXjBw50jQ0NBhjWMdIi7qAYowxjzzyiMnMzDQul8vMnTvX7NmzJ9JTsp1XX33VSOpzW7JkiTHm1KnG9957r0lNTTVut9vMmzfPVFRUWHqcOHHCLF682CQmJhqPx2NuvPFG09raGoFHEzn9raEk89RTTwXGdHR0mNtuu82MGDHCDBs2zHzve98zx44ds/T5z3/+Y6688kqTkJBgRo4caVatWmW6u7sH+dFEzk033WTGjx9vXC6XGTVqlJk3b14gnBjDGn5Vnw8orOfALFy40IwZM8a4XC4zduxYs3DhQlNVVRXYzjpGlsMYYyKz7wYAAKB/UXUMCgAAGBoIKAAAwHYIKAAAwHYIKAAAwHYIKAAAwHYIKAAAwHYIKAAAwHYIKAAAwHYIKAAAwHYIKAAAwHYIKAAAwHb+D5LkKxdBuLHhAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import gymnasium as gym\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "env = gym.make('highway-fast-v0', render_mode=\"rgb_array\")\n",
    "env.reset()\n",
    "\n",
    "# To visualise a initial/idle state\n",
    "action = env.unwrapped.action_type.actions_indexes[\"IDLE\"]\n",
    "obs, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "plt.imshow(env.render())\n",
    "plt.show()\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the Highway Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring and understanding the environment by analysing the observation and action spaces, the dynamics of the environment, and the reward structure. Here’s how you can start exploring highway-env:\n",
    "\n",
    "#### Understanding the Observation Space:\n",
    "\n",
    "The observation space in highway-env can vary based on the configuration but typically includes the positions, velocities, and other attributes of nearby vehicles relative to the controlled vehicle. Understanding this space is crucial for designing your agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: Box(-inf, inf, (5, 5), float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Observation space:\", env.observation_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding the Action Space:\n",
    "Actions in highway-env usually involve discrete decisions like changing lanes, accelerating, or braking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space: Discrete(5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Action space:\", env.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reward Structure Exploration\n",
    "\n",
    "Understanding how rewards are assigned is crucial for designing your RL model. Perform actions and progress through the game to see what actions increase the score, how much reward is given for different achievements, and identify if there are any penalties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward received:  0.7175582990397805\n",
      "Reward received:  0.7347553717229882\n",
      "Reward received:  0.8494110707274963\n",
      "Reward received:  0.9801695933672692\n",
      "Reward received:  0.9973885885268879\n",
      "Reward received:  0.8838810761297416\n",
      "Reward received:  0.868933584785261\n",
      "Reward received:  0.9827402251569067\n",
      "Reward received:  0.9977271078395926\n",
      "Reward received:  0.999700689098218\n",
      "Reward received:  0.33329391790593815\n",
      "Reward received:  0.03333333333333336\n",
      "Reward received:  0.03333333333333336\n",
      "Reward received:  0.03333333333333336\n",
      "Reward received:  0.03333333333333336\n",
      "Reward received:  0.03333333333333336\n",
      "Reward received:  0.0\n",
      "Reward received:  0.0\n",
      "Reward received:  0.0\n",
      "Reward received:  0.0\n",
      "Reward received:  0.0\n",
      "Reward received:  0.0\n",
      "Reward received:  0.0\n",
      "Reward received:  0.0\n",
      "Reward received:  0.0\n",
      "Reward received:  0.0\n",
      "Reward received:  0.0\n",
      "Reward received:  0.0\n",
      "Reward received:  0.03333333333333336\n",
      "Reward received:  0.0\n",
      "Reward received:  0.0\n",
      "Reward received:  0.0\n",
      "Reward received:  0.0\n",
      "Reward received:  0.0\n",
      "Reward received:  0.0\n",
      "Reward received:  0.0\n",
      "Reward received:  0.0\n",
      "Reward received:  0.0\n",
      "Reward received:  0.0\n",
      "Reward received:  0.0\n",
      "Reward received:  0.0\n",
      "Reward received:  0.0\n",
      "Reward received:  0.0\n",
      "Reward received:  0.0\n",
      "Reward received:  0.03333333333333336\n",
      "Reward received:  0.06666666666666665\n",
      "Reward received:  0.06666666666666665\n",
      "Reward received:  0.03333333333333336\n",
      "Reward received:  0.06666666666666665\n",
      "Reward received:  0.06666666666666665\n"
     ]
    }
   ],
   "source": [
    "# Example: Perform an action and observe the reward\n",
    "env.reset()\n",
    "for _ in range(50):\n",
    "    _, reward, _, _, _ = env.step(env.action_space.sample())\n",
    "    print(\"Reward received: \", reward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the Environment - Simulation:\n",
    "\n",
    "You can visualize the environment in a Jupyter notebook or Python script to understand the dynamics visually. highway-env supports rendering directly to a Jupyter notebook using its render method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def generate_gif(frames):\n",
    "    # Save the captured frames as a GIF\n",
    "    gif_path = 'highway_simulation.gif'\n",
    "    imageio.mimsave(gif_path, frames, fps=10)  # fps controls the speed of the animation\n",
    "\n",
    "    # Display the GIF in the notebook\n",
    "    display(Image(filename=gif_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple environment demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/gif": "R0lGODlhWAKWAIIAAP///5P//0n/AGTI/zLIAGRkZDw8PAAAACH5BAAKAAAALAAAAABYApYAAAj/AAsIHEiwoMGDCBMqXMiwocOHECNKnEixosWLGDNq3Mixo8ePIEOKHEmypMmTKFOqXMmypcuXMGPKnEmzps2bOHPq3Mmzp8+fQIMKHUq0qNGjSJMqXcq0qdOnUKNKnUq1qtWrWLNq3cq1q9evYMOKHUu2rNmzaNOqXcu2rdu3cOPKnUu3rt27ePPq3cu3r9+/gAMLHky4sOHDiBMrXsy4sePHkCNLnky5suXLmDNrDgqgs+fPoEOLHk26tOnTqFOrXs26tevXsGPLnk27tu3buHPr3s27N+jNwIMLH068uPHjyJMrX868ufPnzA1In069unXr0LNrt2lggPfv4MOL//ceIICB7ejTt+w+vv348ufVy58/kr37++TN09/Pf6N9/PjF19+ABEL0H4DuCVjgggwadCCC4ynY4IQLPgjhd/BRqGGFF7aX4YYg8mdhhx+GaKJ616Wo4nQntujiizDGKOOMNNZo44045qjjjjwS9ltBrRkUJJCsCbnaQUUSeaSSqhm5JEFJMokakk8ONCSUUVqZpUBbclmll18WcKWWYXYpZphnNinllGue5mRqPcYp55x01mnnnXjmqeeeyq3oJ3Z8BlrXiBeWKOihbxEKoaGINqqWoggy6uikZUEKoYSUZhqWpQhiqumnXHEKoKeglnqVqO5JauqqVKHqoX6sxv9alavvwSrrrVD9qat0uPbq66/ABivssMQWa+yxyCar449YltnlmGDC+SabzapZrbTXUksmttmaRqW123Ibrbhpgjuum9Oi2623bbK7bmnpuvvuaN+SC2259qKp7L789uvvvwAHLHB2u+qaVsF/DvycAQQ07PDDEEfcsAACkLpph7VarHBxDEvsscQUa/wVreKpurFxHX+s8sQVH4xxybaenFzKK68sslckRyjzcjTX/PHNXeUsHtA7Z9azzxITvZXQ4SldtGVHI+1wyC6/DJ7JTwMXtdQEUI0W0/k5nfVkW0vt9VlgD4D12EYjvOLBbqvI9tx012333XjnrffefPeg7bdwvgUu+OCEF2744YgnrvjijDfu2t+QRy755JRXbvnlmGeu+eacd+7556CHLvropJdu+umop6766qy37vrrsMcu++y012777bjnrvvuvPfu++/ABy/88MQXb/zxyCev/PLMN+/889BHL/301Fdv/fXYZ6/99tx37/334Icv/vjkl2/++einr/767Lfv/vvwxy///PTXb//9+OevP/kBAQAh+QQBCgAHACwAABkAWAI3AIL///+T//9J/wBkyP8yyABkZGQ8PDwAAAAI/wAPCBxIsKDBgwgTKlzIsKHDhxAjSpxIsaLFixgzatzIsaPHjyAFGhhJkqTEAihTpgzJsqXLlzBjypxJs6bNmzgXGhjAs2dPhwECGFBJNKfRo0iTKl3KtKnTozt9+gQqlKjKp1izat3KtavXrw+jSuVJdahVlGDTql3Ltq3btwjFjoVo9izcu3jz6t3LN6NcqXTPou1LuLDhw4i5/p0aVnCBxJAjS55MeePinw2D1rVaubPnz6AjXyabuarg0KhTq17tdfSAso5Zy55Nu3bMkrhPnrbNu7fv38CDCx9OvLjx48iTK1/OvLnz59CjS59Ovbr1656JAtjOnaFV7t0Xfv8HD8C7dvLii5Ivr3A8ePMq18NPKT99fPTt1eNPyLk+//Pv2Ufffv/dF2B+BoZX4Er+IeSeggui1KCDAEJIYYLbCYjWhAb1R+BBD2aoYQEcdlihiBE+ht2KLLbo4oswxijjjDTWaOONOOao4448OoTbj0DmNpBjRF7V45FI6uXaWEwOoFmRUCYp5ZRsLdmkVE9CSSSVXHa5lZVX9pSllrt5aeaZSIEZ5msHbEZmUWjGKSdNaoYp0ptlzqnnnh/VeeWdeHLG56CEYuRnk2MGulKhjDYa1pqQJqqoio5WamlBhzIpqaKXdnppkKD+SNCkRnpq6qmopqrqqqy26uqrsMbDKuustNZq661vncgeggMemGKJBYW464UMfmgihsMSK6Gxx/ZqIYi6jngAsEPq5yu0yM637LXYOovir8yOau2zwUY7IrXVZntuuOkWy225V6F7gLDakshuu9uSK26puPbr778AByzwwAQXbPDBewJJkV0INzzdZRBtSqnDFDcH8UMSV6wxcxfDJujGIBvXcWMfh2xycCP7yPDJLPuWckNuDtbyzLW9rFDGNOcsm80J4azzz6jxjJDPQBfdmcITrWz0SwEBACH5BAEKAAcALAAAGQBYAjcAgv///5P//0n/AGTI/zLIAGRkZDw8PAAAAAj/AA8IHEiwoMGDCBMqXMiwocOHECNKnEixosWLGDNq3Mixo0eNBkKKHEmyZEmGBVKqXMmyZcuPMGPKnEmzps2bOHPq3MkzoYEBQIMKHUoUaIAABlC6XMo0Zc+nUKNKnUq1qtWrN38W3Vr0aNKFTcO+xEq2rNmzaNOqXStQK9e3RpEqFUuXrd27ePPq3WvXLVy4XxXSHcy3sOHDiBMrhuj3L9fACQfXXUy5suXLmKc2dlwUMkLJYjOLHk26tOmHmzkH9ToX9NLTsGPLnn04teoBrMG6Zkq7t+/fwKXaVp1b8O7XwZMrX878osnn0EW2Pr6yufXr2LNr3869u/fv4MOL/x9Pvrz58+jTq1/Pvr379/DjyzcLoH796QXs28ev/75xlv0BoFt1AQ6oUoEGpoTgfwf2l6CCDjLo1IKfAUjhQS1diKGF+vEXYWQZflghgSJuuJKGBoXY4YMoEuRSiwO9BKNAKq4I4oklmtigjTfuuJ+EBRyQ43xEFmnkkUgmqeSSTDbp5JNQRinllFRWGd2VJ01EnUtVduklW8NxVlxEW4715ZloWhWmY2NCVCZLacYp51Nr/tXmQ29WN+eefNJUp2Oe4ZmnU30WauhGf/4VqEODEnroo5BGlChgFDUaZKSYZurTbV3JpWWjmoYq6gGTbnUno6COqiqkpXa6aEOWrv8qq6FY1hpSpanOquuuvPbq66/ABivssMQWa+yxyCar7LKYDllQjf4BOeMBLzobI5zTQisgi9ZeiyOPOvoY7YgqCdkttRyCm2K645ILobrrfvtjj+JuS2+Q2bJr773Toitvu/H+u2+4+J6r7cABvzsvv+f6W++D5i7M7MQUV2zxxRhnrPHGHLt3Zcc52Vrrg1uCjFaYJmfFKVGnuphrylihDLOfKw/Vsrd5zkyWzDrH1CrLnt5bcs9qvkW0zzUT9SrObx5dFc9Oc/RzZyRTF7VmRl8tddJDLU3jy1rzBHXYznEdl9cON012T2OvTdHUQt389aBui5113RXBvVrQ7pYQibdOH//9tsiBC2214FMFBAAh+QQBCgAHACwAABkAWAI3AIL///+T//9J/wBkyP8yyABkZGQ8PDwAAAAI/wAPCBxIsKDBgwgTKlzIsKHDhxAjSpxIsaLFixgzatzIsaOBjyBDihw5smOBkyhTqly5sqPLlzBjypxJs6bNmzhz6qRoYIDPn0CDCvUZIIABkyyTKj25s6nTp1CjSp1KtarOnkOzDi16lOPSry2tih1LtqzZs2jTDsSqtS1Ro0jBylVLt67du3jzqmXr1m3XjXID6x1MuLDhw4gb8u2r9a/GwHMTS55MubJlp4sZD3WcETLYy6BDix5NWmFmzT+5xvWctLTr17Bj4z2NeoBqr6yVyt7Nu7fvq7W3wsWdm+Xv48iTK49IsrlzkKuLp1xOvbr169iza9/Ovbv37+DDi/8fT768+fPo06tfz769+/fw42NE6RCAfQACpze8P1D/wvv45UcfQwD2x9R+/B3g338JLqhQggoOyKB9Bh44YYARFlBfgxJeKKCFHmaoIYIYOohQgR9uSGGKJAZo4okcgvjgiiK2WOGIIWaooosdzrjiiwehCKRBEA5JEIo6yqfkkkw26eSTUEYp5ZRUVmnllVhmqWV5z3VZUnTSybjlmGRWRRtqtxEXZo9ltunmTmdqliZgaxr55p14ehScUHM+ViebeQYqKEZxosZZZ3+KOeiijD5UqGaHzpcojo1WamlCjzIW6UWTUnrpp59m2lafiCYK6qmh7hkUqZKaiuqrjIr/qhWrnE4K662CeqnrRy51iuuvwAYr7LDEFmvsscgmq+yyzDbr7LPQRmsZoEHG6GlCRVJbEJJ2CsStotX+qO221qp4o40fXhtuieASWS663Xr7LoE0xvutuutWuGO6+9ZI4rn01jvuQPf2G+8BQg5M8LwTApyjwtJGLPHEFFds8cUYZ6yxbLvq6qdu0XbsJZ2ubvyUrFnRKtFX0qIs3KYT+WryyaoCpXJELIdcc2rDlfrnzDTvbFvPtYIMrct8El30z0A3hfRmH7ems9A+wbyyrU3DSXXVURs3NdVW44x11jk9LVTYD+V89NYDoJ322GTfZDbPbjek9rNzv1W33XDHLl1T3kPvvdDdzgJ+s9gl+/031Ye/bTTejCttkcyK/y3yc12HdfTlzpHMdOXIBQQAIfkEAQoABwAsAAAUAFgCSACC////k////5OTZMj//2RkZGRkPDw8AAAACP8ACwgcSLCgwYMIEypcyLChw4cQI0qcSLGixYsYM2rcyLGjx48gQ4oseKCkyZMoU6pcybKly5cwY8qcSbOmzZs4c+rcybOnz59AgwodSrSo0aNIkypdyrSp06dQo0qdSrWq1atYs2rdyrWr169gw4odS7as2bNZAahdy7at27dw48qdS7eu3bt48+rdy7ev37+AAwseTLiw4cOIEytui7ax48eQI6fcKLmy5cuYM2v2SXmz58+gQ4sm23m06dOoU6v+WXq169ewY5s1QLu27du4aR+ofVG279/Ag0M1MKC48ePIkxcPEMBAb+HQo0ufbpO48uvKmTu3SL279+/TrWP/H7+8+XPw6NOrPy2ePPaS2yuun0+/fuX27t+ft8+/v3+u+OWnnAH/FWjggbMJiJ12CDbo4INWBahgeQRCaOGFGBYl4YQMZujhhyDWlNuIJNYW4okopqgiVRJNBpFKEcH4Ikot0hijjQ/JmKOLO55Uo483AjmjkA7pWCSOPZr0o5JBMpmkk0ci2RCPTx6wZElXWjkkkVPauOKXYIYp5phklmnmmWimqeaabEJXV0p5qRQnSnrBOedJddKJl5x72nmXn3/q2Seed5qU10GFlpQnoYMamugBj0LaqKOBMloppZcqOqmmmXJqF6Butelfa6KWampmpJ6q6qqNpcrqq7B+/+VqrLTWKlSJJO6G20S29uorUBuSd5J2vP5q7LHVTWjcsOZlieyz0KIU7HjMxrdltNhGO+170hab7bfPbiuglk2Ca26v4uZX4bnstrubssl16O6836Y7nrz05hsuvMjhq++/vuIqsG0AF2zwwd9lWS6W1zJcpcILL0xulFwyRCXFDj8cccMTd1mxxVJ6DCXGHYMc8kJGipwxyRA3LPHGCMcs88w012zzzTjnrLNXswL1pqCfgkqX0EMDHbSlR2P6s6A+zWXQokovHXXRSFNd9VxEY2201J4m3bXVU8vFZ6dQfw22pHchitdAV4u9NVuqEiD33HTXbbfcAgiQMnc7w//WM713Bx543nvL1/drf88r+OJ0E34x34evlri7jFcud+EURe7a5O1aXjnm3mp+2cC64qoywJ4zDrqzokOWbkvEmmxw6oPr/bjhrVv2Okuxo4ww7Xc7fnLmueueH+zN+n4w8HYL/zHxxUtmr7CnR7+6xNafNf1469Y88PfZf7c9dt3TbADzdeddfvjRjR9vczifj/7c6rPfnfv9wn+z/PMTUL/94eHXcfw1M/71jwDrAyBwvke6/R1wbglU4K9GQsEKWtAhBuyftS7IwQ568IMgDKEIRwi5NGWQef+ToArv98AUrvCF0Dkh8FwIwxr6hoECs+GvFsPDHvrwh0AMohAMh0jEIhrxiEjcS0AAACH5BAEKAAcALAAAGQBYAmoAgv///5P//0n/AGTI/zLIAGRkZDw8PAAAAAj/AAsIHEiwoMGDCBMqXMiwocOHECNKnEixosWLGDNq3Mixo8ePIEOKLHigpMmTKFOqXMmypcuXMGPKnEmzps2bOHPq3Mmzp8+fQIMKHUq0qNGjSJMqXcq0qdOnUKNKnUq1qtWrWLNq3cq1q9evYMOKHUu2rNmzaNOqXcu2LdKNbuPKnUu3rl2fcO/q3cu3r1+yef8KHky4sOGfgQ8rXsy48eDEjiNLnkx5LOTKmDNr3pz0MufPoEOLful5tOnTqCuXTs26tWu/q1/Lnk07bezauHPr3s27t+/fwIMLH068uPHjyJMrX868ufPn0J83TBlRZXWUEqlfP5kdO0Tr37U//xQ/3nt47ttNpld/nn37kt3Rvz+wHv58+vPjuy8v3yF4/v1NZ95B0RVo4IEIJqjgggw26OCDEEYo4YSj3UbhhRhqZWGGHHYI1YYehiiiUSCOaOKJPJWI4oosyqRiizDGOOBFMtZoI2ka3ajjjvvRyOOPNb4I5JATCknkkUgm6RgATDbp5JNQRinllFRWaeWVWGap5ZZcdunll2CGKeaYZJZp5plopqnmmmw+qeSbcMYp55x01mnnnXgqJ2CADP3n34x79hioffndNxBeCpH3J599Atooo4kq+qigkxIKoKWLUhqpo5tCmpCkleJX6KWYhipqAQakquqqrLbaqkASEv8g66y01mqrrAIIkOeFBgzg66/ABiusrwEEYACFtyabbK67UtjrsNAOW+yxEyprLa3MNivhs9F2S6yxyF4rLgHabuvtub5SG+u415aLmpElcYtutOpGyG677poG7wHyzjtsvRDeu6yu+VaY4039+vvrtOEKXGu2BYe2b8IKD8BwtQ4/THDEoE1csbAXcyzyXRO7avLJqTq478iGrWyjyyw/drCdMMf8V80x4mwzXzq32PPOJM9c589AJ2hlSlwiraVKWzK9NEpJQ900d1seNLXUWSr99ElRc321SV+DvbXYY5fUNdlZY42l02mrfaXWbaO9tttv010l21EySHTRfPf/tXffgNv1d+CExzV44cuNpPjijDfu+OOQRy755AahbPmrlGceEuJ5UqxwyJyHzpjn/oIu+umFkT6v6ai37pfq/gLs+ux6wT6v7LTnPpft6OKu++9s8d4t68AXn5bw0RJv/PJkIQ+t8sxH/9Xl1Kcs/fXYZ6/99tx37/33urMK/vhlyXsy+TIdbffd60+Jd93tSwn33F6XfUDYZtt/v/1n588//gDg3ckASMD/GZB+9UOg3NSXQAXu74AOxN8D84Y+pDhPWKuqoAaPckGQgWuDIBRKB4MFvRCa0CYjBFYJT8hCmKQQgy2MIQo/9i8Z2nAmLwSW727Iw5OwioYr7KEQR+NlsuF9cIhIxGERg5jEJrokg06MohSnSMUqWvGKWMyiFrfIxS568YtgDKMYx0jGlrTpjGhMoxrXyMY2uvGNcIyjHOfYpYAAACH5BAEKAAcALAAARQBWAjYAgv///5P//0n/AGTI/zLIAGRkZDw8PAAAAAj/AA8IHEiwoMGDCBMqXMiwocOHECNKnEixosWLGDNq3Mixo8ePIEEaGEmypAGIBVKqXFkgpMuXMGPKnEmzps2bOHPqPGhggM+fQAcwDBDAAMujO5MqXcq0qdOnUKPm7Bk06NCiR1lK3cq1q9evYMOKXUi16s+rRrOqHMu2rdu3cOPKJVjWrNCGadW2nMu3r9+/gANTrGvWYV61ghMrXsy4MVfCVQ3rTem4suXLmDNfhGx1IdHDWTWLHk26NGPOQNFO3mu6tevXsLeiPusZ6+TYuHPr3v3SpG+Ut3kLH068uPHjyJMrX868ufPn0KNLn069uvXr2LNr3869u1LWCAGI/x9/AKnC8eTNh0cvvrzWhOzFh4bP3v379ejtrz1fX/3B+ADoRxl97M2HX3r+GRSfgOD91999B7aXYEEAMshffgY6iOGEBC3IYYcPrnThhiISiF6GCoZYYoQBfjiQhxBqiOCKMs64n3c45qjjjjz26OOPQAYp5JBEFmnkkUgmCdaAm52k5JNQlpaSkxP59FmUWGZp2ZQVWVmUlmCGGRiXFHlJpZhoptkWmV0OcKaacMa5FZtluinnnXg6RWeVdubp55837QmRmYAWauhLgj5E6KGMNppRog4t6uiklD7EpEUjVarpppx26umnoIYq6qiklmqqdDGeqqqmq9246lwNps1Ioqs1tpgqiCpeKuuJLh4A460v5horhcKOaKOuxBbY66807iohsMHOimyyxxYA4LXPNkttttriWu2w0Va7ELPThiuuieOhuK2t0PparLHs0upsvOUKVGGvr2rW6r715uvvkfzu++/AUAbcKsEIG5mpbww3TFK/CUeMY08WfQaxxBhrR3FFFmfs8Y4bU9TxxyR3R1iVRpWsssZ2RZaQm+CuLLNzs7VsFcwz5yxdzTb/RFR5OgdNc89EXyn00crxXPSXSDdtnMNQN+y0TAEBACH5BAEKAAcALAAALABYAlcAgv///5P//0n/AGTI/zLIAGRkZDw8PAAAAAj/AAEIHEiwoMGDCBMqXMiwocOHECNKnEixosWLGDNq3Mixo8ePIEOKLHigpMmTKFOqXMmypcuXMGPKnEmzps2bOHPq3Mmzp8+fQIMKHUq0qNGjSJMqXcq0qdOnUKNKnUq1qtWrWLNq3cq1q9evYMOKHUu2rNmzaNOqXcu2rdu3PA3InUu3rl27cPPq3cu3r1+YBgYIHky4sGHBAQIY+Mu4sePHkLMGPkz5cOLFkTNr3sy5M83JlUMjVuy5tOnTqP2CFi0ac+rXsGPL3rqadWXXs3Pr3s07aG3bh3H3Hk68uPGTv4EPvny8ufPnsJMrH8AcuvXr2BtLV149u/fv4NHe/x1Pfm748+jTq1/Pvr379/Djy59Pv7593gXy69/Pv7///wAGKOCABBZo4IEIJqjgggw26OCDEEYo4YQUVmjhhRhmyN99HHboYUwGpSSRiBGRCJGJDqlUIkojsrjiSS3CeCKKDak4o4w3mhSjji/y+JCNP7qYY0k7EtmjkUEKmSKNDDHZpJJL4ljjh1RWaeWVK5VHF5ZcdmmdAQSEKeaYYsJUgJdoYiVhmjWBmZMABxhwJpt0RrVmnTG5iROccuLZmZaAbtnXnX66pOdNfM5ZaGbbAdfdXoQumiUBO/UpaWSN2vaoXpFeitKhOFnqqWOZsrZpXp2OWhKoN4mq6l+l2v8mHKoRvvoppXvGqaitfcXK2qxwpaoqqzQlyius093ml7CjLgZoS8Ye22uyhp0abK3SHkCgmdny5Wtl1r7FbLfkmvYtZeGWq+66OQXqLrvwxivvvPTWa++9+Oar775mJZiSvygBfBKCKhH874EHIxywwQMrvLCBBTtsksATM1yxxCVZfHGBEUP8sMcNY6ytyCODHDLHH6N8ssobs5xxfvzGLDNLIUI5pZRR+pikzjfj/KTPP/PcM5I7Ez200UELvZCTS9uc9AFFQj0k0k0DXbXSV1OdtdRFa50QkDl7/bXTW08989lop6322my3ndO4bsf9Idxy1/2pu8/2RrfdfJ//axlpemPL9+Aq+V0t4PgJTvjiq1JbWLqw7c1424YHN5zkk69duWHAyoZ55mlvXljnsX0O+tmij0Z65IqfXnfq1CG+m+muxww75LXn7hzeeevu++/ABy/88MQXb/zx9lH8ssjKl+zy8s87v23K069cfcsDdhy9xtJfD/3zzXPfvYDaez8++dRnn36A5au/PoAJm/y9+eHDjPz94Y2k//789+///wAMoAAHSMACGnAi+EugAutFuwU60C0NfKAE0xLBCVqQLBW8oAa/ksENelArHfygCKsSwhGaEColPKEKl5LCFbrQKC18oQyDEsMZ2vCGOMyhDnfIwx768IdADKIQG4dIRDxp6IhITKISl8jEJjrxiVCMohSnqKCAAAAh+QQBCgAHACwAABYAWAJZAIL///+T//9J/wBkyP8yyABkZGQ8PDwAAAAI/wABCBxIsKDBgwgTKlzIsKHDhxAjSpxIsaLFixgzatzIsaPHjyBDiix4oKTJkyhTqlzJsqXLlzBjypxJs6bNmzhz6tzJs6fPn0CDCh1KtKjRo0iTKl3KtKnTp1CjSp1KtarVq1izat3KtavXr2DDih1LtqzZs2jTql3Ltq3btzQNyJ1Lt65du3Dz6t3Lt69fmAYGCB5MuLBhwQECGPjLuLHjx5CzBj5M+XDixZEza97MuXPcyqAJX/ZMurTp034nh16NGbXr17Bjb1W9GnRr2bhz694dlHZtyrd5Cx9OvPhJ379FKzbOvLnz18iTI17+vLr1642jSx+Nvbv372nviv8fPxe8+fPo06tfz769+/fw48ufT7++/fv48+vfz79//gIABlhTgALORGCBMh0IIE0KDniggwQy2KCBEyb4oIQRYoighRly2GFMFXq4oIYjUvghTAoWQGKJIF5o4oYtnvhSiiuq6N+NOOao44489ujjj0AGKeSQRBZpZHPkJYmXWik26SSMR0YJnnbJcZfWk1iGKOWW3VH5m5VoZSkmi1yWWZ2XtYF51phimunmmdJVFpxZbGb55p3MofnbnGXViSWegA6nZ218kuXnk4EmqtugoKlJ56FNKippbIxW5mifkNI46aanVUrZpYZmqiWnpGqm5KlyrSXqqKW26uqrsMb/KuustNZq66245qrrrrz2SpVBKY0KLErCknSSpicNaxKyJR1ErIsmKbsstM0aeyy1B0h7ALPVEvQstc5eK2O4045rbblQarstttpym+2565oLb7HefpsuvPHeWy+6+g5kL4zklkTvvgKzi+/AAv1L5rsE5wulrxBHLPHEFFds8cUYZ6wxjqieCtuq2G58saeWUecayDKKbDHJhoHqGcoPq0wxy4W53BnMC8s8c5zAfYyzzhnTbFihL/8M9Mg8H0b0zUYfXbHQg9nMGc42Or1z0lGbjBrVVj+NddZLT9101xF3rKTPMJOt9tpst+3223DHLffcdNdt991cqvuS3i7xot2S3ysFDBPggeO7t+F9I86S4IcrXnjDgzv+uL80EZ4S44lD3jjlM1l+ueSfg44S5n+LPrrpyaKO9+qst+7667DHLvvsFnNN++1g2Y777lvpzvvvVvkO/PBRCU/88UwZj/zyRynP/PNCOQ/99D1JT/31OFmP/fYvgsz99+CHL/745Jdv/vnop6++xFS37/778Mcv//z012///fjnr//+/B8YEAAh+QQBCgAHACwAABQAWAJFAIL///+T//9J/wBkyP8yyABkZGQ8PDwAAAAI/wABCBxIsKDBgwgTKlzIsKHDhxAjSpxIsaLFixgzatzIsaPHjyBDiix4oKTJkyhTqlzJsqXLlzBjypxJs6bNmzhz6tzJs6fPn0CDCh1KtCjKAkiTKl3KtKnTp1CjSp1KtarVq1izat3KtavXr2DDih1LtqzZs2iXGl3Ltq3bt3Djyp1Lt67du3jz6t3Lt6/fv4ADCx5MuLDhw4gTK85roLHjx5AjR15MubLly5gzaz5gYIDnz6BDi/YcIICBzahTq17NuvXNzqNjjy59AKrr27hz697NWPYAmKUN2OZNvLjx48hhwo4tU/jT5NCjS5+eevno5sOpa9/Ovbte66KxP//3Tr68+fM+wYcGbjo7+vfw48tXD5q9c6fy8+vfr53+Z/vu8SfggASyJpljnB0oWYAFNujgg5mFBeGEFFZomIQWZqjhhhx26OGHIIYo4ogklmjiiSi6NlBKErEYkYsPqfQijA7RWCNKLeI440k78giRjD/qGKSPQ5rUo5FFIhmjkEsS2aSST5Z0pJRJHpCjkzdi2ZCNDKXo5ZdgroRVSmMeZZVKV6F5pplrnlSmm23CWZWac7JZp5x3mvSmnnHymWdJewKapp1UkdmnoH8iWiihUxl66KCMRkVnAWFWaumlmGaq6aacdpqcgqAe6OmopOrmn2+hBVfqqqxWh+qrtCH/1eqstCoGG07ByVrrrrwCdmtOzvUq7LB4/YpTsMQmq6xbxr6m67LQRgtUszTlSqm02GZ7rGe4tnettuCG6xK1M1kr7rnontRYgqGG+my68IaLYbz0Zjtvvfjmq+++/Pbr778ABywwfCsymSWUB1MZpcIJM7ylwQ9r2SXEE0usEJALW1nllQhH3PFCGDes8cIcO+yxyRV/fDGXIFPcssUrw5wQyzEPbLO9kPqZaM46N+roongC3bPPQUs1KdFFSxqp0kkzPbTRS48XNX5TU900g4HWdqjWiXIttKJfex02z2BDbefNaKfNYdhqt41pAe2e9pLcHMZtt9v1wp0TAQcIy0D3hqe+SpppeNOrN058+z3hc4L7pmrh8B5+U+J/N/hU5SzJ9jjk6EqOOOYEXh4TqqBzbm/pMxGAOn+iw0S66Z2vHpPqizslO0qy3Q57sp7XRHntTelu0myE7y6v8Cv9DmHro4u2ufH2HkDA9NRXP31Lyj/IvEuaFw+9tnErBzxTdiOo4Pfo53dv+uzrt3778Mcv//z012///fjnn9tI/Pfv//8ADKAAB0jAAhrwgAiciP4WGLq0OPCBEIygBCdIwQpa8IIYzKAGsRIQACH5BAEKAAcALAAAFABYAlYAgv///5P//0n/AGTI/zLIAGRkZDw8PAAAAAj/AAsIHEiwoMGDCBMqXMiwocOHECNKnEixosWLGDNq3Mixo8ePIEOKLHigpMmTKFOqXMmypcuXMGPKnEmzps2bOHPq3Mmzp8+fQIMKHUq0qNGjSJMqXcq0qdOnUKNKnUq1qtWrWLNq3cq1q9evYMOKHUu2rNmzaNOqXcu2rdu3KjfCnUu3rt27eGHKzcu3r9+/gLHuDUy4sOHDiGcOTsy4sePHdRdDnky5suWski9r3sy588/MnkOLHk26JOjSqFOrTnx6tevXsOm2jk27tu2ws2/r3s27t+/fwIMLH068+F8AyJMrX868ufPn0KNLn069uvXr2LNr3869u/fv4MOL/x9Pvrz58+iXG1/Pvr379/DjPx2YUmL9iPcfxoW4Xz9K+//hFyB/AzrUn4H5IXgSgAsK2KB/BTZ0oIQRUvgghCYxmCGBFS6UoIIbchgihqaJKN+JKKao4oosgmXAizDGKOOMM7Zo442TGTDAjjz26OOPOwYQgAE4FmmkYToCqSSQQhJ55JNQfmhRVUkuaWWQQ0apZZS5KVXllVc6ueWYOHaZ1JdgLikmmWyuaCZSaKYJ5Jpt1infm0fFKSePTdrp550aUbmnkn3+aWh7eBql56CFHuoocYkWReOklML46KXCRYrpppy2pGmnoIb6aaiklmrqqaimquqqq1Kn0nUpYf8XK6wo0Vqrda/iequuJ8m6a3WzAhusq78S26utJvl6rLDFSpcrs8kiW5Ky0fJarbHLYjuttAdQuy1zrIYr7rjklisTfR16mK5CUqq7LkITMtSuuyOCWKKJBzh4oYX7yvsuvP8eNG9C8dJbr7/9InywwveSmC++DzusYcP2RiwxxOZmrPHGHAtV6cc1diwyjovu2ejIgIFMJ8pRlSznySyvtbJKBNRs880CCJBvcKO+5XKaMMeclgEE5KSzAQXwHChiP8s5s9BmEW30AUgrnVFiTaf5NNRkSZ0TAVUD17NbWYO5NddieZ1T2L+N3VbZSwaNdtdF68S2b26zBTehWc7/jZbaNuV8d295yzwok337HXXdNx2dtNhLH6by5IqfBXhNjluNUeWnXq6Syo+3HTnnoZ69sMCQX0366qy37vrrsMcuu03aflu7t91yy23u0F473bC36y5877b/3qyzx0cHvPHZMt888sk/tzz0vjtfvPW815499rh339zs4Icv/vhLjWT++einr/767Lfv/vvwxy//ROTXbz/4k6t8//5YH/6j3PwLIF/2hjjTCfCAcCHg/xKHwAbaRYFzcqAE6wLBHxlwghgcSwV9dMEMetArG8RSBz9IwqyEcAAALKEKt3LCFK7whVbJH8hgSMMa2vCGOMyhDnfIwx768IdA5E16FYZIxCIa8YhITKISl8jEJjrxidkJCAAh+QQBCgAHACwAACcAWAJZAIL///+T//9J/wBkyP8yyABkZGQ8PDwAAAAI/wALCBxIsKDBgwgTKlzIsKHDhxAjSpxIsaLFixgzatzIsaPHjyBDiix4oKTJkyhTqlzJsqXLlzBjypxJs6bNmzhz6tzJs6fPn0CDCh1KtKjRo0iTKl3KtKnTp1CjSp1KtarVq1izat3KtavXr2DDih1LtqzZs2jTql3Ltq3btwc2wp1Lt67du3hhys3Lt6/fv4Cx7g1MuLDhw4hnDk7MuLHjx3UXQ55MubLlrJIva97MufPPzJ5Dix5NuiTo0qhTq058erXr17Dpto5Nu7btsLNv697Nu7fv38CDCx9OvLjx48iTK1/OvLnz59CjPwdAvToAmtap18x+HXt2799ncv/vLpP79vDi0ZdXD3M8+OrnrceH/157evYv3d+nv99+f/LryfcfgO3hl5+BLpkn3YIMNujggxBGKOGEFFZo4YUYZqiha7kZZcCHIIYo4ogjbmgihB0WZcAALLbo4oswshhAAAacqFUBL9VoI18pErVijEDGOKOOOyKFY44sEXCAAEQWaVePQ/0Y5JQy0uikkU3WpCSTV94FpVBSUkllll0GVQCZM22JZplsfRlUmGIGuSabPJ25EwFz0omWm0DBGWeMeeqJk5064SnoW3z+5OefLQ55KFCE5mToo21qFNWijA7gKKU9RWqTmpyulahPmDK6aag6earlkoGi6tWoPZH/KOusILqaaqstgWrrrqGqqpKSLuHK67AnHhksscgmq+yyzDbr7LPQRpsqSSjpZ5JBKSl4ErbV4sftSdqa9m1J1opLULbhxkUtuN6ua1K66p7brYDXjksuewfNS6+5A6G7L78C+ctfvfKy+2+++voHcMAGH+zuvfg+fAC89k7cbsHvRixxughnrHG/CRMYL8gNK7ywwCaTLO3KLLfs8sswxyzzzDTXrCysZNGqc4k295wTzmOV+uepPhetmKV8CR0n0UY37RLQYiktJtNOV50S1GFJHaewVvuMNVhai8l11zZ//VXYY5KtNsEY9YU2kFSv7bTZXr0tpJVyk013V3bD8xh33kXvzdXOhH8I+OGIJ6744ow37vjjkEcu+eSUw1bxS5c/LTHmm7fUcUyZe9656BiDPvpKn+sVOuqns1666q9r3vrVq6tUu+2z0x677CrDvjtLqXP+O/C5o3S78QxXrvzyzDfv/PPQRy+904UTPv31W/X94t/Yd/+U9i5y7/34SoHfKN7kp9+U+S6Orf77O7Hfovvw12+T/CzSb//+MckvPv8ArIn/0BfAAuJkgPozoAIPUL2dLfCBEIygBCdIwQpa8IIYzKAGdzOeDnrwgyAMoQhHSMISmvCEKEyhClfIwha68IUwjKEMZ0jDGtrwhi8MCAAh+QQBCgAHACwAAD0AWAJFAIL///+T//9J/wBkyP8yyABkZGQ8PDwAAAAI/wALCBxIsKDBgwgTKlzIsKHDhxAjSpxIsaLFixgzatzIsaPHjyBDiix4oKTJkyhTqlzJsqXLlzBjypxJs6bNmzhz6tzJs6fPn0CDCh1KtChKAEiTKl3KtKnTp1CjSp1KtarVq1izat3KtavXr2DDih1LtqzZs2iXGl3Ltq3bt3Djyp1Lt67du3jz6t3Lt6/fv4ADCx5MuLDhw4gTK4a7cbHjx5AjS55M+UDjypgnN8zMubNnlgZChz4gurTp06JJfl59twBM1KZJs55NG7KBAbhx1wwQwIDq2sDZFjCQk8ABAcSDK1/u93buAbt7/2ZOvefw4seTV9/O3a3z3NF9E//sTt7m9ZwCkJdfz77nd902xQ9sT5/l+eLa6+vfv/I99PjT8UfffTgRkJ+ACOrn303yCZRgfQTWRMCEBz5oIXkL0sRbg65duF6ENBmnnockcuffcyimmBtvlo1XYncgziRihS/WONuJKuaI24Y2fkgjShMGKeSE6f3Y45GYwabkkkjC+NqSojUp5ZRUVmnllVhmqeWWXHbp5Zdg2uggShKlVCaZEZkJkUppormmmw+p+eZJbcK5mZwO4ZmnnXfSOaefcerJkKCD8lkooIEi2qeihzK6EKGPGhqpowqFaemlmMIVlUpXpYSVp50eZRWno4JalamnilrqSZ+qShWpqbL/Gqqsq5rUKq2vojoVrLni2qutswIbq69S8bqrq7+WdKuwTmXq7LPQRivttNRWa+21O12G7bbc7qdtt+CG2x2U5I4m7rnopqvuuuz+xWK78MZL3bvy1mvvvfjmey58+vbrL2L8/ivwwAQXbPBqOib8HL0HN+zwawpHzOPDFFeMUrkYW6zxxhx37PHHIIcs8sgkpzsmpZVKmjLKCUHasssIwRyzyi+zPLPNBrH5p0l18txzSWfiHCDQOxOdqM9FB4300UbvSfNBOjPdYtI/T+10yVhvvKmuxSJ7LLFdgw2VsWGL/RTXZSsbrNq1sp2s218z+/aycMdd99Ze4212s3nruX233wes/ffZaI/dt+F785141ow37vjjkEe+3beSV+4s5ZZnHmZCGEeppOagZ8l5TDpOHPrpU44uk4qmo+56j6qTnmLrr9dOYuww6Wik7bx7i9DuJykMfO/Ef/i77LoXrzx/uLdUem/LRz9gzBErTLv02NOHY/UrQp/999p3DiX45Jdv/vnop6/++uw7PtL78Mcv//z012///fjnr//+E7XvP39pCaAAB0jAAhrwgAhMoAIXyMAGZiUgACH5BAEKAAcALAcARABGAjcAgv///5P//0n/AGTI/zLIAGRkZDw8PAAAAAj/AA8IHEiwoMGDCBMqXMiwocOHECNKnEixosWLGDNq3Mixo0ePBkKKHEkypMICKFOqXInyo8uXMGPKnEmzps2bOHPqbGhggM+fQIP6NBgggAGWSFXuXMq0qdOnUKNKnZqzp9CrP4kaTcqVqtevYMOKHUu27EGrWK9qPcoVqdm3cOPKnUt3Ltq0QRGybbuyrt+/gAMLHkzxLt6sZ/myJMy4sePHkKkaPjxAr+K+kTNr3sy5s8TJh9deVuq5tOnTqAeDxit6dMvUsGPLnh11ddrWrmnr3s27N8eSwEeedF3At/HjyJMrX868ufPn0KNLn069uvXr2LNr3869u/fv4MNH/yYNoHz5huTNO0x/Hn1KgeYBuH99IP784vXtM2Qv/z589f7l195CmOlH4Hv/DTjcawYeyCCA+yHYYEIFQrggfgL25yB+8Wl4YYIefpjhehJaSCGCI0ZI34QI8UfigwqKyKJ4NNZo44045qjjjjz26OOPQAYp5JBEFilTcCXd15aRTDbJmG15IVTUXnw5aeWVdEEJVEJTjobll2COpSViB3V5WZhoplkbZUMpROWSasYpJ05jtpnQm13NqeeeL9VZmZte8inooBj5yeVWZxKq6KIPGSoloooxKumkZ7H5Z5mQVknpppMiSZKSeXIq6qiklmrqqaimquqqrLbq6quwxrYqK5/8hdhiiTGeCKOtt+4aYIobgsirQS4GOONBxW7IoYm9YnhsQckGC6y0zxJUYa7IoljtQLUay2yzIL64LLbEavttuSueCy2uw6I7brvr+jrrvPTWa++9+Oar77789rvvpxVh5u/A1xkmkZkoEqywdAZHhDB9C0fsXMMQPYyhxBgrR3FEb2bscXIbQ9TxxyT3FnKjApessmwnM2TxyjDH1vJCL8dss2kzK1TzzTxvBjBFKccaEAAh+QQBCgAHACwEAEQAVAI3AIL///+T//9J/wBkyP8yyABkZGQ8PDwAAAAI/wAPCBxIsKDBgwgTKlzIsKHDhxAjSpxIsaLFixgzatzIsaNHiQZCihxJkmGBkyhTqvzIsqXLlzBjypxJs6bNmzg7GhjAs6fPnwgDBDCgsmjKnEiTKl3KtKnTp1CjEtz5s2rPoEONapXKtavXr2DDih3rkKrVqliJai1Ktq3bt3Djyp1r0OxZnwrVrj1Kt6/fv4ADC65o9y7PvHtXDl7MuLHjx10LG0acGCXky5gza958UfLdtJUtcx5NurTpxp7Pgg5d4LTr17Bje01tdXVo2bhz697tkqTvkSZZ8x5OvLjx48iTK1/OvLnz59CjS59Ovbr169iza9/Ovbv37wJFH/8AQP6hePIAHPIdX74hX/Tp3Z8cCF/9fIHozd9nHz/4/vzy/deef/QBSCB+Bi503oAH8mefgP0pCGGECi3IYIUQ6tcaghQmtF6CGGYYYIEXejjhgyQ+uKGDAa4IoofgxSjjjDTWaOONOOao44489ujjj0AGKSRLv5Wk4lZDJqnkY7RdpZBQeq215JRUAtbkYU9mlViVXHb51pUDLARlZV6WaeZshmG5UJRInunmm0qB2RCbRsFp5501yckQnWzh6eefH+mZ0JhbAmrooRYJapuUiDbq6Jxphpkln4o9aumlAxUJ3JF1Yurpp6CGKuqopJZq6qmopqrqqqy26uqrBVmnqGGKLdLq34b1jchhhwjJiiKHKtoqoYgN5lrsi70SeyyvB31YYrIuItvsibqyWK20BjnLbLa+LrttrNQuGyywtZJrEqzopqvuuuy26+678MYrL6ybVrTevPhaZ9dEhO6X77/S7StRvysCbLBzAkdE8MEMN5cwSPc2LHFxD0cU5cQYU4wXRRdn7LFuFTu08MckxxZyQyOXrLJpJzOU8sowb1YvRRG/GxAAIfkEAQoABwAsBABEAFQCNwCC////k///Sf8AZMj/MsgAZGRkPDw8AAAACP8ADwgcSLCgwYMIEypcyLChw4cQI0qcSLGixYsYM2rcyLGjx4cGQmIsQPKjyZMoU6pcybKly5cwY8p8aWCATYoBAhggWWCmz59AgwodSrSo0aMQa96cmHNnSaRQo0qdSrWq1asZlQ7AqZMn1q9gw4odS7asRK0WnfY0y7at27dw455EW1Gt3Lt48+rdS5YuRbt8AwseTLgwSr8Rm3o1zLix48eOEUNU/BSy5cuYM4uV/JDyWs2gQ4seLTOkgZGVSatezbq169ewY8ueTbu27du4c+vezbu379/AgwsfTry4cYcAkis/wHNxQuXLm6c2CD26dIXVAQiU/vlgdubcsVf/B3/9+fjw5s+XR5hdO3r26td7j99cPHTyzuHffz+f/vSC3+H3H0Hfcdcddf4NOFCB8iGYoH37NQhgggdOGKGEBD6Y3oX5OcihggJpd9yIJJZo4okopqjiiiy26OKLMMYo44w0enRaRhXWqOOOhdVkUQAH7MTjkEQK5mNFQApZ5JJMwnUkTkHm2OSUVFr1ZF1SVqnllkVd+VeWXIYpZkxeTqTkmGimSdNWSEap5ptwHsYmlGfGaeedac3JlJt49uknSBqB+eeghBZq6KGIJqrooow26uijkEYq6aSU6mddfRAmJyCY7W2aqYj8eaipgZ9uyqmGll7aoYUfntqqq6qunpphqwsxiGmqo2K44HiebpirriFSWGqorMYKq7HDEjursce6B+wBnSq7K6reVWrttdhmq+223Hbr7bfgVvosQ6aJFO65vkl3I0Q2tdsUuvDupq5E7dr0brz42jZvRPUOcG++AMe2L731rhvwwawNzG/BCDe8msLsMuzwxKFB3FC//1KssWUWM4SxThuHDFnHC31ssMgoDzbuQuWezG1AACH5BAEKAAcALAcARABGAjcAgv///5P//0n/AGTI/zLIAGRkZDw8PAAAAAj/AA8IHEiwoMGDCBMqXMiwocOHECNKnEixosWLGDNq3MixI0cDIEOKFNmwgMmTKFF6XMmypcuXMGPKnEmzps2bHg0M2MmzZ8+EAQIYSEn0JM6jSJMqXcq0qdOnUAXq9El1J1ChRYtG3cq1q9evYMOKVTi1qs+rQ7OmHMu2rdu3cOPKPVDWLM+FadUancu3r9+/gAM/rGt3AF69KgUrXsy4seOmhO0eRmzyseXLmDNrhhjZLFrKlTeLHk26tN/OVT+DNs26tevXkAv/RBg0L2LYuHPr3q1xpO+QJVfzHk68uPHjyJMrX868ufPn0KNLn069uvXr2LNr3869u/fMiQGI/wfgMPz44HvHk2e49oB69AUEql+/0Px59unv4w/9fj9//QrZJx588vVXX34DEugegAm1Z2CAAio4n4QPNoggfQf+l2CGGmJoYYceIiRgiAdFSOGGEF743YostujiizDGKOOMNNZo44045qjjjjn+5lt5lPEo5JCKoXaWarcRqeSScRk5G21YBcnklFSC5eRdSOpV5ZZcPnWlVZMl2eWYZNr0pWFhalnmmmy6dCZDtqnV5px09iYbmFDGmVWdfPYZ0ZtZyunnoIQeBGiewhWqKKE+jgSkmItGKumklFZq6aWYZqrpppx26umnoIb6qYn+FYjihx3CF9+Cp4p4IYkGjZ54IqyxqujfqhW6CuKstBJEKoem9jqQgwzqmmqprLZa4quzPoprscvaCmyywgokK7K5GhusqtuK6u234IYr7rjklmvuueiG+yNFRKXrLnWRRVRbu+/W+1y8EM3bnr38KofvQ/om1u/Axv3LGb0EJ8ybwYMhrPDDsDHskJ4QV/yaxAsFvJfFHJOGsUIah9bxyJp9HOiqJKds2boTOfxtQAAh+QQBCgAHACwBAEQAVwI3AIL///+T//9J/wBkyP8yyABkZGQ8PDwAAAAI/wAPCBxIsKDBgwgTKlzIsKHDhxAjSpxIsaLFixgzatzIEaOBjyBDihw5kmGBkyhTqly5sqPLlzBjypxJs6bNmzhz6qRpYIDPn0CDCvUZIIABkyyTKj25s6nTp1CjSp1KtarVgj2Hah1a9OjCpWBbXh1LtqzZs2jTqlWYdatbokaRhp27tq7du3jz6t17oO3bt14Vzh3Mt7Dhw4gTK37o9+/WwAkH011MubLly5ilNnY8FDJCyWEzix5NurRph5s5/+wqF3TS07Bjy55tOLXqAay/ulZKu7fv38Cj2ladW/Du18GTK1/O3CLJ59BBtj6esrn169iza9/Ovbv37+DDi/8fT768+fPo06tfz769+/fw48vnvhKA/fvTC9zHrxvlgf329ecfgAAIeBKB+SFooH4AJtigcdUpGJlK/+3noIULSjhhShp+FuGDGw4IooccjkgiSh0eVJ+JKqqUYkEtvUhQjBhCiCKLBq1YY4gH4jgjhTIOVN18RBZp5JFIJqnkkkw26eSTUEYp5ZRUVglTdFiWZCN1/lnp5Zd5DcdZcSdyyRSYaKZ5lpiOkdmimV2qKeecmt3GVVxbmknnnnzqxCZnnuUIZ5x9FmqoS386FiiMg5556KOQOmenVov+2GikmGbK2KRBuSnopZqGKipWnALlKaOgjqqqpom6daqlg67uKiumWdb60YJczqrrrrz26uuvwAYr7LDEFmvsscgmq+yy6unIX55BCvnhjm+KSO2nN16LbY/aoprtszwy2K2004JbLVM+wsqtueeKy+627gZoYIXjCkRjvQc4Ky+06ZL77b7hRpsvkP0OXG6BGRZs8L8I84vvve/CyuzEFFds8cUYZ6zxxhx37HFFttYKb64fl5xdq1t52qijJre8HMpaqbyyyzQrB/Odga5cQM08/3YzpSNT1/PQs/3cWdDHEa30aUYLlfPMS0ctWtOr4amunlJnbRnVcD2dqtZgI8Y1blb7C2fYaB8WcpZI7zZ0QAAh+QQBCgAHACwAACsAWAJXAIL///+T//9J/wBkyP8yyABkZGQ8PDwAAAAI/wABCBxIsKDBgwgTKlzIsKHDhxAjSpxIsaLFixgzatzIsaPHjyBDiix4oKTJkyhTqlzJsqXLlzBjypxJs6bNmzhz6tzJs6fPn0CDCh1KtKjRo0iTKl3KtKnTp1CjSp1KtarVq1izat3KtavXr2DDih1LtqzZs2jTql3Ltm1KA3Djyp1Ll67bu3jz6t3L16eBAYADCx5MGHCAAAb6Kl7MuLHjsn8LSy58OPHjy5gza94MNPLkz4YRcx5NurTpzZ5Bg7Z8urXr17Ahq57NOrbt27hzL009W3Jt3cCDCx8ek3dvwZWJK1/OPLjx46F/N59OvTrm59CTW9/OvXveuuDDx//1Tr68+fPo06tfz769+/fw48ufT7++zwL48+vfz7+///8ABijggAQWaOCBCCao4IIMNujggxBGKOGEFFZo4YUY7mffhhx2GJNBKkWUkkQjiogSiSdCFKKKJT7UoospsniSiTE6tCKMM9JoEoo5yrijjz/iGKSQJfE4pI01NnQjkkky9CKTRy7k4ZRUVmnllVhmqeWWpEXI5ZdgbuZlmGTGJ96Zduk1ZplssofdcdrltWabdJ73Zm9x4jVnnXx2d+dsed61Z5+EUvdnb9K1NWihjCp3KG17LdropMA9qlqibElK6aa2WTpZoG5pyumorXkqGaiKQkjqqp1CR5lorMb/KqtOaNYK16y45qrrrrz26uuvwAYr7LBtFpASgscemGyBKimLErLPOnsStNMa2Ky1yxKYrbbRYluttyZJ+y2345IbrrglUXsus9sKeC275Q7YrrvdmruuvcTmq2+RJD3pZJP/9kjkAUbyOzDBQBoMpcILI5ywjlFK6a/EAjdcsMMDQ8xwwBFT3LFCE3u8scgjgxxyQiejDLDK+7bs8sswxyxzfaLObPOGNd+sc1K21iqoqjsH/ZSpr2J6Vs5CJ92Zq4ShihbSSke9E9FNw5rqg1JnTRTVhRltFtRahy0T14R5XRbYYqfdEtmDmU0W2mrHjRLb0f2Mtdx4z0T3AE4f0Q103oC7tHffgRcOW89oGq744ow37vjjkEcu+eSjGVsvvuqmC+698l7eebz0gh7gvAC+i+8B6KKeeuaqb9766avH7jrrqb/+uej/kV6656Fz3rvvo1Mu/HIjFW/88cgnr/zyzDfv/PPQRz/R8NRXb/312A8Fd/bcY7V99+BP9X345Ds1fvnoJ3V++uwTtX778P/0fvz06zR//fjXdH/+/MO0f/8AXMn/AkjAAhrwgAhMoAIXyMAGOvCBecuQBCdIwQpa8IIYzKAGN8jBDnowQQEBACH5BAEKAAcALAAAKgBYAkQAgv///5P//0n/AGTI/zLIAGRkZDw8PAAAAAj/AAEIHEiwoMGDCBMqXMiwocOHECNKnEixosWLGDNq3Mixo8ePIEOKLFigpMmTKFOqXMmypcuXMGPKnEmzps2bOHPq3Mmzp8+fQIMKHUq0KMoDSJMqXcq0qdOnUKNKnUq1qtWrWLNq3cq1q9evYMOKHUu2rNmzaNOqXcu2rdu3cOPKnUu3rt27ePPq3cu3r9+/gAMLHky4sOHBBhIrXsy4cePDkCNLnky5suWvBgZo3sy5s2fNAQIYmOrzsunTqFOrXn0g8+fXn0OPllqate3buHPrXusatm/Qokn33E28uPHjyJH2/v17dtTayaNLn04dMfPrzqFCr869u/fvaZdf/3+d/el28OjTq1//VPx4zrKF82RPv7797u7fAy/v9Pz9/wAGqFp++sVH23ACJqjggpA55uCDism3E4MUVmghcv5dqOGGHHbo4YcghijiiCSWaOKJKKao4oostujii/RF1JSMTNGolEQ12pgUjkvpuCNEOQLZo48H8HijkEM+NCOSPzKJlJFNKpmkQ0tKeaSTRRIJ5ZNYZmnllVT2mFJTNDFVk5llLnWmmjOR2SaaMsEZJ5tvKpUmnTG5Oaeddya1Jp91+hmooHsSWihSfxqaJ54w6bkooy/J+aiiLsFo6aWYZqrpppx26umnoIZKH4SkPibqqagmR+B7Bj6HYKqwxv8K16rjtardq7LmqqtZtF5nq3m47irssFz1Oh5/jupE7LLMXmUsdhIq2+y01Db1LHPISppTtdxyey1sv/YXbLfkCvvta+Emu2257JqrX2zBHThfu/TKWuq9iUW7br389qsvTv4GLPDABBds8MEIJ6zwwgw37PDDGxLpZZhTNhTkl1xiueXEFl/cMZgURxlyxhhzzFCVI5P8scgrq9yyySdXHLPMC3n88sY4dymxlmNqWymkkQL9M6CHHtAnpUMT3ajQLfmcNKKDQl200VEnKnXRVlM99dFaY8111lx3vTTTKzndNNk9Q6z22my37fbbcMd9Kr73ym03jOfCm+3V0t6P7Td6eXuWLtI3/W34d4F3Njjf+x7uuHSJe7a32I0/brlxkXc2eYaXd35b5pxtPq7npK8G+gCLUw5w6ayzdnrqnLcu+2SvxyvuvLPnXhndpd6Ku+7Aoxd78MQXb/zxyCev/PLMN+/886eOJP301Fdv/fXYZ6/99tx37/1ERoUv/vjkl2/++einr/767LdvU0AAIfkEAQoABwAsAAAvAFgCNwCC////k///Sf8AZMj/MsgAZGRkPDw8AAAACP8ADwgcSLCgwYMIEypcyLChw4cQI0qcSLGixYsYMx4wwLGjx48MC4gcSbKkxpMoU6pcybKly5cwY8qcSbOmRQMDcurcyRNhgAAGSgolabOo0aNIkypdyrSp05o4eUrV6RPo0KtPs2rdyrWr169gj0adKrVq0KtCw6pdy7at27dwXY4lu1PhWbRE4+rdy7ev379I59LNaRevScCIEytezFix4MGFDY9sTLmy5cuYxQ7uefDnXcmZQ4seTbp0wsd0zUqebLq169ew96Imq3p1gdi4c+verfSjb48hbfMeTry48ePIkytfzry58+fQo0ufTr269evYs2vfzr279+/gkwP/GA9A4VDy6M0LRU9ePVH25d1Phr8wLf2EQw/cR3h+/0H77NVnkn//DRigfCLpdyB/6xFYEIALFvhehBLOR6FBELaHX4bjISgSfPExOGF6HipI4oYjaihiih2iSBKIJcLoYoIOhmfjjTjmqOOOPPbo449ABinkkEQWaeRav/3WkHBHNukkabOVVRtoT1ZpJWVRctaZVatd6eWXf2VZ15SGgWnmmW6JSVVkVKLp5ptbqUkYm2XCaeedvW225mlM4unnnzLJOUBCnvUJ6KGIoiQooVy2meijkE60KJl4RWrppQ0l6duSXWLq6aeghirqqKSWauqpqKaq6qqsturqq7BK3nRihSPJuGKtNQ7EYYi33parrgbOiuGuHhZgK62+XvhgsCr2amKzyD7bYq/G/nrArrwOy2K22loobLc0Kgsss9MiW624AhEbI7rpksstQflZ2x+72K77baz45qvvvvz26++/AAcssG6advSQowPnVrCSCROk5kKF1tmwwnqOOfFGekLcKFoXU1zxnBc/rFDElXYcm6AgTyzyQp9hZTJsKA/a8cp0uvyyazGbTDOfEt9sWs4zZzzyxjb7XBrQIQvNaMv5Gf3zxyk3vLNBJHPs9NFQyxzywgf3fHVoC/sWEAAh+QQBCgAHACwAAEAAWAImAIL///+T//9J/wBkyP8yyABkZGQ8PDwAAAAI/wALCCxwoKDBgwASKgQwsOHBhwcWKmwoEOJDiQAOUCRo0SBGjRQ7epQI0qFIjAw3ioyIcSPHjh9VrowZciZJmSclurSpE6dFmiZzLiw5cCXLoT5/3qwJs2XSi06DNkXKdKpCohV5Xn2KMKpUiCh3Ct1aVSnVr0bTql3Ltq3bt3Djyp1Lt67du3jz6t3Lt6/fv4ADCx5MuLDhw4gTK17MuLHjx5AjS55MubLly5gza97MubPnz6BDix5NurRpuAbuvjzNurXr17Bj7zUwYG6AAwZWy97Nu7fv36Bp28atG7jx48iTK59dW+7t3MujS59OnbpwutCra9/OvTvp63Oze/8fT768ecXg5Yo/z769+/eom8d9Xhy+/fv4z6d/Sz+///8AVrefW/0FaOCBCMqWml31JejggxBGKOGEFFZo4YUYZqjhhhx26OGHIIYo4ogklmjiiSi+hVZXPZUFVYtFaZUQVg2OdFaMY83IlY0LiWXVRDsWBBSOP2YUpJBLrcgikC4uyaSSSN6YVY5GNulklVBGSVaWYR3ZZZZHbUmkWWJOWSSNMibkI5lPjvlimTVqqaOVKdZp55145qnnnnz26eefgAYq6KCMxdnWgoSmaMCijDKaqGgFIApXbQFI+miJtA2g6aaarhXAbZc6FulclFoaqoiZcrqpp6CeutiocpVh6iqmqnLK6qyvmvrWALriymGqtfqaGayk9ipshsCqeuxlxMZq7LIWJmsrtJQ1u+sBlVLbobSrqvWptoNZ65as4GrIbafetlquX+K2Re66F54rn1HfwsvuXc/am2Cj/LoVEAAh+QQBCgAHACwAAC8AWAI3AIL///+T//9J/wBkyP8yyABkZGQ8PDwAAAAI/wAPCBxIsKDBgwgTKlzIsKHDhxAjSpxIsaLFixgzHihQIKMBAxpDihxJsqTJkyhTqlzJsqXLlyk5gqQ4YECAADNh6tzJs6fPn0CDCh06VGbFmjdzEl3KtKnTp1CjSmVqlKZNnFOzat3KtavXrz6rHh2gFKzZs2jTql3bVKzVsmzjyp1Lt65dg24n1oR7t6/fv4AD98wLESlWwYgTK17M+CHhh4b5Np5MubLltI8dRr7MubPnz207YvwIurTp06hTq17NurXr17Bjy55Nu7bt27hz697Nu7fv38CDC18MoDgAgRyTc0RovDly5aIPNi8+EHp0g9OPP1eeMHt16N2nb//nLt37RuvMzaNP73z8cvbGv5Mv3976dYLZtduHH//8fOziuXcffgH6l1x47Rn4Hn397cdgg+Dxp52CAw5kHoUI9oehhAJWeEB+HUqoX4QPTrheicOlqOKKLLbo4oswxijjjDTWaOONOOYo1IIWkabjj0BylllDmwVp5JGKDclQkUg26aRdSi7E5JNUVolWlEuSZeWWXHaFpZRadinmmE59qdBeZKapJlBmHjTlmnDGqVKbBr0p5514akRnQXbm6eefEPFYkY+AFmrooYgmquiijDbq6KOQRirppJRWaumlCtV3YkEgboiigBlSByqHo37qIIABnsqpeiSiquGmqybdCCuBmrZKa63/3QphrrqaaGuv8h1IqqeuiqpqryPyamGBsy4r66/OvgqtQKxO2+mx0e4q7KfExqohpuCGK+645JZr7rnopqsuY4JSROi6jX0kr2QNTZvungT1CS9iBtTk7wARJWUvuvgOpO++gfX7L8AQCaysugULdDDCfyn8b8A4DXxuxAaHSbFiFvs7kQEam8uxxB5/zO/CDEdE8sP3FkCvZimrnDDLI5dcLscT21xXyDVh/PK2CPN81cw+0wV0yw45TPS+RieVtGBLC60zue2OjPTUcc37bkTQBQQAIfkEAQoABwAsBgAvAE0CNwCC////k///Sf8AZMj/MsgAZGRkPDw8AAAACP8ADwgcSLCgwYMIEypcyLChw4cQI0qcSLGixYsYLRbYiNGAx4wgQ4ocSbKkyZMoU6pcybKly5YbCxigOKBmgAAzX+rcybOnz59AgwodSjRmTok1B9w8SrSp06dQo0qdSrXoRqYQky6tyrWr169gw4rdadRiUqxj06pdy7atW6FlK559S7eu3bt48xqMS7MmWr2AAwseTNgl34hacRZezLix48cKD2e1qRiy5cuYM7OV/DDxX82gQ4serTNmx4+kU6tezbq169ewY8ueTbu27du4c+vezbu379/AgwsfTry4caEAkisHIDCmc4TLkw90zhF69OnUE0Zn3jy79eXYnx//3M6denWD5Lt7R39dvenvysO/H9/+gHn48e3fp9/efAH83OknHn/5CTgfe+C5dx6CBe7HYH7+ASjfgQRtN+F/EiqIIYHSaQhgeQ4WlJ6BFA5koYcZkrjhcSy26OKLMMYo44w01mjjjTjmqOOOPE60YEWo9SjkkI5dJZdSlRGp5JKAGdnXVkxGKeVbTk5E2WdTZqklVVX2heWWYIYJl0wX+SXmmWiO+WVDZqbp5puGkflkknDWaedIXSKG5Jp39uknQ3lOBuWfhBYK6IpA8mnooow26uijkEYq6aSUVmrppZhmqummnOY4YoQcBhiiiPWNWmGp6z0oaqqn9meqQJ++4XrAiSpqh+qAql74oYaImngiqLmiGKquKco6660lwvqrrLQCS2qCtRbLaqsNTqusq9Yeiy2u1HYY7bDCdiruuOSWa+656Kar7rrsrvUjRUG2u5hH9CqKkLHoBtrZnvI2ZkBSSUW0FL7n6uvQlf0y9i/AAwiME8HmGswmvwkXtjDADhsAcbkSHzyAvRW7dXHAEmmcbbodTwxyyGyNXNNEJnPLbsoMtclyYC43XPLG5NKcEMI348ywzg8NfHK+clpJcdB65Zwxz+P6jBDQTOflNERGy7zuuzCvXHVY9cYbkXkBAQAh+QQBCgAHACwAACoAWAJWAIL///+T//9J/wBkyP8yyABkZGQ8PDwAAAAI/wALCBxIsKDBgwgTKlzIsKHDhxAjSpxIsaLFixgzatzIsaPHjyBDiix4oKTJkyhTqlzJsqXLlzBjypxJs6bNmzhz6tzJs6fPn0CDCh1KtKjRo0iTKl3KtKnTp1CjSp1KtarVq1izat3KtavXr2DDih1LtqzZs2jTql3LNujGtnDjyp1Lt27Rt3bz6t3Lt69avH4DCx5MuPBdjYYTK17MuDHgxpAjS56c9jHly5gza35qebPnz6BD1+wsurTp055Jo17NunVh1a5jy54NFzbt27hz697Nu7fv38CDCx9OHCuA48iTK1/OvLnz59CjS59Ovbr169iza9/Ovbv37+DDi/8fT768+fPKi6tfz769+/fwrz5UGTGlRPv1Ud7XD5F+f/zz8fffSfsROKCBAQroEIAJmlSgg/khuCCDDfnXYEkPYhghhBdq2OEBG3rY4UHxlWjiiSimWJQBLLbo4oswwqjijDRuZsAAOOao44484hhAAAbUKGRkMcrY3o09Jtnjj0EO6aRdTbpEwJRUVimAACDWZZtPSCrppY9APinmXAYQkBOWBhSgJWJHdfnll1GOKadaZZ55QJprZoSUm28qGeecgJZVZ04E4EnXlj3x2WePfwbqKFiD5mToXIjypOiiOTL56KZhRYrTpHJVutOlmA6gKaeocuVpTVeCGpeoOpH/iumpqdZ61ao0oanmoWwaVeSvwNoqbFW4zqRrnhgNq+xnxaIEbIu7UtrrstRS1qiFCyF7UbXcduvtt+CGK+645JabFXIpXZdudSpZty67KKkbr7vzUtcuvPVO9669+erbr3T7AhxwdAMT/K/BJ8mbML4L83vwcwVDFzHEDzt3r8MN+2vuxhx37PHHRH0YIogjZ0jygSJWSCFD2Kos4YQvu8whzDFnu7LNNeM8M80py9yzzjuzfLNCQxOtIM8nI520zz8bnbPTQUcL8tRUVy3Xs1i7aPXWjsq6KK1ch/2k132CLfbZmMHKEtlvmo02Z9O+zZPaK7Hd57VyL0V33i3t/52S3W/izTdSfg9etMk1AQ6n4U4VznjUFI1a6pJhPq533JbP5LhJiifpduYhYw46TJuX1Dnlgo/+U+mMs57166ofxbrhs8cOVu184257V7rL3fvuWv0O/PDEF2/88ch/i27FFjPP3MUam6Sw9PRmHH1J1VuPsPYSO/+898tN3Dz3FIOfnPjNof89+eVTj7H712PPsPzzHzA9/fHbX7/+7yfv//8ADKBPRkLAAhrwgAhMoAIXyMAGOvCBEJyIACdIQdS8LmsV/MoFsZZBZ02OR5/roFVOB8LKifBOH9xRCE84FRKq0IQidKGOVsjCqMgwUzDs4A11lLoaPmWHOeohAGWBiCMh+pApRByAEf2XxCUeMSlNrCEQafhEJKZwhjnM4BSzWMUfXhGHTkTeFsPYRaKMUYobDFYZpZJGNa7xjXCMoxznSMc62vGOeMyjHmuInj768Y+ADKQgB0nIQhrykIhMJHYCAgAh+QQBCgAHACwAACwAWAJUAIL///+T//9J/wBkyP8yyABkZGQ8PDwAAAAI/wABCBxIsKDBgwgTKlzIsKHDhxAjSpxIsaLFixgzatzIsaPHjyBDiix4oKTJkyhTqlzJsqXLlzBjypxJs6bNmzhz6tzJs6fPn0CDCh1KtKjRo0iTKl3KtKnTp1CjSp1KtarVq1izat3KtavXr2DDih1LtqzZs2jTql3LlqmBt3Djyp07t63du3jz6t1b1MCAv4ADCx78N0AAA3wTK17MuPFav4QjEzaM2LHly5gzazYKWbLnwoc3ix5NurTpzp8/VzbNurXr12pRp5a8Grbt27hzQ5U9m3Bt3cCDCx9uk3dvwJSJK1/OfLnx4wOSN59Ovfpp6JNDW9/OvXtiuuDDw//1Tr68+fPoyxZYz769+/fw48ufT7++/fv48+vfz7+///8ABijggAQWaOCBCCao4ILupefggxBGKOGEFFZo4YUYZqjhhhx2iFRDKkUUIkQpSVSiiCiZmCKJJz40oosrsniSijPKWCOMMTrU4kPv0WiSjyWhmCOIQxJ5I44/CpkkkkvquKORTZLk4ZRKEUjlla6JN159G1qJ5ZejFXAAAWSWaSaZB2iZpoZegukmZgX8RhMBBwggJ4VtvqknY3HmRKedl2kpaFw/5bnnoXv1mZMAgFr23HHS9WQoopTapaifd36H3WCR8jRppaCSRkCmfD3aW6c7fRrqqpehiZmpx5H/apOqrNZqK0uw9iZrTbTe6quvuc6266/EwjbomWcymlmwnqFa7LO23Tfoq5sK5iy02GarFLOSXavtt+ACNei44ZZr7rmUspfSfuvmp5J+7bqLErvzwlsvfu/Ke+998eK7L7//2tevwANzGbDBJ9GbsL0L+3vwfPk6bJLCEzNcscQXA/ywfOh27PHHIIcs8sgkl2zyycxBGSVDLzp5pMsrs1ykzC/TXPNCLat8AJA7KxmkjO1F9F7PTBJdNM9I2xizQk/qnLTSRusctc1LJ9T0QCjz1WvWXLO6dddgpztg2GTb+nXZaOs27rQznZ22UGsL+vZu1QbmLUtuz/0Tt5Hd/613X3Ujp51Mef/NE9/ZDWu4uIGDpnjDAS6eFOKcDi75UZT7RlPhl9+U+WCPd67T54KFXhLnotNEemCmp15c44C17rpXq8c+O1G1+337WLlbvrtPvcv+e1bBD89447obTzvsySsvU9xqOm8W9OJJbz2o6m7MsfbwRaxxxt+fbrH4+oKPMOQEcz+0+uujn77555Mfvvzv01//ARTbHz/+5cMPccH0AWAA2dcgAmbPgOvx3v2ux8AGOvCBEIygBCdIQbCM5IIYzKAGN8jBDnrwgyAMoQhHOJEGoq6CTjmh9FSIwqWwUHkvbCFSYjg8GsqwKDbcXQ5vKJQdzs6HPCzU2EeCCMQgSmqIPCyiEVOFxBsqcYk5eeLlpAjFWTWxiljMoha3yMUuevGLYAyjGMdIRhwy6IxoTKMa18jGNrrxjXCMoxznuJ+AAAAh+QQBCgAHACwAABYAWAJZAIL///+T//9J/wBkyP8yyABkZGQ8PDwAAAAI/wABCBxIsKDBgwgTKlzIsKHDhxAjSpxIsaLFixgzatzIsaPHjyBDiix4oKTJkyhTqlzJsqXLlzBjypxJs6bNmzhz6tzJs6fPn0CDCh1KtKjRo0iTKl3KtKnTp1CjSp1KtarVq1izat3KtavXr2DDih1LtqzZs2jTql3LVqqBt3Djyp07t63du3jz6t1b1MCAv4ADCx78N0AAA3wTK17MuPFav4QjEzaM2LHly5gzazYKWbLnwoc3ix5NurTpzp8/VzbNurXr12pRp5a8Grbt27hzQ5U9m3Bt3cCDCx9uk3dvwJSJK1/OfLnx4wOSN59Ovfpp6JNDW9/OvXtiuuDDw//1Tr68+fPo06tfz769+/fw48ufT7++/fv48+vfz79/6wIABlgATQICWFOBAxJY4IELzoRggjI9qKCADFI4YYAXYuggghlCGGGDG1oYooYfghiThCMa2GGFJJ7IYYoqltiiiyKW6N+NOOao44489ujjj0AGKeSQRBbZnnhI1uXTg0w2OaORUEaZ0nPHSdeTk1i+KOWWXFLZm5U8ZSlmjFyWaaSXs4G505himulmkWj29ptObGb55p1BxjnbnDnViSWegPaoZ2p84uSnk4EmmuOgkqlJ56FMKippf4xG5mifkKI46ab3VZpdoTdlqimnpMqX5Klv/SSqlqW26uqrsMb/KuustNZq66245qrrrrz26qtZox5wEEqsljTsScUKSxKxJhq7LLLNKksQs9EaRG2N0k4LLbbZDnQtmc5qu+2T1o5L7rMlBXusScmum2616L7Lbbnmehiut/Xa2y0A34Lr7gHtxgswvOKySzC+Bh8sUL/2/htwvA8jnPCvFFcMH6jIWqwxkAYQ8BLG6W4scqce4yTAAQboO/LKR5Z808kpP4XqqSyuqjLLxc2M5KYd5wTzzUd5OtilLtnMLc7FYTe0dpL2rFPMTgktGNEtGf0k0jVJHRjVukLdlNbIMS2jzVg/rfTUYpdNFNiBgayS1eCqPRPbgLktt9lnC2Y3w5ne/5103m37vTbggXcoquA00f3X3ognTnh0acMEN9CNT/k415X/DTjmb8OdOUx0c/65TKFH/tLko7tUOuOpt6Tzzob33fpKr4s3++2456777rz37vvvwAcv/PDEn/TvS8e7RK9My8fUPEzPKx99S8lTLzDy10tfMPTTs1S999lbvz3342Nfvvjng5+++hI7Hz77C8/0/Urzq9R98fjnr//+/Pfv//8AvAzqAkiUARbPgAQMCgKHt8AELslz+GugA8MEwQNWcIIPtFr+JIhBTGkwghfs4JpCKDwOitAmJvRdCk8Io8OB8IMsfBQMibfCGEqOhDbMoQ53yMMe+vCHQAyiEB+HSMSiTe6ISEyiEpfIxCY68YlQjKIUp0jFKlpRQAEBACH5BAEKAAcALAAAFABYAkUAgv///5P//0n/AGTI/zLIAGRkZDw8PAAAAAj/AAEIHEiwoMGDCBMqXMiwocOHECNKnEixosWLGDNq3Mixo8ePIEOKLHigpMmTKFOqXMmypcuXMGPKnEmzps2bOHPq3Mmzp8+fQIMKHUq0KMoCSJMqXcq0qdOnUKNKnUq1qtWrWLNq3cq1q9evYMOKHUu2rNmzaJcaXcu2rdu3cOPKnUu3rt27ePPq3cu3r9+/gAMLHky4sOHDiEsaWMy4sePHjxNLnky5suXLmGkaGMC5s+fPoDkHCGAgs+nTqFOrXh1U6YHQsGGPLs26tu3buHNLVkqbpufZuoMLH068+FDeNkH3Ns68ufPnxJHXVA69uvXr2ClLT955efbv4MOL/3+7ffoA4OPTq1/PvmZ53+dJt59Pv/769zF/y7fPv79/5rxBJmBkjf1n4IEIqhZWggw26OBuYD0o4YQUVmjhhRhmqOGGHHbo4YcghijiiCYppFJEJ0KUkkQroogSiy+q2OJDM9IYo4wnwZgjjjvaeKNDNQL5o5A9EllkQyn6WKKLRyI5pJNNLpSkkUsqWRJDJGap5ZYlFaDSVSlhFSaYR5F5kplnWvWlmmWymaabJqEZJ5xzVjUmnQeI2aade061Jp99SnUnoHUS2iWeeSIqZ6J46snlo5BGKumklFZqaW4DZirgpZx2qttmsYXaGXqelmpqZki9JqqopJ7q6quHIf/l3Uyi7Qfrrbj+JStOns2a66/AyrXrTb0Ga+yx5BXgK60DLIvss9DqNCxOrUZr7bXuKatTtdh26+1K05rH7bfkfiurpugesFi57Ja7YLvwevtuvPTWa++9+Oar77789uvvv7eZGCSWA0v5JMFRGpywwAsjNCWUVVp5gI4RUzkxjxUj3PBBBSucscZXYhyyxBdLTPHIJjP5McMbG/QwyCUnBPDM2Ho5qJ+BCppzVDfj/CZVfwLdM887QzU00T/7nLTORTt1tNFNOx11U09LPbVaVVN9NdZLM12o0l97HTbSY5N9KKI0p632hEKv7Xalyqb7krNGoWv3um9Tdrfd7tLu/RIBBwjgN1GgrhrbuHkXVrjhoSEerbY4AS44XYwfHkDielcu2+Wu1Tx4S5J/jnmCi9s0W+fXQp4TAaL3xdnokpV+kwGoW6t65K3z9TrsiMluE+1JdXv7TazzfqHvNQGfquerB577XqMZfxjyMp0ePPOROz9Z9NIr7pnppNX++AEElG/++eWDrn33E1Ifk/XLY8v33HTtnSn7hBVo/2Pi4//TvP4TDAAD6JMBEtAvBjygAhfIwAY68IEQjKAEVzOSClrwghjMoAY3yMEOevCDIAzhRCZIwv+k5YQoTKEKV8jCFrrwhTCMoQxnmJWAAAAh+QQBCgAHACwAABQAWAJWAIL///+T//9J/wBkyP8yyABkZGQ8PDwAAAAI/wALCBxIsKDBgwgTKlzIsKHDhxAjSpxIsaLFixgzatzIsaPHjyBDiix4oKTJkyhTqlzJsqXLlzBjypxJs6bNmzhz6tzJs6fPn0CDCh1KtKjRo0iTKl3KtKnTp1CjSp1KtarVq1izat3KtavXr2DDih1LtqzZs2jTql3L1urGtnDjyp1Lt27Rt3bz6t3Lt69avH4DCx5MuPBdjYYTK17MuDHgxpAjS56c9jHly5gza35qebPnz6BD1+wsurTp055Jo17NunVh1a5jy54NFzbt27hz697Nu7fv38CDCx9OfCiA48iTK1/OvLnz59CjS59Ovbr169iza9/Ovbv37+DDi/8fT768+fPKi6tfz769+/fwrypUGZE+xJQS8ddHmZ//ff0PARigf/+d1J+BBSI4IIEOCdgggw8qGKGEDdm3oEkHYrgfhRVCyJCFE2p4YUkfxmfiiSimqGJWBrTo4oswxhjjijTWuJkBA+So44489phjAAEYYOOQREKGo49I+gikkEU26eRNtg11ZJJU/hjkk1hm+VKUQk1ZZZVMainmmAdwGZSXXyYZJplsOmkmUGim6eOabdZp45s/xSmnjkva6eediDGl554D9PnnoSni6dOgexqK6KPwKdqTjJRW6iKkmLonaaacdtrSpp6GKiqoopZq6qmopqrqqqy2iuV1KVn/p5KssVZXq60owZorrSfx2iuuvwJrkq7BUnfrdLMKO6yyBxC7LLO+PovssdJRW+2u0EbbLLPbGpurq+CGK+645LI0n4MlergQuumKOGKZG7rbobrnctguifHim6C+IfI7r731yvuvvwPD+67B/SJccIYE36vwwvs2HLDA69JLULkYZ6xxXZZ2POPGIBPJqJyOhmxyUh7TydjIaZZ88ss2qawSATTXbLMAApTJWaB5EqrklTDHRCqbBhCQU84GFLBzRmf6jKTMQYN4EapFH31A0ktj1LTTPUIdtcUMh1p1TgRg7dTQLLEsp9dfU0wR1UbrZHZTaK+kdpUut83u26eO/53T3EzVrdLdVOatN8ATwX20AIAvJXhKhCdp+OESJ9533DchrfTZPC+acsqUr/R4ln7bpHnWU4cu1uhYlm63x5vT3bnqXrH+JNtuG4S6RbSHZXvvwAcv/PDEF0+5syVp2+202DIvrfPJa4v88tc2X/3z10ef7fbQa9899dFZG7712YMPXbLekn+++usX2/30yktv/Pz012+/4yPlr//+/Pfv//8ADKAAB0jAAobtfghM4Gw+BzoFCoqBHXPgori2o8lJUEoU5BPQLii3DFoJdxycoActGMKYRA5JJCzhpDxYqA2qsCYnVNMLixLDp80wZizMEQhveJMazomHNPFh11uAuDUW7pCIJRGiBo+IRBOyMIVNTOITXRjFv02RiURU4geryBMtthCLQIRgBLkoNzFWioxoTKMa18jGNrrxjXCMoxznaDL02PGOeMyjHvfIxz768Y+ADKQgsRMQACH5BAEKAAcALAAAJwBYAkUAgv///5P//0n/AGTI/zLIAGRkZDw8PAAAAAj/AAsIHEiwoMGDCBMqXMiwocOHECNKnEixosWLGDNq3Mixo8ePIEOKLHigpMmTKFOqXMmypcuXMGPKnEmzps2bOHPq3Mmzp8+fQIMKHUq0KEoASJMqXcq0qdOnUKNKnUq1qtWrWLNq3cq1q9evYMOKHUu2rNmzaJcaXcu2rdu3cOPKnUu3rt27ePPq3cu3r9+/gAMLHky4sOHDiFduTMy4sePHkCNLprl4suXLmDNr3kyUoIHPoEOLHm3gQGjOqFOrXs26sWebA2IPCBCgdOvbuHPr3i309c3YtG3zHk68uPHdvmHPrn28ufPn0B0nryl7gPDo2LNr3w53uszqsa9z/x9Pvrx5md5jgrd+vr379+XTw6weHL79+/iJEzywvr9/4MzlJ+CABKJmwH8I0hdggQw26CBipEUoIWgPVmjhhRhmqOGGHHbo4YcghijiiCSW+KFEKUWkkoopQtSiiyihGCOLJ9FYI4w34miSjDk+9KJDK+q4o5AH8DgkkTYeCeSPDTHZ5IxIJlkkkVP6GKOJWGapZUpNcXmVl1aBSZVKXx5V5klYiTmmmVWRGaaaUsEZJ5tt0rkmmm/aOSeeeZqUpp57+tmnoHUCCpWcUSF6qKFPuTnVlpBGKumklFZq6aXNVYbpppzepmmnoDr4pHMDTWjqZ6ahGuqq4xUA06mmPf9X6m8AisfqrbLaOhMBBwig63Cz4rTcr7gWCyyxMPHqq6wCIfvSsMZGe1wBzr4kwLKkNpuTbNVK6y1q1O5EQLeeaqsct9+mm1u4Oo3LLLvUVUeuuvRGBq9NBOQ7L2vBxgttvQBzdm9Nyu672kD8JZhgfQE3jNnANBWM3YEKI8iwwxjbW22+HHec77UGt3bqyKpmbLJrr4588sost+zyyzDHLPPMNGcqpZRVLgmlzkryXJKRP99MpdBRFm1lj6MizVCQR/ecdNBGPw21z1NLDXTOVF+N8801d+01oUop2iijY/N5p9mPku2U2Gur3aXbarHNlKNnl/Qn2mnjHajdg/L/XSjYdR9wN+B5E56o3HHDHbbii+t9uONlQz7315RXbvnlmGfO0qeau6ZR54BxDjpioo9+V2kkm+qq6Yadljpp+7Gu14E5BWDa6rIPRnFsNgUXe+6nD1B7bbgDD9juwtfkO8LG20U7Tr43HxjyvRPPvPRzPZ+TAcVjvxf1N3F/vfdwaf8b9+T3Bb5N4guUflzmw4b++7NXh1P73dNvVPw02T6//sGTTfXwB8C2IK9i66FNkQoYQAT2R4G/YyBRDuhA2VxMgtmr4AMXhMH9vW5CHaTLB0EYwhKa8IQoTKEKV8jCFv5lJDCMoQxnSMMa2vCGOMyhDnfIw4m48IfnSYsQFIdIxCIa8YhITKISl8jEJjoxKwEBACH5BAEKAAcALAcALgBLAjcAgv///5P//0n/AGTI/zLIAGRkZDw8PAAAAAj/AA8IHEiwoMGDCBMqXMiwocOHECNKnEixosWLGDNqJFigY0eLBkKG3EiypMmTKFOqXMmypcuXMGPKHOixowGJA3LmDBDg5syfQIMKHUq0qNGjSDXWLOATos6dPZNKnUq1qtWrWLOmXNr04dMBPLtqHUu2rNmzaNNO5Erxq1i1cOPKnUu3Lkq2E93a3cu3r9+/cPHifPoWsOHDiBMrNinY69OwiyNLnky5cmOHXyFX3sy5s2e0lxtmjvq5tOnTqH8uBSmycOrXsGPLnk27tu3buHPr3s27t+/fwIMLH068uPHjyJMrX34cgPPnNFcjfA5d4NICCak7j15zunYA1q97/6fOvfvB7+U/jq9+QPz67eHNG/wOPr7H9/CvYz+vPf1+/uTZpx6A7LlHIHztSTcfegkqWBCDDcr3YH8C/rdggBEOeGGBDhJEX4UWesigfvj5lx2FGYYoIoYGTohii8zFKOOMNNZo44045qjjjjz26OOPQAZp1H0XiSTkkUhaZlNbULmW5JNQ2uWRkwvppFmUWGY515RMgkWalmCGWRaXFelEpZhopkkUmV2eqeabcL7EZl45uRnnnXiWNKdTTebp5593LUmnl3YCauihCu3pGKGINuqoQ0SyVuijlFZq6aWYZqrpppx26umnoIYq6qiklkochDCuyKGELq4aaavVkfp4YH0pqigQqh2qimCqA+HKaq++vqprfrweEKyGsNJarLEv5gosi84yS6GsG+5a7LG23trsr8+6imy3sV47orjQcqttucIOa+KsykZr6rvwxivvvPTWa++9+Oa716QLZauvUa1dZO6/KBkwgEUBHGCAvwQPZbBOE4U1cMMlGYywwgxTDNTDOUXc08Qaa2RxRQkvHDJSHB8skcTpnkzSyCBl7DJMKVe0cMszZwSzzTLn3FLNFN38rc8Y7Rx0z0SrBPREQiOdtENGR1Sy00+btDRELA9dNdMqUzT11jNd/VDWVIONUNRYY2x2TGI7RPbaICkF90sBWwTyQwEBACH5BAEKAAcALAEALgBXAjcAgv///5P//0n/AGTI/zLIAGRkZDw8PAAAAAj/AA8IHEiwoMGDCBMqXMiwocOHECNKnEixosWLGDNqfFigY4GLBkIa2EiypMmTKFOqXMmypcuXMGPKhOixwEiJA3IOCBDg5syfQIMKHUq0qNGjSF3W9AlR586eSaNKnUq1qtWrWIMuneiUJ9OsYMOKHUu2rFmUWyk6/Xq2rdu3cOPKBZqWq062c/Pq3cu3b966OO/6HUy4sOHDRAE/7AoVsePHkCNLZqjYIWO8kzNr3sz5bOWGlzuLHk26NNKaIEWaXs26tevXsGPLnk27tu3buHPr3s27t+/fwIMLH068uPHjyOnW7IgQgPPnA5d/bP7cefTlCatbFyiduvbrqA9q/98ufbrB8eA9Zv/OHbt36O3Di2d/oPt89uXfb69v/zz9/v5Vlx5z+gEwoHkFjWcgf+4FKCCD8iX4X4MO7geghA9CSGCFFlJIkILxRfjhhCKOmOGFJsKnIYIYqqhecjDGKOOMNNZo44045qjjjjz26OOPQML1okWqBWnkkZx5hBlDOnmF5JNQPqakWjk5GeWVWPI1pV1PLZnll2CGtSWVA3gZ5ploRjUml2am6eabytlkkWBw1mmnVh21iVCTjd3p558srdlUlX0CauihGgm6GKF6IuroowcNWVGRkFZq6aWYZqrpppx26umnoIYq6qiklmrqnfnd56KHKXZY4kDohfu4YYurvnoAiCuyCCuJktK64IrrncjqrsLaimuqHB6oq0CxAlvggcHW2iuxDyLr64LWtvoritS6Om232w57a7PcjotfueSKa660s/oK7bPxnSrvvPTWa++9+Oar77780tYoZf0mJdK/CNkaMFAGDGBRAAcYsOzBCDs1kVcGQyxTwgs3/LDFF0ssEcXfctxxxg6LPFTCOk3cU8Umt4QxSBu37LLHEzkcsswzY1QyzjOhnNOkLPOM0stExiz00DRLZHO7R7NE9MQaNw2Tzwp/vPLNUpv09MdRZz1zylYvbbTXGm0dEcM7k60S1SqLrfZKBCs09ttEUkpR0BgFBAAh+QQBCgAHACwAACkAWAJXAIL///+T//9J/wBkyP8yyABkZGQ8PDwAAAAI/wALCBxIsKDBgwgTKlzIsKHDhxAjSpxIsaLFixgzatzIsaPHjyBDiix4oKTJkyhTqlzJsqXLlzBjypxJs6bNmzhz6tzJs6fPn0CDCh1KtKjRo0iTKl3KtKnTp1CjSp1KtarVq1izat3KtavXr2DDih1LtqzZs2jTql3LNu3GtnDjyp1Lt27Rt3bz6t3Lt69avH4DCx5MuPBdjYYTK17MuDHgxpAjS57sFjHly5gza5b6eLPnz6BD2+wsurTp059Jo17NurVh1a5jy54dFzbt27hz697Nu7fv38CDCx9OvLjx48inAljOvLnz59CjS59Ovbr169iza9/Ovbv37+DDi/8fT768+fPo06tf7zy5+/fwaxZQGTGlRPv1Ud7XD5F+f/7/nbSfgPkR+JB/B+KXoIELmjSggwEy2BCCDinYYEkPYlgghBdq2GGGB4AIYnwklmjiiSimqOKKLFZlwIswxijjjDO2aOONixkwwI489ujjjzsGEIABOBZpFY01pmZZVDoC6SSQQhJp5JRDSekSAVhmqaUAAoSoZEZTNfnkmEEOSeWZQBlAQE5dGjCfZ7YpJSaZZFqJ5p05qcnmAW5+iVGYdAZqJ56E0qRnTgT0CeeSUM0ZqJODFirpS4fm+eZmcSbl6KM9RjnppzBVipOimDL61KaclhkpqKyaJGpNXJL/qlmmSKGaqqet5nrSqzS1eemspjqF5LDE6mosn2vi5KufFx3r7Fq8pkQsjL9mRuuz2G61qoUKZevtt+CGK+645JZr7rmoVaeSdutml9J277KLErzzuhsvdvfiW6+9J9HbL7//6rvvdfkSPLDBASOcsHXtCmySvw/LuzDDB6tbsMUVU3dxc+h27DFL1XpYIYAfbijyyBIyROGEJKPMYckRnqwytzO3XPPLLst8s87d0rzQyjuHaLLQMRMNc848J+TzzzYHPeLHUEct9dRUVz3YtFjHaPXWN9rKKa5ch23XtUR5/SjY55IttlVqC2V2oGib2/baU82dZqpPbiuu3XRD/8W3T28/qne4f/fdVOE8BS6ox4gbrlTjOik+ZtzlQu74UZaPivePlJOb+eVEfW6T5E92Pq7ooAeFuqFZZ814sKmzDXvsfs9OO2e2387U6rr37vvvwAcv/PDEF+8exhNrvPF0yzOfsfLJQx+xw9MrXBLE10tcvfUHaL898t9Lnz3A41PfPfnlU/y8dM2zv7770Tsff3QNc3+++fIbr39vI/Xv//8ADKAAB0jAAhrwgAhM4ET2x8AGOvCBEJxJ61wXwTRNcFoVNArpnGS6DN5kg1AykwertDkfdXCEhiphp0SIwrupUFUt3AkIOcfCGPZkhkAanA0p9cIe6XCHEuwhj2x+CMSV4PBHRCwiD4U4gCQqcVdMbOITIyfEE05RWlWs4RVT2EMrbtFVWXTiF6HYRS2OUSVH5JEXz4iSC2KQjSxxY7HgSMc62vGOeMyjHvfIxz768Y94Yo8gB0nIQhrykIhMpCIXychGOpI7AQEAIfkEAQoABwAsAAA9AFgCRQCC////k///Sf8AZMj/MsgAZGRkPDw8AAAACP8ACwgcSLCgwYMIEypcyLChw4cQI0qcSLGixYsYM2rcyLGjx48gQ4oseKCkyZMoU6pcybKly5cwY8qcSbOmzZs4c+rcybOnz59AgwodSrQoSgBIkypdyrSp06dQo0qdSrWq1atYs2rdyrWr169gw4odS7as2bNolxpdy7at27dw48qdS7eu3bt48+rdy7ev37+AAwseTLiw4cOIf25MzLix48eQI0umuXiy5cuYITfMzBloQQOgQ4seTfrA6M6oU6v2DJN0aQOrY8/8XHOAbdsBAsCWzbu375MFdt8kcECA8N/ID9C2eTv38eTQo0cOnpO4cem/l9fGrRu79++Hqef/FHAdfGztNG/bfm6+vXu74quzf38ZfUz1t+fT38+faHycBOjX32P2wYTfegMmqKBiAsJEwIMNLhgeQRGqhJ9zEmao4WwVtmRdhxsCRtKBJJbIHYghpjjgfzV9qGJkBpgoo3oYvmjjhiyq9OCOPD5IHoo39uXakESGFuSRChbQWpFGIunkk1BGKeWUVFZp5ZVYZqnllly6x5BKEYEJUUoSkRkmSmWiOaaZD7HZppprAnemnG/C6ZCYdZqUJp15ljQnn5u5GSigg+r5p5+HKhcnoQvheaedBnUp6aSUtoVVSleplOlRm550KadWYRqqqFVpOqqnnZr0Kaqnqtqqq6WC/xorq7PCWmtJqdo6lam3HrCqrrvKGqywUvFKFaaVJqvsssw26+yz0EarU2XSVmstf9Req+222A3E5LemgcbtuOTy5u1NzXVX7rrsYnYuTgPU2O689DL2Lrry1qvvviIKBGRK+fEr8MB63Zueev8SrPDCPBk8E34JMyzxxDI5LFO6EVOs8cZwHjDjx/lyLPLIMcX4sYwhk6zyyid967K4LMcs88w012zzzTjnrPPOPGf4paA/Qxq0oYsiWrSiRyeK9KOMNir00Eb3uXShRDPddEJAQz011Vs7/bRCjnK9Z9VWR11212BnnfbXWLOtZM9w2/wrrq/S3evcvuaad9167/99LKl/0xo4sMUSW7jghyMeFeCD23233n1HzjfklPfq97CKQ4Vs3Jx37vnnoK+cbeh+jU66YKafXrBGqhMG28tMvt16XkbCPuRAswsWY04BmCZ77naZPMBNzuEO/F+741T88XcJT7xuxjPPV/LPG/C79HE5b1PxAmE//fA6We/9XNrfZH3349MOPrzipw9X+Tadf7375K+Pbvv0twV/TfLnH7z9Nekd/vxnlP3JhHvzI6BbhHcyEuVGOQpcCwMbeKHeRS+Cb5kgBTGGwQJu0IHq6mD2bFckERKFhCU0oQpXyMIWuvCFMIyhDNsykhra8IY4zKEOd8jDHvrwh0AM4kQbZkjE/qTliEhMohKXyMQmOvGJUIyiFKeYlYAAACH5BAEKAAcALAAALABYAlYAgv///5P//0n/AGTI/zLIAGRkZDw8PAAAAAj/AAEIHEiwoMGDCBMqXMiwocOHECNKnEixosWLGDNq3Mixo8ePIEOKLHigpMmTKFOqXMmypcuXMGPKnEmzps2bOHPq3Mmzp8+fQIMKHUq0qNGjSJMqXcq0qdOnUKNKnUq1qtWrWLNq3cq1q9evYMOKHUu2rNmzaNOqXcu2rUwDcOPKnUuXrtu7ePPq3cvXp4EBgAMLHkwYcIAABvoqXsy4seOyfwtLLnw48ePLmDNr3gw08uTPhhFzHk26tOnNnkGDtny6tevXsCGrns06tu3buHMvTT1bcm3dwIMLHx6Td2/BlYkrX848uPHjoX83n069Oubn0JNb3869e9664MPH//VOvrz58+jTq1/Pvr379/DLF5hPv779+/jz69/Pv7///wAGKOCABBZo4IEIJqjgggw26OCDEEYo4YT2xWfhhRhmqOGGHF6VUEoSgRiRiA+pNCJKIaJ44kkpsgiRiS+S6JCMM6oYo4s3mrQijjXy2KOOO5bUIpAl0sgQjEX62JCRR9r4I5EKdSjllFRW+ZZ441lZFYNadhmVAQSEKeaYYsJUgJdFcYnmmkqBmZMABxhwJptBqUnnnUO5iROccnKH5Z9yKWUnnoT6RcCbcc5pHXbHaYfUoIVGmpOekypaHaO9OXoUpJJ2ShOlOPW5HaazaWoUp56m+hKoN4m6KHSTSf9HFKqq1qoSqzTxaSl1pPYm61C02ipsSbjOpKufsPom6ILDNptSYn+2dOyoyQ5maprMOqttSf6ZiWy1gV277bjkBtUraOKWq+66rQIKKLvwxivvvPTWa++9+DY7YEoCqtQvSvsC/O9JARMcoL8H85uwwQubVLDDA0MMIMITC9wwtxFjfPEBGWv8H8UfW1wxwyNLHLLI3SpcMrf5tuzyyzDHjNOHTj55wJBC5gjlkjXzrGSTPy/EZJRD09yz0EcjHTTRSxu9M9BNH1S00znrfHOQVycZtUFI2oxz1lpXbTPYVMts9tlotxZs2mx3uXbbcE/5dtx0n+Xuu1TNve3d0db/bTe44YqWd7bznvtZun5/ZfhkiDOlt7aLS9Z44lxFTpngUz3urOWETU65VpwX9mtTmjcbOmGjf77V6YOlvlTpw7IumOuqYyV7YLQnBbuwtwOWe+1V3e657oTLKzzmwHt1/O/JG7V884oDHh30Uj1PfeV8i3c9VNlrv/334Icv/vjkl79pxx1zvPHDHp9ssvvt9wdyyijLX7/9JMOv/vob768/+/77H/r6l74B8u+A+gsg/vK3QJaZ74EQjKAEizKSClrwghjMoAY3yMEOevCDIAzhRCZIwhJuZ3cmdAkKU2iTFbJwfgd64fkUJEOeuLCGZioeDluowx365IY7BKIPU1cixBoWcYj3KxASeUjDJf6wh05UIRSjyMQEUVEmR4xiFlm4xSV20YRfvKIYx0jGMprxjGhMoxrXyMY2RpBCcIyjHOdIxzra8Y54zKMe98hHAgUEACH5BAEKAAcALAAAKABYAkcAgv///5P//0n/AGTI/zLIAGRkZDw8PAAAAAj/AAEIHEiwoMGDCBMqXMiwocOHECNKnEixosWLGDNq3Mixo8ePIEOKLHigpMmTKFOqXMmypcuXMGPKnEmzps2bOHPq3Mmzp8+fQIMKHUq0qNGjSJMqXcq0qdOnUKNKnUq1qtWrWLNq3cq1q9egBcKKHUu2rNmzaNOqXcu2rdu3cOPKnUu3rt27ePPq3cu3r9+/gAOT/Uq4sOHDiJMaWMy4sePHjxNLnky5suXLmGkaGMC5s+fPoDkHCGAgs+nTqFOrXl10c+jXoUeXZk27tu3buC27hs1bNOncwIMLH04cpt0DvZNznl28ufPn0DHb3a0cNvPo2LNr3y51evXe17mL/x9PvjxO799j/zbPvr1799NLpv8s+739+/ifx0c+v3P9/AAGKKBq0y12AGQIIjjgggw2eJheDkYo4YSWQUjhhRhmmJWFGnbo4YdIcQjiiCSWaOKJKKao4oAMpSSRixHBCJGMDqkUI0ov4njjSTnyOCONDdn4o49DmtSjkUUi+ZCQS+qY5AFHlhQllE9S2aSTNWKZJZFXKnnQimCGKeaYZJZp5plopkkmWinF1SZcb7qlEpwouVknnSfZmedbc/IZZ1t/Anqnn3sSahKehQqaqKKHIlqSno3KGehafUq6KFuTUjooo5GmpeanoOaW4KgKhnoTpqSGZ+qqTFHX3wD/sf8qU2mpHkDArbjiKoAABxQg669KudpfrMC6ZAABOfFqgK/FNjuUsPMR66xKxyZ7ILMNijhtq6+Cpuq2JlWbEwHLRqgtuIp1+9m36IqbU7kOnovuUdD2xy647oop77ytqevbvfzitKuE+wYsVL3fSWtwmQUv/BPC1SnssL55TWxUqhgbaHGuHOdaq7kVWyyyVxljGm/II6esck4Nr+zyy5seB/PMNNds8804B9iilkHyvDOXW3rZs88KATm00EdLuSPSCzEZNNNFEx010Elb+bTSXUKdkNE/a7211F9T3TTXU4tdNtZZW3312Tm37fbbcMct99x0XypWpmrh7WnMmvL7nbfff9sdeKec9moo4X0Lzibgeyu+uONn6R255GZRXjnjjyOe+KOHc24p5GVZHjrmk4M+mOh1D5cxxqm3zirEykns+uxlwp6c7LTnDqbtveGu+++rtawT78kB3LbwwG+I8sH+dmZ8zsgnf1X0NxEPXuvUS09V9jVZ/5rvxy+vvVfca9Y8+NCLPz5X5c/kvXrP49z++k3NH9PqH9dtP/1K7c8/T/77n1ECKMDzqK+AVSEgAmuiwAX+pIEOjAkEI0jBClrwgpcZiQY3yMEOevCDIAyhCEdIwhKacCIYTKEKV8jCFrowTYKJoQxnSMMa2vCGOMyhDnfIwx7KJSAAIfkEAQoABwAsAAAoAFgCRACC////k///Sf8AZMj/MsgAZGRkPDw8AAAACP8ACwgcSLCgwYMIEypcyLChw4cQI0qcSLGixYsYM2rcyLGjx48gQ4osCKCkyZMoU6pcybKly5cwY8qcSbOmzZs4c+rcybOnz59AgwodSrQoygNIkypdyrSp06dQo0qdSrWq1atYs2rdyrWr169gw4odS7as2bNo06pdy7at27dw48qdS7eu3bt48+rdy7ev37+AAwseTLiw4cOIkW5MzLix48eQI0tOaqCy5QOWM2veXNng5M+gQ4seTXqrgQGoU18NEMCA59KwY8ueTTvw6dSoV7d+Xbu379/Ag3O9jVu364LCkytfzpw2cdVYjxNsTr269euEn+eOzhu79+/gw6P/1T4gq/SB4tOrX89eKnnj3dvLn0+/+nurrM8LrM+/v//e5OEm4ICosXZAfP8lqOCCjHHm4IOXMSjhhBRWaOGFGGao4YYcdujhhyCGKOKIJJZo4olUMcSURCtG1CJELzrUlItLsVgjjUrZmCOMMTY0I487ApmUjkMKWeRDPyJ5o5EH4nikkkHK2KOKUy5UpZVLQvmkQSoxVZOXMzVFk5hhLvWlmWOiWaZSaaoZE5hrJnUmm23KGaedMpGZp5tv8gkTnHvSGaigfRJaKJ6DIjUnon8C6hKKkEYq6aSUVmrppZhmqummnHaK1WKeiuVjqKRCaOpmToFKalQFTHUqZqt6/xoggbQOkF+qGsXKqgFcEXCAALzquumstQ54a5IYCftUAcFq5SuwympKbLG4HXvlRNHO2KxWAkCb7aXTUovbtlFe9G2N5GZFQLrnQhquuKix22RG7Q4pb73RvguvvKri2xUBvvorqb7FWpuluQIn3C7BtRpcrkUKR5wtw7Q6vCXEEj8F8MYcE9BtxiaeKnJlIMclcskop6zyyiy37PLLMMcs88w0N0flwzdfnLNiTvKspc4KXZuQ0AgRfZDRyCE9ndLoHTwqzlhCPTTT+1HdqtM7z/uz1lJKXbTVyD4NdNBYRz12AV36+ZKja7P9qNstwR232m8b2qjddeM9t957M8d6t99t872SnocC3reidSJ+5wGLKl64439DHjnjiVO+eOWWB17z5px37vnnoIcu+uhr9Uv66SUyOzKEsKLu+ojMclVea6/XDmLsW81+r+28T4j7Vhb3LryEv+e++/DI81e8VgMcn/zz7S1/VWrOQ2+9eNJbpfv13NOXfVXbdy/+eq3CWzDt46cv3uqvqu/++/DHL//89Ndv//3456/rSPz37///AAygAAdIwAIa8IAInIhRFsjABjrwgRCMoAQnSMEKWvCCNgkIACH5BAEKAAcALAAAFgBYAlYAgv///5P//0n/AGTI/zLIAGRkZDw8PAAAAAj/AAEIHEiwoMGDCBMqXMiwocOHECNKnEixosWLGDNq3Mixo8ePIEOKLHigpMmTKFOqXMmypcuXMGPKnEmzps2bOHPq3Mmzp8+fQIMKHUq0qNGjSJMqXcq0qdOnUKNKnUq1qtWrWLNq3cq1q9evYMOKHUu2rNmzaNOqXcu2bVIDcOPKnUuXrtu7ePPq3cvXp4EBgAMLHkwYcIAABvoqXsy4seOyfwtLLnw48ePLmDNr3gw08uTPhhFzHk26tOnNnkGDtny6tevXsCGrns06tu3buHMvTT1bcm3dwIMLHx6Td2/BlYkrX848uPHjoX83n069Oubn0JNb3869e9664MPH//VOvrz58+jTq1/Pvr379/BtF5hPv779+/jz69/Pv7///wAGKOCABBZo4IEIJqjgggw26OCDEEYo4YT2xWfhhRhmqOGGHF4FUUoSgRiRiB+iNCKJDqGYooknnhQiiw+p1KKLJdJYo0kv2rgijDvq2JCKP/LYY0k54nijkTECuZCSSwoZpI8AdCjllFRWaWVsDF6p5Za5Zcnll2Ca5mWYZJb52JhYiaemXWa2WSaaV2F3nHZu1sklnFbJ2RuddvZZJZ5V6Tkbn34WyiGgVAnam3SGNmoholMpSpujlGIIqVSSqsZopZymd2lUmU5GaKekllpUqJKNauqqrO6EKmWitf8q66w3rWkrXLTmquuuvPbq66/AOopfSgMSG6BKAiJ7LErFMpuss8ue9Cy0/xkbrUnNSjstttdyC6Cy31Jbrbj+WRuutueiO66663qbbknZuluuufwFa++9+Oarr0xHHlAkkTMC3G/AAg/pL8H/Hjxwvwob3PCTSCYJJUNMJiQjwwhnvPDGDhP8MMVOgjxxk1Dua/LJX96K8qMLrsySAQTELPPMMsNUgMvdfXoyzDkJcIABN+O8nc4m84yTz0Avd6utuhK9r9E3IR00ca8SpuqqTusLNU5JK1f1YFebmnW+W9c69XBfIxcrrWPjW7ZNXVMN3WSbit2y0Ci9PZPUSs//7VvTd+Ntkt4y8e2134XVXWrb9ya2ZkuGy414YGEvHrjg8PZnc9+TR4f551OmTfnaoJeO4dKPm6766qy37vrrsMe+2bDkal77fuC2K6/t7M7bO++7A5/5u8PrfkC8xRuP/PHdJi+88/Xejrv0+tHre/DTU0/779Fznz3230Mfvvjby27++einb9ZI7Lfv/vvwxy///PTXb//9+E+k/v78u8x4/wDEzP8CSEDGDLCACNzLARPIQLcssIEQTMsDI0hBskywghj8ygUzyEGtbLCDIKzKB0NIQqiMsIQoTKEKV8jCFrrwhTCMoQxnSMP9UeiGOMyhDnfIwx768IdADKIQBYdIoIAAACH5BAEKAAcALAAAFgBYAlQAgv///5P//0n/AGTI/zLIAGRkZDw8PAAAAAj/AAsIHEiwoMGDCBMqXMiwocOHECNKnEixosWLGDNq3Mixo8ePIEOKLHigpMmTKFOqXMmypcuXMGPKnEmzps2bOHPq3Mmzp8+fQIMKHUq0qNGjSJMqXcq0qdOnUKNKnUq1qtWrWLNq3cq1q9evYMOKHUu2rNmzaNOqXcu2bdKNbuPKnUu3rl2fcO/q3cu3r1+yef8KHky4sOGfgQ8rXsy48eDEjiNLnkx5LOTKmDNr3vxWI+fPoEOLrnl5tOnTqDGXTs26teu/q1/Lnk1bbezauHPr3g0agO/fwIMLH068uPHjyJMrX868ufPn0KNLn069uvXr2LNr3869u/fgvMOL/x9Pvrz58+jTq1/Pvr379/CRQkwpkX5E+/NR3sfvkH9//fudVB+AD6kUoID5IZigSQMq+B+BDzrYkH8LGWDhhRhmqKGGEEZY0oEMLhhigR1OWCJDFMan4msGDODiizDGKKOLAQRgwIo45thaizP2OGONN+oo5JCf8ejjkTTaSOSSTE5mJJJIBtnklFQS9iSUPkrJ1G1VdumlSVdiOaOWS3H55ZlThinmi0A+ZSaacA6p5poDtOnUm3HmueKca9rZFJ56BurehoQWeqGbngmq6KJVAcroo5DilWiklFYqlKOWZqrpSphu6ummnX4q6qiS/ZaSc6cyp1Jzq6qKEqqvsv8a63Kt0pqqrSfBmqusu7raq3K1AnursL8Sa5Kux/paLHLBJjessSUhGy2vyeK67HGkZqvtttx26+234IYr7rhbiXhAgyOSKKGJ6y5koLnofgjiufPOS6+67SpEIYonuttvQu/imy67AxMsL7wIGaqwhiTtq6/DAP8bcb4Pr0vuxVrxKaafGKfl0MJkduyVxlhyLPJZIBOg8sosCyDAyWKRDKXJMNeMo8xYhmxzx6FmhjOUOu+sl8qp9YzZz1EKXbPRlSHdI81K70VA0JsxTZnTPyoZdVgFUB2Ty15nZrWTdGYd9tZWdZ0TAQcIcHZlY0sG8txog6U2Tmy7fVrcdX/9WsABLAe+8gEKE773pH3XDPK9E4/Gd+KQV4145JTX9njlmGd+pqmzWjut559DG7qznYsu7QHUVis66sqOTvq12Jb+uuqz087ss7fDbhzuudseu+y/604c78G73rvxxbMOuvKra+7889BHL/301Fdv/WMjZa/99tx37/33Cs0NMvjkl2/++R1drxfWMkKt/vtWlt2+1vDXXxj7Mbpv//534S/j2/wLIFv8FyMACvCAKJPfmBDIwLkQMEkGbKAER6ZAGOlvghgEywPrRL8MejBm4ivcB0dIwhKa8IQoTKEKV8jCFrrwhdr6jgxnSMMa2vCGOMyhDnfIwx768DkBAQAh+QQBCgAHACwAABYAWAJUAIL///+T//9J/wBkyP8yyABkZGQ8PDwAAAAI/wABCBxIsKDBgwgTKlzIsKHDhxAjSpxIsaLFixgzatzIsaPHjyBDiix4oKTJkyhTqlzJsqXLlzBjypxJs6bNmzhz6tzJs6fPn0CDCh1KtKjRo0iTKl3KtKnTp1CjSp1KtarVq1izat3KtavXr2DDih1LtqzZs2jTql3Ltu1UA3Djyp1Ll67bu3jz6t3L16eBAYADCx5MGHCAAAb6Kl7MuLHjsn8LSy58OPHjy5gza94MNPLkz4YRcx5NurTpzZ5Bg7Z8urXr17Ahq57NOrbt27hzL009W3Jt3cCDCx8ek3dvwZWJK1/OPLjx46F/N59OvTrm59CTW9/OvXveuuDDx//1Tr68+fPAC6hfz769+/fw48ufT7++/fv48+vfz7+///8ABijggAQWaOCBCCaoYHvoNejggxBGKOGEFFZo4YUYZqjhhhwi5VBKEakUIogQkVgiShKZ+KGKDYl44kkpojgijDOaVKONL+KYY0kx0rjjASG6FxF7Oq7o40Mstigjkkku5CKTR5LU4ZTVDUjllVhSZ2WWXHaZnoBehinma1uOaeaZmdknHlwHrDkemnDGiZaaLqmmnZx45ukVnSv1dqeegAZKFZ8q+SmaoIgm2hShKUEnnaKQRvqTfQdAN9mjkmaq6VDYWYrppqCGmlOnhn4q6qmovkTqbH+m6uqrK63/auehsNZqa5tu5mrqrbz2euV6KekXLH4q5VcssSgJm6yxy953rLPDQnuSstMyWy2y11IarbbNcmsStd9aG6602db3rLclgZuuuOtiOy667cLr67z01mvvvfjmq+++/M5rZJFKLvkvwAw16aTAAwP5o8JQRlkwwgET/LDDE0us0JMJ92jxxRBXzOPCN378kJAhayxywgyjXDJC/bYsVZkum5XrAfTF/BXMNotVwAEE9Ozzzz3jGl6bOXOFc9E37+oSAQcIoDTSTh0NtdFPs8S00xPqOjOZYE4NVgFVsyQA1hLKClqrpkntdVZg70RA2NuZ/Rnapam99t1yT0Y3aXbf/12VAUzn9PbOZVvqG2x9+/1W4DcJ0CbhEeb9GdyOJa54VIDn5LgBkEMo+aWXp5qYmzwD7fPYNGdt+GB7h56puaSrvnpgrbtuO3OfE1b77bwLp3XsvQcvfJjAdgsvu/Gau63y5TL/7vHuPl/z8tM3X7301yfvvPbznbs99/JRnz3NyCNPPrnYh2/89+qej77738M//vD012///fjnr//+/Fs10v8ADKAAB0jAAhrwgAhMoAIXOJH+6cVyDoxgXiAowQqyhYIWzOBZMKjBDuqsax4M4Vo4KMISsg2EJkzhBwOkwhaGhYQujCFTYCjDGtrwhjjMoQ53yMMe+vCHQAzidBcWRMQiGvGISEyiEpfIxCY68YlQ3E9AAAAh+QQBCgAHACwAABQAWAJFAIL///+T//9J/wBkyP8yyABkZGQ8PDwAAAAI/wABCBxIsKDBgwgTKlzIsKHDhxAjSpxIsaLFixgzatzIsaPHjyBDiix4oKTJkyhTqlzJsqXLlzBjypxJs6bNmzhz6tzJs6fPn0CDCh1KtCjKAkiTKl3KtKnTp1CjSp1KtarVq1izat3KtavXr2DDih1LtqzZs2iXGl3Ltq3bt3Djyp1Lt67du3jz6t3Lt6/fv4ADCx5MuLDhw4gTtzTAuLHjx5AhK55MubLly5gzszQwoLPnz6BDdw4QwIDm06hTq17NemfSA6JjxyZturXt27hz6y6ctHZNz7R3Cx9OvLhxn71vgvZ9vLnz59B1J7e5PLr169izI56uvDNz7eDDi/8fv5Y79eDk06tfzz6m+d/o28ufTz/8e5nAS9ffz79/8d6RBRjZAY35Z+CBCJ4WVoIMNuigYQs+KOGEFFZo4YUYZqjhhhx26OGHIIYoImESpRSRSieaCJGKK6JUoospnhSjjC3SWKNJL9r4EIsOoXgjjj8ekCOQQQ5Z0oxE9ghjkUgK2WSTTu444pRUVqkSVSlddaVVW1aVpZZHgXmSmGNy+aWXYZpZppomYXUmlm9OFaecaaK5pp1tspknnnvCeaeffQJaEpmBStWloAc8ZeWijDbq6KOQRirppHIJaGmAlGaq6W2cyeZpft9tKuqolXX6qaekJeoVqay2Cpepp87/VtpXrtZq61CwxhqbAbTe6uuvOeWqa2i8rgrsscjCJOywnxXbVbLQRovSsszS1qu02CJL7bDWGpvtt75uq2u3z4Jrbq2XpssYgdee6+67Eb4rr7nxzmvvvfjmq+++/Pbr778AS2pklEouWbCODfF48JFPNiylwQlDHDHCEye5MMEVW8yQjw9rvLHEH1McsscKcXzxwCg7fDHGIwfsMrx0/mnonFEdGnOhM8ucM85Q2bwzz4rWiaibQt88qJ5H86kq0kTrXHPRT0PdM81TO1010EFb7ZTPUWvdFNUFvCz22BwiSvbZkqqbtrpqo+22iOLGGt/bdE+oKLOizV333gw+qBXqSrLpzffg/vkd06d/E+5qAYk7ajhMiCsOLOM7EdC4g48fvqvkv1KOEwEHCHB5g5lDHprgnLPq+U2gi55h6S/lrV/qtoZNwO245357S62P3rdTvpcU+Oy0o5uusq8Dz/a6AhbvvHr1Pi/9etFPb/312Gev/fbcd+/993yNJP745Jdv/vnop6/++uy37/5E4MdPX1r012///fjnr//+/Pfv//8AzEpAAAAh+QQBCgAHACwAABkAWAI3AIL///+T//9J/wBkyP8yyABkZGQ8PDwAAAAI/wAPCBxIsKDBgwgTKlzIsKHDhxAjSpxIsaLFixgzatzIkWKBjxgNiOxIsqTJkyhTqlzJsqXLlzBjkvxYwADFATgDBLAps6fPn0CDCh1KtKjRmR95SsQ5QKfSo1CjSp1KtarVqyppPoXI1CnWr2DDih1LtizSmhaZbjXLtq3bt3DjutSaFudauXjz6t3L1y3dimr7Ch5MuLDhnn+X5tx5uLHjx5AjJ0wcsStjyZgza97cljLXxXc5ix5NunRMmiFHml7NurXr17Bjy55Nu7bt27hz697Nu7fv38CDCx9OvLjx45gBKFc+kCZqhMuXN3deAHp05gKpVz94Hbv27Qa7T/93nlB8durlr49/zl39efLt3X+3Hn09+4LmD2hPX//9ffzu6YdefP0JCF945s1HIHYG/kdQfvvRJ51/IEnIYIQIyochgAUqmOGEDVa4IAD2gffhhQOe6N2GDwaI3IswxijjjDTWaOONOOao44489ujjj0AmJNKQRBZppGolfqekiUAaGeSTbBnA1JRUVjnlAU4tqaWDPkp5JZRgiuWllWRSieVOW24J5pg4henmV2yWWeaZBqSp5ZpmvqknVXHKaeVAddqpJJ5f7mnoUX36mecBgQrK4o9xHippUYkqyhSgjnoYZKSTdgpUpZYOQGemj3a5qKeowgSqpaOSeuCmp6b/KutKqyraqqsiwlrorLyidOSvRxaEK5c9Otnrscgmq+yyzDbr7LPQRivttNRWa+212PIVYKkCQZgihx1+26KG4g7k7avgoojuuCBye8C5xHZHYoi5sqvuut1uW665+uKbb7j+yluihSvu+26/xB4McMLw1mvvvPQSPK+mDydJ8MAXU8hkxRpLrPHG/4KY7cgkl2zyySinrPLKLLccJMgThfbikhIB63KzaFVEwAECyIzckj4TVKZXNy+bM0U793wj0A4NfVnRyR49UdJBG8d0Q05XDfWkUiOtNXFXN03m11sb2vXUZAsXNtZjl43s2RIRkHZwazNU5txuhwn3Q1QvKa3k11nn3eveDvVtY90JBS74rIQ3ZHiNiCOk+OKpwlyz3xQ3ZDPlBwUEACH5BAEKAAcALAAAFABYAlYAgv///5P//0n/AGTI/zLIAGRkZDw8PAAAAAj/AAsIHEiwoMGDCBMqXMiwocOHECNKnEixosWLGDNq3Mixo8ePIEOKLHigpMmTKFOqXMmypcuXMGPKnEmzps2bOHPq3Mmzp8+fQIMKHUq0qNGjSJMqXcq0qdOnUKNKnUq1qtWrWLNq3cq1q9evYMOKHUu2rNmzaNOqXcu2bdaNbuPKnUu3rl2fcO/q3cu3r1+yef8KHky4sOGfgQ8rXsy48eDEjiNLnkx5LOTKmDNr3pz0MufPoEOLful5tOnTqCuXTs26tWu/q1/Lnk07bezauHPr3s27t+/fwIMLH06cLoDjyJMrX868ufPn0KNLn069uvXr2LNr3869u/fv4MOL/x9Pvrz588qLq1/Pvr379/CvIkwpkX5E+w9V3kdZn//+k/0BCJF+A+LnkIEH+leggAua9B+DCUIYoYMPlhQghfkhyBCBGUrYkIYbKjghhgvFZ+KJKKaoYm8GtOjiizDGGOOKNNa4mQED5Kjjjjz2mGMAARhg45BEOoajj0j6CKSQRTbp5FK3uXRkklT+GGRvBj2ppVdRtjRllVUyuVuWW5b5lkY5fQlmkmLqRqaZcFLVJUtqruljm7m9GeeeT825Up126rgkliTxaWhTfqoEaKADDMqbnodGalSiKS0aqKNjFirppkRRipKMoIbqIqEEcWqqUJ4+CemprOaUqpOrtv8qK02vNhnrrLjmquuuvPbq66+hWZfSdcMKixKxx1ankrHJUlesss06G610y0I7bXTPSnsSstsya5K331obrrglcTuutudSm62610K3LrvpwlvuccDWa++9+Obb6UEglijiiAdUaGGDAxMcsMAXFgzwwR166K/DD5MIcMIML4zwxQZTLHDFH/abkMcf/9sxxCGLPJ++KKesMpyitjzjri6/vPKTltqJaa41+3hqzJLmDObNuPrM45Z4rkTA0UgnLYAAAdM40QGMKnklzFETTUBOTBtQgNMStRn1jkXLKvSOVmN9gNZcR+T11zmG3erYOpadEwForzjR2my7zSrcOcr/nebWdnedUtRAz8r3AH7jVLeKdw/OaOFiV62lAVfjtPTiKTaOEuFT63p44jVlDTjjXc8Ys8w4nz7q5JXfJHraGM0Mc+t0ujx65mjKjjNMC8dXq+7ABy/88MQXb/zxtIF7gLnzkru88so/j2687rZbfbfOR6999tB3z/30zU/3LrbWPzf+9dSbf75z1YLPvPTu04v8/PTXbz9rI+Wv//789+///wAMoAAHSMACPu1+CEygAuOiOpct8IG1OVyPIAfBCppGgjyioAU3+BkM7kiDHAwhZjzII72J8ISSISHYUMjCzKhQRyZsoQwL80IQzvCGf6lh53DIQ8LoMIY9DCJdLxrYMiEa8YhITKISl8jEJjrxiVCMohSnOBb0WPGKWMyiFrfIxS568YtgDKMYsRMQACH5BAEKAAcALAAAJwBYAkUAgv///5P//0n/AGTI/zLIAGRkZDw8PAAAAAj/AAsIHEiwoMGDCBMqXMiwocOHECNKnEixosWLGDNq3Mixo8ePIEOKLHigpMmTKFOqXMmypcuXMGPKnEmzps2bOHPq3Mmzp8+fQIMKHUq0KEoASJMqXcq0qdOnUKNKnUq1qtWrWLNq3cq1q9evYMOKHUu2rNmzaJcaXcu2rdu3cOPKnUu3rt27ePPq3cu3r9+/gAMLHky4sOHDiBPb3Ki4sePHkCNLnsySMeXLmDNr3sy550ADoEOLHk0a9IHQnVOrXs26teHPNwfIDhDAgOvbuHPr3u0TNs4BtG3zHk68uPHbvmMHP868ufPniJPblD1AOPTr2LNrbyt9JnXZ1reL/x9PvvzL7jK/VzfPvr177ehjUl/+vr79+7kHHlDPv796+vgFKOCAmBng34H8AUjgggw2OFhpEEaImoMUVmjhhRhmqOGGHHbo4YcghijiiCTKFVFKEqF4IkopsgiRSiu6+JCKL8o4o40NwVgjjgzReONJLQIZo0lDErmjkUeWFCSSPzKZo49P8rgQlFE6WaWSApWo5ZZclqSUSleBaVVKWJEZ5lFjmlmVmGuimeZJZbrZJpxv0jmnSXHaeaeXZ+o5FZtUAfqnnIESOqifh+JZp6J7HpAno412KemklFZq6aWYZmqpZZrytGSnoHKnUag7fUpqZT1SKmGEp5E20akrrf+KmqwkhVoATLKepiqCB54U3KuwpmQgr7Kx9CtBpBYQXk0EHCDAslsOS6x6vtYGbLAnScursdYiayu0MzX77K7TUmvSsUViqy2C3BpQK6jK6iTAuJOuW66w12Jbkr3+ueSut/CCSxMBApPIL7H4mhrswfz5+26n8epEMLnlUpdwugvf29K/+n2bEwEgFzwiw+ye2y3GsJL8XbsPaxrxTeKKLKLKxNJ2QL760syrzS1n+rJNMVNc8X+16auTzggqeOrPK4Hs9NMgzytziLJWbZrROFldtb63vmQ11mCHLfbYZJdt9tlop622Zuma6nbbSWLZpJVTSlm3kHFjrHfecPP/7bdDOs59c9+Cvy344IcTDrjdCtG49uOQ0/WlmoUaGhXllUOaOZ+R9ono5ZaD/rnomifK+eanm+6o56mr/mjrpJceO+xQYe4666svmjvqu9+u++uRBy/88MQXb/zxQXGK/PJmK8/882EjpPWspUFv/dIHTW2Sf0pf7/2m2dOUYNHflw++QdqfNH765rffofTi98e++/RjCL98B85f//4O3g8TgvrjnwAH5L+XcI98A0xghhCyn6GtT4EQ/BDSDtS9CFqwQtNb1QU3yMEOevCDIAyhCEdIwg+N5IQoTKEKV8jCFrrwhTCMoQxniLMS2vBCacmhDnfIwx768IdADKIQB4dIxCJmJSAAIfkEAQoABwAsAAAWAFgCVgCC////k///Sf8AZMj/MsgAZGRkPDw8AAAACP8AAQgcSLCgwYMIEypcyLChw4cQI0qcSLGixYsYM2rcyLGjx48gQ4oseKCkyZMoU6pcybKly5cwY8qcSbOmzZs4c+rcybOnz59AgwodSrSo0aNIkypdyrSp06dQo0qdSrWq1atYs2rdyrWr169gw4odS7as2bNo06pdy7YtWgNw48qdS5eu27t48+rdy9engQGAAwseTBhwgAAG+ipezLix47J/C0sufDjx48uYM2veDDTy5M+GEXMeTbq06c2eQYO2fLq169ewIauezTq27du4cy9NPVtybd3AgwsfHpN3b8GViStfzjy48eOhfzefTr065ufQk1vfzr173rrgw8f/9U6+vPnz6NOrX8++vfv38NsWmE+/vv37+PPr38+/v///AAYo4IAEFmjggQgmqOCCDDbo4IMQRijhhPbFZ+GFGGao4YYcXgVRShGpFCKIH6IkEYklnjSiiSmq2GJJJ7L44gExuviQiDPWaJKOMK6444w0AuljjzkOGWSRN6LokJIDdejkk1BGKSV7DE5p5ZW5VYnlllyapmWXYGoo3ph24fXldWSmKV2YbNKE3XHa3XXmZW/2FmebeM5U52x3yrcgatBRJlqehBYXKGF9sjXnY3uqlmihkKLUKG15LerYpKqtGemmmK5W6Z+adfqZpptCKupkpKJlaWOn+lbqqya1/zrYo2qtypisyA0Ka6m4BkbrrjL1Gh2wvB46q67E1iTsAL8mC6aaaTprE7RkSmvttdhmq+223HbLZX0qCRhugCkNWK64KKGbLrnnAtiuu+uye5K58f43LrzzqmsSvfnKu6+//+Lbr731EjywwQELXJK+Cfv3LsILM+ztxBRXbPHFUSG5JJMM4ZikjR//qHFDHm8so8kih0ykykeybGTLJJ+M8sozwxwzyDfj3DHHC/Hcs8w50xy0zT8DXXTKTWKs9NLAqgmprdlC3aUBBFRt9dVWw1SAlVJf2/WWVOckwAEGbD3l19KifWXYOI1dNtegkk2teGyqbSXbN7lttpRfLv/bLN9xE4o3Tm+fHbffyH4beJ6D31Q44ArGamyuqUKeYKSNT7t3lH1PPljlnC+OZ+Yz6Q135CUtCxjoUNo9JekymW446mR7LhjrT7ouZWLVsiS75QhKbvvfodNeqMMvbW4t4rgz7XyYzD8vPa9zhzf99dhnr/323HfvvYXgPtzfvRAfwG/DyB88vvj8kZ8++uurHz/87Rc8P/36sV+//Pvjn7/9/fMfftx3P/NJ7HwRA5gBFZbA8iFwgQz8ngQnSMEKmmckGMygBjfIwQ568IMgDKEIR0jCiVjwhChMYWl0p8IWEoeFLoyhbmAowxrGhoY2zOFpcKjDHnKGhz4M4mVEgCjEIi6GiEZMol6QqMQm+sl4ToyiZpgoxSpa8YpYzKIWt8jFLnrxi2AMoxifSKEymvGMaEyjGtfIxja68Y1wjGOAAgIAIfkEAQoABwAsAAAWAFgCVACC////k///Sf8AZMj/MsgAZGRkPDw8AAAACP8ACwgcSLCgwYMIEypcyLChw4cQI0qcSLGixYsYM2rcyLGjx48gQ4oseKCkyZMoU6pcybKly5cwY8qcSbOmzZs4c+rcybOnz59AgwodSrSo0aNIkypdyrSp06dQo0qdSrWq1atYs2rdyrWr169gw4odS7as2bNo06pdy7Yt2o1u48qdS7euXZ9w7+rdy7evX7J5/woeTLiw4Z+BDytezLjx4MSOI0ueTHks5MqYM2venPQy58+gQ4t+6Xm06dOoK5dOzbq1a7+rX8ueTTtt7Nq4c+veTReA79/AgwsfTry48ePIkytfzry58+fQo0ufTr269evYs2vfzr279+C8w4v/H0++vPnz6NOrX8++vfv38JFCTBlRZX3681FKxJ//5H39/fkXYEn7ATjgAQUK+JB9ByZokoME/vfggQgGaMCFGGao4YYbShhhgx5WuCB/DpE4UHwopniAAQO06OKLMMbYYgABGKDijTiixqKMPMpIo405BimkZjv2aOSMNQ6p5JKOFXnkkUAyKSV5t8nl5JM9RllXlVN26RKXbl2JpYxa0gWml2gaiNFfYo7p4o96nZnmnHKu1aabA8B5V51zeslnWne6qaddf/YpZaFncajoohjGqZGhkLKEaKQmWkTppRNmhOlOk26qYqebguppfKJeWuqo7p0aqaqotupqVb+l/9ScSrOi5JystZ50q63M0dorrssBGyyvv+qaq0nHIlusssuWtKuxzR6QrLPRShvts8wOC61yvmq7bXLCcvvquOSWa+656Kar7rrsttsliCOq2RCD8WZa74f3ilhipQvRu6+C+UKo77/2zssvQYwm3KFAByvUcEIPH+SvwfIyFLHEFVuccb8AKuzxhRoDfKK7tAU65qAko2Qyliif65DHuK38ZMsplyTzkTSb6zEBPPfsswAC5HazkTmnPHSPRdec3tFGlqk001kqDR/UPDrdE6ujUU2m1DPxLDSeUQuFtWhax2g11+eV/WaSYj+6ntpIno32SgTIrSPYMSat09ihwf+dJ9vpFmA3TEAPbprfeufEN2iIA46u4DkRcIAAhmf9scJDLf7Z5ZirCzlOklNuruZz01bAAT6n3vOKjK44utulDwlzyOSSHvvtvNmO++616c7778CPFyux4hIPrvHHf5t8tsUzj1y3zTt/XLjLU3vttNNa663122vfPbbcVx/+89RPjzz5yqMvvXHQi++9+OAHL//89Ndv//3456///pmP5P//AAygAAdIwAL6j3MJM6ACF8jAkfEPTY2r3AMneDi8wShxFMwg2Sz4Igxq8IOb8VuLJAjCEk5GhAMgoQlXyBgUqpCFMCxMBGNIw8rMsIY4bBIH1/bCHPqQLghs3Q8rh0jEIhrxiEhMohKXyMQmOvGJUOzNd6ZIxSpa8YpYzKIWt8jFLnrxi84JCAAh+QQBCgAHACwAABYAWAJUAIL///+T//9J/wBkyP8yyABkZGQ8PDwAAAAI/wABCBxIsKDBgwgTKlzIsKHDhxAjSpxIsaLFixgzatzIsaPHjyBDiix4oKTJkyhTqlzJsqXLlzBjypxJs6bNmzhz6tzJs6fPn0CDCh1KtKjRo0iTKl3KtKnTp1CjSp1KtarVq1izat3KtavXr2DDih1LtqzZs2jTql3Ltq1bkwbiyp1Lt27dt3jz6t3Lt+9NAwMCCx5MuHDgAAEM+F3MuLHjx18BG55sGLFiyJgza97MWadkyqAPJ+5MurTp048/hw59GbXr17Bjg1W9mnJr2bhz695tlHZtw7d5Cx9OvDhL378FWzbOvLnz3MiTD1j+vLr165ijJ6eOvbv372ztiv8fLxe8+fPo07stwL69+/fw48ufT7++/fv48+vfz7+///8ABijggAQWaOCBCCao4IIMvqfegxBGKOGEFFZo4YUYZqjhhhx26OFNDakUUUoSkTgiSiWiCJGIK5r4kIsvqtjiSSfK6BCLMdJYo0kp6jgjjz8CmaOPN9roEHw9ClmkkQzhuKSST5aU0IdUflhglVhm2dyVWnbpZW5cfinmmKWFSeaZ0JGnJl3GmRnZmnAGh+acLWn3G3fDuemVnbXhSeefKvG5mp+86dmVoKERCuiiByAKmqK6GcqVo5RByiidlIIm526SbpWpbZeG2qh0oBbXqVafTrapqGimChyrRbn/WtiqsI4pq3Kj1SrUraLRqquXvE6X668/BWspsVoaOyyyPCnrK7NVxgkntD1Juya12Gb7WHsp7aeStyjx1y24J4kbrn7fojtufuuye6665ZJrkrzzwluvvSWZGy++B9CbL7/98qvvve7ui1+6BRt8X7sHa+vwwxBHLPHEFFds8cUYgxcijBsTGeUBSUq5o8hDQtkkxyd73LHJKbOskJMruzwlkwwhOTLIN9+Mc8kkfxzyzjzrLDRENgcJNEkZX3dqxUtDO6194DU9sdTEFnAAAVhnrTXWjZLX6HdURxy2rgU86xIBBwhgtqkEJv2ugFOvzRLaaoPd9lXWqqn03WLL/82SAHV7NzZSzu49YNw7EeC3cIMfVbh1jbttXuSxklrYsXnyDbEBaOekuNWCa05VsIEtjhvloXKekwCNgt4d6kORPoDpssHOqOo4sW6A65KfJDvtvVun2LVbaw14v8Gj9HjyEi58LfNwWU4Y5tBXn+Xy1mf/Zd5ea+/99xxy+/bCDEM9PvkKo09ww+nXhzD77dNXvvnxy38+/evjn7/79/Nf/3zz89/+7Nc/AAbQgP+TzwEROEAGNlCBC4xPBCUIvgpa8IIYzKAGN8jBDnqQJyMJoQhHSMISmvCEKEyhClfIwhZO5IOAsh0MZwgbGdLwhqaxIQ53uBkd8vCH2xIdEEeHWDshEvGIqPEhEpe4HiMy8YmZUSIUp1gWKVLxiljMoha3yMUuevGLYAyjGMdIxqM06IxoTKMa18jGNrrxjXCMoxzn2J+AAAAh+QQBCgAHACwAABQAWAJFAIL///+T//9J/wBkyP8yyABkZGQ8PDwAAAAI/wABCBxIsKDBgwgTKlzIsKHDhxAjSpxIsaLFixgzatzIsaPHjyBDiix4oKTJkyhTqlzJsqXLlzBjypxJs6bNmzhz6tzJs6fPn0CDCh1KtCjKAkiTKl3KtKnTp1CjSp1KtarVq1izat3KtavXr2DDih1LtqzZs2iXGl3Ltq3bt3Djyp1Lt67du3jz6t3Lt6/fv4ADCx5MuLDhw4gTuzXAuLHjx5AhK55MubLly5gzszQwoLPnz6BDdw4QwIDm06hTq17NmifSA6JjxyZturXt27hz6zaMtLbN0aV3Cx9OvLjxn71xfvZ9vLnz59B3J7+5PLr169izJ56ufABz7eDDi/8fz5b7Tdrk06tfz36meZvo28ufT3/8+5nAv9ffz7+/9AKRBSjgAYz5Z+CBCKIWVoIMNuggb2A9KOGEFFZo4YUYZqjhhhx26OGHIIYo4lARqVRiSieeJBGKKZq0IkotuggRizPCGOMBL6pYo40PmbijjD+WlCOQDvnYI41F8nikjkHieOONTi7JZJIjVmnllSlNpdJVWXJ5lJcnYdVlVVtaVSaZX5qZJpphqrmmlmNSFaecb8LZppsmgXknnXVGNaedeepZkqCD4hkom4ciWmhTWDbq6KOQRirppJTuJuClAVaaF6acOqbppy1xJtuonsUHKl2ikjqqqae2SqCqpJL/dgCfrvqUKqyiyfpUrZLeOipLtNHK606+fhZTsE4NC2mxsblkgLDK4sRsZzM9m2y0jU4bmrPQYluTttXu6u2V2oLGLaDjfitbuNemO2K5xq6ErFTu3gQuTPMyVe+7uAJbWrf7Orsuvv+2G7CH8Hrmr7X0HizTvS/lq5bDCHdKIKYAU5zSgJ06Jq7Gji4I8k0ij4xlySa7F2HKLLfs8sswxyzzzDTXbPN8UObc5JBCPumzlEQ2hCSVQQutJNE9A5000ksbPSXTPEfJtNROP83Q0FU3nTXVW+usNNcL3Sz22Il+vCe6sxIqZp9+sm122Q27bfCiiqZtqN3dEoo32muf8M232nfvHbffbRNeONyD04224IcjDtWfiTP+GtmUV95oxpZnfqrFmn/bMaedh+5owrEGJ/rpHCaLq2ysou56hU7px9Jspr9u+4SxyzSq7LeLB2DvMeUe0+7Ar/e7TgTwXrPwuoumfPHYHX8TAQcI8PzMzA8PWuvQgye9TdRbb3n2MIXGfffZFXAAAey37z77LYV/vczkt0T7/Og/x7mz4zf1eWMXk0z+BigflBHwgPMxIAIXyMAGOvCBEIygBCdIQayN5IIYzKAGN8jBDnrwgyAMoQhHuLUKmrCAaUmhClfIwha68IUwjKEMZ0jDGmIlIAAh+QQBCgAHACwBABkAVwI3AIL///+T//9J/wBkyP8yyABkZGQ8PDwAAAAI/wAPCBxIsKDBgwgTKlzIsKHDhxAjSpxIsaLFixgzatzIsSNCAyBDijQAsYDJkygLeFzJsqXLlzBjypxJs6bNmzgNGhjAs6fPAQwDBDCQsmjOo0iTKl3KtKnTp1AX7vz5M+jQoimjat3KtavXr2DDVpxKtadVolhPil3Ltq3bt3DjNiRbFujctGrl6t3Lt6/fvxzplnWIFi/gw4gTK168VjBVwnhNMp5MubLlyx4dV10otHBazKBDix59WbPPs5FVkl7NurVrsabNcr4a+bXt27hz1xzJu2Rt3cCDCx9OvLjx48iTK1/OvLnz59CjS59Ovbr169iza9/OfS2A7wAaov8cCD48w/EHyptfiL68w/bg3+d1fx7+d/F508evL1n/ffz90cefagIqlJV/6xmYX4EJ2fcfe/PtN6BADDYY4YMK9ocggKptOKGHH1aIkIMcEihhhh2KaJCDCVoY4IndxSjjjDTWaOONOOao44489ujjj0AGORNvRBYpkkCpJamhkCsZ6WRIBSlpGJM/xlYXVZ1JmRqVLFl5pVlZamkUlz16+SVPYYqJFZmZnXnmAWmquSSbOJp5Zpxy5kdnRnZeCSdteXa45419nulZoIIOalGhgwl0qJqK1unmpI/mGSlGjD7mKKKJXhpjpnVVKqeni07q56aIkkojqD/hGaiqFLH7CiaglsL6qalXulqrrRDJytOfokrJa3e+oklrqsM+VCywnCa73ZPQgoQkp3M6m1C0RkaJrLXcduvtt+CGK+645JZr7rnopqvuuuy2y5yK2moIL0EsckghjC6aiCGK9+47IokfgsivwAPPS++FLf6LsL39JnxQvSHiq7C+Dj+8cMAGTyuvxCteHLG/EzdcosgYcxwvxRWfTLK7LLfs8sswxyzzzDTXbPPN4h5pEXo498wjXRPF6fPQOgItkdBEJ12j0REhrfTTxJ4WK89QV40d0xJ5ZvXW12EdkdZchy2d1w45LfbZzJHdkNlot32c2qjp6fbcw+lcEdV7BgQAIfkEAQoABwAsAAAUAFgCVwCC////k///Sf8AZMj/MsgAZGRkPDw8AAAACP8ACwgcSLCgwYMIEypcyLChw4cQI0qcSLGixYsYM2rcyLGjx48gQ4oseKCkyZMoU6pcybKly5cwY8qcSbOmzZs4c+rcybOnz59AgwodSrSo0aNIkypdyrSp06dQo0qdSrWq1atYs2rdyrWr169gw4odS7as2bNo06pdy7Yt2o1u48qdS7euXZ9w7+rdy7evX7J5/woeTLiw4Z+BDytezLjx4MSOI0ueTHks5MqYM2venPQy58+gQ4t+6Xm06dOoK5dOzbq1a7+rX8ueTTtt7Nq4c+vezbu379/AgwsfTry48ePIGwNYzry58+fQo0ufTr269evYs2vfzr279+/gw4v/H0++vPnz6NOrX+88ufv38G1GVDkfpcSU9+3XP7mfP0T6/+kXoH8DmtSfgQUi+BB+Bx6QH4ELCugQgBFK2BCDCTrYYIMaVgjhhRaCCGF8JJZo4okopqjiiiwyZsCLMMYo44wztmjjjYsZMMCOPPbo4487BhCAATgWqdhtqOkI5JJACklkV0gayWKUpinJ5JVBDukVlVKmyKVoVmKJ5ZNcfdmliWaCFqaYTJK5VZpnxgcnZ2uyCaSbWs0Zp3t6alannTw6uaVGe0rZZ2Z/AjqAoFASWmiRh2KWKKCMlunoozdGWhmNnHYK46AZYYqjpqLSRGqpvp2KKkyqrurqq7DG/yrrrLTWauutuOa6V3MpaaeSr71mF6ywKG037HW/ElussiYZuyyzJTl7ErDPInusdddiW62100IbrbcHUNusuN96K+242CWb7rba6uruu0RxuOG8GT6o4IQY4hviQvnqe6+/JcmbYYcAE1ywvQHTW7DBDFF4sMIPe/hvw/1S/KGI98Kr8cYcd+zxx215KnKNINc08skvlizXyUtNamelKsfkMpswx8wVnisRoPPOPAsggINKzSxmzcS1SpPQWBJtc1YGEJDTzwYUELSiTWqJnNEzIX2l0ktf1fTTB0Q9NdV3Joe1TFqP2XVXX+dEgNhJpX0lzsOdLTPZZa+9Vds5wf+NlNxtmn2pU4AvSbfeVPEdVuE+ch2c3TAx3qPjiKvlc8t4T271cZC/JHmgm1ee2udZHv744E2Rvmjoop+GMstXo87U6yO3blbtrXduu2oWI6777sAHL/zwxBdv/PHIJw8fr+xSpy633a4bvfToUl8u9NW3O73212MfLrnfmwsu+OF7f2733JefvvrVPZ/++ey337zz80vnvvzbr6/8/vCN5P//AAygAAdIwAIa8IAITKACJ8K/BjrwgRCMoPJoJzIJWvAzqqPcBTeYo8yBznQcDKFhMsg6EZpwhB7sEQhPyMK9qG5HK2yhDOnywgHEcIY4DFkKV3fDHPoQLSTs4Q82hziWIBLxiCGjYKeQyMQmOvGJUIyiFKdIxSpa8YpYlBV7tsjFLnrxi2AMoxjHSMYymvGM3AkIADs=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reset environment\n",
    "env.reset()\n",
    "\n",
    "frames = []  # for storing the frames captured during the simulation\n",
    "\n",
    "# Simulate the environment\n",
    "for _ in range(50):\n",
    "    action = env.action_space.sample()  # choose a random action\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    frames.append(env.render())\n",
    "    done = terminated or truncated\n",
    "    if done:\n",
    "        env.reset()\n",
    "\n",
    "# Close the environment to free resources\n",
    "env.close()\n",
    "\n",
    "generate_gif(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the objective:\n",
    "\n",
    "The agent's object is straighforward: maximize average speed while minimizing collisions, with an additional goal of staying in the right lane as much as possible for extra reward. These objectives align well with the rewards settings described (collision_reward, high_speed_reward, and implicitly mentioning a right_lane_reward). This clarity will guide the design of your reinforcement learning model and the reward structure you implement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heavy Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.        ,  0.76346725,  0.        ,  0.3125    ,  0.        ],\n",
       "        [ 1.        ,  0.1263491 ,  0.        , -0.03789194,  0.        ],\n",
       "        [ 1.        ,  0.24673174,  0.        , -0.03197613,  0.        ],\n",
       "        [ 1.        ,  0.37648582,  0.        , -0.03072859,  0.        ],\n",
       "        [ 1.        ,  0.4867912 ,  0.        , -0.03123414,  0.        ]],\n",
       "       dtype=float32),\n",
       " {'speed': 25,\n",
       "  'crashed': False,\n",
       "  'action': 1,\n",
       "  'rewards': {'collision_reward': 0.0,\n",
       "   'right_lane_reward': 0.0,\n",
       "   'high_speed_reward': 0.5,\n",
       "   'on_road_reward': 1.0}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"highway-fast-v0\", render_mode='rgb_array')\n",
    "env.reset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Performance with Stable Baselines3\n",
    "\n",
    "Stable Baselines3 is a set of reliable implementations of reinforcement learning algorithms in PyTorch. It is the next major version of Stable Baselines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to highway_dqn_baseline/DQN_5\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.2     |\n",
      "|    ep_rew_mean      | 8.05     |\n",
      "|    exploration_rate | 0.979    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 64       |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 45       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.9     |\n",
      "|    ep_rew_mean      | 8.65     |\n",
      "|    exploration_rate | 0.955    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 95       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.5     |\n",
      "|    ep_rew_mean      | 7.76     |\n",
      "|    exploration_rate | 0.94     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 126      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.6     |\n",
      "|    ep_rew_mean      | 7.78     |\n",
      "|    exploration_rate | 0.92     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 169      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.6     |\n",
      "|    ep_rew_mean      | 8.6      |\n",
      "|    exploration_rate | 0.89     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 66       |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 232      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0319   |\n",
      "|    n_updates        | 31       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.8     |\n",
      "|    ep_rew_mean      | 8.89     |\n",
      "|    exploration_rate | 0.865    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 64       |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 284      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0692   |\n",
      "|    n_updates        | 83       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.2     |\n",
      "|    ep_rew_mean      | 9.24     |\n",
      "|    exploration_rate | 0.837    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 63       |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 343      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0551   |\n",
      "|    n_updates        | 142      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.8     |\n",
      "|    ep_rew_mean      | 8.82     |\n",
      "|    exploration_rate | 0.821    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 63       |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 377      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.117    |\n",
      "|    n_updates        | 176      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.2     |\n",
      "|    ep_rew_mean      | 8.42     |\n",
      "|    exploration_rate | 0.809    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 403      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.423    |\n",
      "|    n_updates        | 202      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.9     |\n",
      "|    ep_rew_mean      | 8.22     |\n",
      "|    exploration_rate | 0.793    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 436      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0787   |\n",
      "|    n_updates        | 235      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.3     |\n",
      "|    ep_rew_mean      | 8.57     |\n",
      "|    exploration_rate | 0.763    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 498      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.475    |\n",
      "|    n_updates        | 297      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.3     |\n",
      "|    ep_rew_mean      | 8.57     |\n",
      "|    exploration_rate | 0.743    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 542      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.165    |\n",
      "|    n_updates        | 341      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.9     |\n",
      "|    ep_rew_mean      | 8.29     |\n",
      "|    exploration_rate | 0.73     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 568      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.261    |\n",
      "|    n_updates        | 367      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.7     |\n",
      "|    ep_rew_mean      | 8.13     |\n",
      "|    exploration_rate | 0.716    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 598      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.36     |\n",
      "|    n_updates        | 397      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.6     |\n",
      "|    ep_rew_mean      | 8.09     |\n",
      "|    exploration_rate | 0.698    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 636      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.286    |\n",
      "|    n_updates        | 435      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.5     |\n",
      "|    ep_rew_mean      | 7.96     |\n",
      "|    exploration_rate | 0.682    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 669      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.18     |\n",
      "|    n_updates        | 468      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.4     |\n",
      "|    ep_rew_mean      | 7.93     |\n",
      "|    exploration_rate | 0.664    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 707      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.117    |\n",
      "|    n_updates        | 506      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.9     |\n",
      "|    ep_rew_mean      | 8.34     |\n",
      "|    exploration_rate | 0.628    |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 784      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0239   |\n",
      "|    n_updates        | 583      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.9     |\n",
      "|    ep_rew_mean      | 8.34     |\n",
      "|    exploration_rate | 0.608    |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 825      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.404    |\n",
      "|    n_updates        | 624      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.6     |\n",
      "|    ep_rew_mean      | 8.12     |\n",
      "|    exploration_rate | 0.598    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 847      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.122    |\n",
      "|    n_updates        | 646      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.5     |\n",
      "|    ep_rew_mean      | 8.02     |\n",
      "|    exploration_rate | 0.582    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 880      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.591    |\n",
      "|    n_updates        | 679      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.3     |\n",
      "|    ep_rew_mean      | 7.88     |\n",
      "|    exploration_rate | 0.569    |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 907      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.405    |\n",
      "|    n_updates        | 706      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.3     |\n",
      "|    ep_rew_mean      | 7.88     |\n",
      "|    exploration_rate | 0.551    |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 945      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.32     |\n",
      "|    n_updates        | 744      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.3     |\n",
      "|    ep_rew_mean      | 7.95     |\n",
      "|    exploration_rate | 0.53     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 989      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.171    |\n",
      "|    n_updates        | 788      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.3     |\n",
      "|    ep_rew_mean      | 7.98     |\n",
      "|    exploration_rate | 0.51     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 1032     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.199    |\n",
      "|    n_updates        | 831      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 7.92     |\n",
      "|    exploration_rate | 0.494    |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 1065     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.198    |\n",
      "|    n_updates        | 864      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 7.96     |\n",
      "|    exploration_rate | 0.468    |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 1119     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.208    |\n",
      "|    n_updates        | 918      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.6     |\n",
      "|    ep_rew_mean      | 8.26     |\n",
      "|    exploration_rate | 0.435    |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 1189     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.289    |\n",
      "|    n_updates        | 988      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.9     |\n",
      "|    ep_rew_mean      | 8.5      |\n",
      "|    exploration_rate | 0.403    |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 1256     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.152    |\n",
      "|    n_updates        | 1055     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.6     |\n",
      "|    ep_rew_mean      | 8.32     |\n",
      "|    exploration_rate | 0.386    |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 1293     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.291    |\n",
      "|    n_updates        | 1092     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.7     |\n",
      "|    ep_rew_mean      | 8.34     |\n",
      "|    exploration_rate | 0.359    |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 1349     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0468   |\n",
      "|    n_updates        | 1148     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.7     |\n",
      "|    ep_rew_mean      | 8.45     |\n",
      "|    exploration_rate | 0.327    |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 1417     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.269    |\n",
      "|    n_updates        | 1216     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.7     |\n",
      "|    ep_rew_mean      | 8.47     |\n",
      "|    exploration_rate | 0.311    |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 1450     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0358   |\n",
      "|    n_updates        | 1249     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11       |\n",
      "|    ep_rew_mean      | 8.71     |\n",
      "|    exploration_rate | 0.285    |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 1506     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.27     |\n",
      "|    n_updates        | 1305     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.4     |\n",
      "|    ep_rew_mean      | 9.05     |\n",
      "|    exploration_rate | 0.251    |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 1577     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.507    |\n",
      "|    n_updates        | 1376     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.6     |\n",
      "|    ep_rew_mean      | 9.26     |\n",
      "|    exploration_rate | 0.211    |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 1662     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0982   |\n",
      "|    n_updates        | 1461     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12       |\n",
      "|    ep_rew_mean      | 9.56     |\n",
      "|    exploration_rate | 0.173    |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 1741     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.19     |\n",
      "|    n_updates        | 1540     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.1     |\n",
      "|    ep_rew_mean      | 9.66     |\n",
      "|    exploration_rate | 0.154    |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 1782     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.168    |\n",
      "|    n_updates        | 1581     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.4     |\n",
      "|    ep_rew_mean      | 9.87     |\n",
      "|    exploration_rate | 0.126    |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 1839     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.22     |\n",
      "|    n_updates        | 1638     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.8     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.0909   |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 1914     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.19     |\n",
      "|    n_updates        | 1713     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.1     |\n",
      "|    ep_rew_mean      | 10.4     |\n",
      "|    exploration_rate | 0.0605   |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 1978     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.267    |\n",
      "|    n_updates        | 1777     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 10.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 2045     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.108    |\n",
      "|    n_updates        | 1844     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 10.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 2121     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.277    |\n",
      "|    n_updates        | 1920     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 10.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 2161     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.128    |\n",
      "|    n_updates        | 1960     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.1     |\n",
      "|    ep_rew_mean      | 11.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 2254     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0924   |\n",
      "|    n_updates        | 2053     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.3     |\n",
      "|    ep_rew_mean      | 11.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 2308     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.202    |\n",
      "|    n_updates        | 2107     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.9     |\n",
      "|    ep_rew_mean      | 11.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 2401     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.107    |\n",
      "|    n_updates        | 2200     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.3     |\n",
      "|    ep_rew_mean      | 12.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 2475     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.383    |\n",
      "|    n_updates        | 2274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.5     |\n",
      "|    ep_rew_mean      | 12.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 2542     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0924   |\n",
      "|    n_updates        | 2341     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.6     |\n",
      "|    ep_rew_mean      | 12.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 2588     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.155    |\n",
      "|    n_updates        | 2387     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.2     |\n",
      "|    ep_rew_mean      | 12.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 2683     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0926   |\n",
      "|    n_updates        | 2482     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.6     |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 2779     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0541   |\n",
      "|    n_updates        | 2578     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.5     |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 2839     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.179    |\n",
      "|    n_updates        | 2638     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.7     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 2926     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.189    |\n",
      "|    n_updates        | 2725     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.8     |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 2970     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.247    |\n",
      "|    n_updates        | 2769     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.9     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 3037     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.222    |\n",
      "|    n_updates        | 2836     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.8     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 3099     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0315   |\n",
      "|    n_updates        | 2898     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.3     |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 3176     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.46     |\n",
      "|    n_updates        | 2975     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.7     |\n",
      "|    ep_rew_mean      | 14.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 3275     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.145    |\n",
      "|    n_updates        | 3074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | 14       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 3341     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.113    |\n",
      "|    n_updates        | 3140     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.3     |\n",
      "|    ep_rew_mean      | 13.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 3394     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0482   |\n",
      "|    n_updates        | 3193     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.3     |\n",
      "|    ep_rew_mean      | 13.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 3468     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.095    |\n",
      "|    n_updates        | 3267     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | 14       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 3542     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.107    |\n",
      "|    n_updates        | 3341     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.7     |\n",
      "|    ep_rew_mean      | 14.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 3608     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.134    |\n",
      "|    n_updates        | 3407     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.4     |\n",
      "|    ep_rew_mean      | 13.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 3655     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.266    |\n",
      "|    n_updates        | 3454     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.7     |\n",
      "|    ep_rew_mean      | 14.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 3752     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0916   |\n",
      "|    n_updates        | 3551     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.7     |\n",
      "|    ep_rew_mean      | 14.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 3817     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.105    |\n",
      "|    n_updates        | 3616     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.7     |\n",
      "|    ep_rew_mean      | 14.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 3890     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.174    |\n",
      "|    n_updates        | 3689     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.3     |\n",
      "|    ep_rew_mean      | 14.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 3995     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.182    |\n",
      "|    n_updates        | 3794     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.3     |\n",
      "|    ep_rew_mean      | 14.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 4084     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0674   |\n",
      "|    n_updates        | 3883     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.8     |\n",
      "|    ep_rew_mean      | 15       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 4188     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.2      |\n",
      "|    n_updates        | 3987     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.9     |\n",
      "|    ep_rew_mean      | 15.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 4293     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0616   |\n",
      "|    n_updates        | 4092     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19       |\n",
      "|    ep_rew_mean      | 15.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 4372     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.124    |\n",
      "|    n_updates        | 4171     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.8     |\n",
      "|    ep_rew_mean      | 15       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 4424     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.141    |\n",
      "|    n_updates        | 4223     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.2     |\n",
      "|    ep_rew_mean      | 15.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 4506     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 4305     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.1     |\n",
      "|    ep_rew_mean      | 15.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 4598     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.167    |\n",
      "|    n_updates        | 4397     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.7     |\n",
      "|    ep_rew_mean      | 15       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 4649     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.314    |\n",
      "|    n_updates        | 4448     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19       |\n",
      "|    ep_rew_mean      | 15.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 4740     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.163    |\n",
      "|    n_updates        | 4539     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.3     |\n",
      "|    ep_rew_mean      | 15.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 4852     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.525    |\n",
      "|    n_updates        | 4651     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.8     |\n",
      "|    ep_rew_mean      | 15.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 4949     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0846   |\n",
      "|    n_updates        | 4748     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.5     |\n",
      "|    ep_rew_mean      | 15.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 4990     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.221    |\n",
      "|    n_updates        | 4789     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.7     |\n",
      "|    ep_rew_mean      | 15.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total_timesteps  | 5070     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.138    |\n",
      "|    n_updates        | 4869     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.6     |\n",
      "|    ep_rew_mean      | 15.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 5134     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 4933     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.4     |\n",
      "|    ep_rew_mean      | 15.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 5213     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.135    |\n",
      "|    n_updates        | 5012     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.6     |\n",
      "|    ep_rew_mean      | 15.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 5297     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0347   |\n",
      "|    n_updates        | 5096     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.8     |\n",
      "|    ep_rew_mean      | 15.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 5374     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.115    |\n",
      "|    n_updates        | 5173     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20       |\n",
      "|    ep_rew_mean      | 15.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 5472     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.218    |\n",
      "|    n_updates        | 5271     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.1     |\n",
      "|    ep_rew_mean      | 15.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 5554     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.221    |\n",
      "|    n_updates        | 5353     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.6     |\n",
      "|    ep_rew_mean      | 16.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 5666     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.117    |\n",
      "|    n_updates        | 5465     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 16.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 5772     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0556   |\n",
      "|    n_updates        | 5571     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.3     |\n",
      "|    ep_rew_mean      | 16.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 5879     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0573   |\n",
      "|    n_updates        | 5678     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 16.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 5974     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.152    |\n",
      "|    n_updates        | 5773     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 16.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 6074     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.158    |\n",
      "|    n_updates        | 5873     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.7     |\n",
      "|    ep_rew_mean      | 16.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 6169     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.3      |\n",
      "|    n_updates        | 5968     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 16.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 6224     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0608   |\n",
      "|    n_updates        | 6023     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 16.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 104      |\n",
      "|    total_timesteps  | 6329     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0764   |\n",
      "|    n_updates        | 6128     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 16.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 6449     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.126    |\n",
      "|    n_updates        | 6248     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 16.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 6535     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.177    |\n",
      "|    n_updates        | 6334     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.3     |\n",
      "|    ep_rew_mean      | 17.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 6655     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.129    |\n",
      "|    n_updates        | 6454     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 17.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 6723     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0902   |\n",
      "|    n_updates        | 6522     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 17.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 6812     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.24     |\n",
      "|    n_updates        | 6611     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.6     |\n",
      "|    ep_rew_mean      | 17.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total_timesteps  | 6907     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.116    |\n",
      "|    n_updates        | 6706     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.5     |\n",
      "|    ep_rew_mean      | 17.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total_timesteps  | 6987     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.122    |\n",
      "|    n_updates        | 6786     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 17.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 116      |\n",
      "|    total_timesteps  | 7068     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.143    |\n",
      "|    n_updates        | 6867     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 17.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 117      |\n",
      "|    total_timesteps  | 7162     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.139    |\n",
      "|    n_updates        | 6961     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.8     |\n",
      "|    ep_rew_mean      | 17.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 119      |\n",
      "|    total_timesteps  | 7267     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.186    |\n",
      "|    n_updates        | 7066     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23       |\n",
      "|    ep_rew_mean      | 17.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 121      |\n",
      "|    total_timesteps  | 7369     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0888   |\n",
      "|    n_updates        | 7168     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 18.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 123      |\n",
      "|    total_timesteps  | 7471     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.167    |\n",
      "|    n_updates        | 7270     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.7     |\n",
      "|    ep_rew_mean      | 18.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 124      |\n",
      "|    total_timesteps  | 7584     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0701   |\n",
      "|    n_updates        | 7383     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.1     |\n",
      "|    ep_rew_mean      | 18.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 126      |\n",
      "|    total_timesteps  | 7704     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0691   |\n",
      "|    n_updates        | 7503     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.3     |\n",
      "|    ep_rew_mean      | 18.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 128      |\n",
      "|    total_timesteps  | 7803     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.12     |\n",
      "|    n_updates        | 7602     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.5     |\n",
      "|    ep_rew_mean      | 19       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 130      |\n",
      "|    total_timesteps  | 7919     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.142    |\n",
      "|    n_updates        | 7718     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.5     |\n",
      "|    ep_rew_mean      | 19.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 131      |\n",
      "|    total_timesteps  | 8007     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.103    |\n",
      "|    n_updates        | 7806     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.5     |\n",
      "|    ep_rew_mean      | 19.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 133      |\n",
      "|    total_timesteps  | 8120     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.064    |\n",
      "|    n_updates        | 7919     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.2     |\n",
      "|    ep_rew_mean      | 18.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 135      |\n",
      "|    total_timesteps  | 8197     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0921   |\n",
      "|    n_updates        | 7996     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.2     |\n",
      "|    ep_rew_mean      | 18.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 136      |\n",
      "|    total_timesteps  | 8302     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0416   |\n",
      "|    n_updates        | 8101     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.5     |\n",
      "|    ep_rew_mean      | 19.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 138      |\n",
      "|    total_timesteps  | 8422     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0384   |\n",
      "|    n_updates        | 8221     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.6     |\n",
      "|    ep_rew_mean      | 19.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 140      |\n",
      "|    total_timesteps  | 8534     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.205    |\n",
      "|    n_updates        | 8333     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.6     |\n",
      "|    ep_rew_mean      | 19.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 142      |\n",
      "|    total_timesteps  | 8631     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0359   |\n",
      "|    n_updates        | 8430     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.3     |\n",
      "|    ep_rew_mean      | 19.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total_timesteps  | 8751     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.11     |\n",
      "|    n_updates        | 8550     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.1     |\n",
      "|    ep_rew_mean      | 19.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 145      |\n",
      "|    total_timesteps  | 8842     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0864   |\n",
      "|    n_updates        | 8641     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.1     |\n",
      "|    ep_rew_mean      | 19.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 147      |\n",
      "|    total_timesteps  | 8957     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 8756     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.2     |\n",
      "|    ep_rew_mean      | 19.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 149      |\n",
      "|    total_timesteps  | 9051     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.202    |\n",
      "|    n_updates        | 8850     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.1     |\n",
      "|    ep_rew_mean      | 19.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 150      |\n",
      "|    total_timesteps  | 9162     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0469   |\n",
      "|    n_updates        | 8961     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.5     |\n",
      "|    ep_rew_mean      | 19.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 152      |\n",
      "|    total_timesteps  | 9269     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0788   |\n",
      "|    n_updates        | 9068     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.8     |\n",
      "|    ep_rew_mean      | 20.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 504      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 154      |\n",
      "|    total_timesteps  | 9389     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0397   |\n",
      "|    n_updates        | 9188     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.8     |\n",
      "|    ep_rew_mean      | 20.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 508      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 156      |\n",
      "|    total_timesteps  | 9488     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0179   |\n",
      "|    n_updates        | 9287     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 26.2     |\n",
      "|    ep_rew_mean      | 20.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 512      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 158      |\n",
      "|    total_timesteps  | 9608     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0946   |\n",
      "|    n_updates        | 9407     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 26.2     |\n",
      "|    ep_rew_mean      | 20.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 516      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 159      |\n",
      "|    total_timesteps  | 9693     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0975   |\n",
      "|    n_updates        | 9492     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 26       |\n",
      "|    ep_rew_mean      | 20.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 520      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 160      |\n",
      "|    total_timesteps  | 9761     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.103    |\n",
      "|    n_updates        | 9560     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.8     |\n",
      "|    ep_rew_mean      | 20.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 524      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 162      |\n",
      "|    total_timesteps  | 9845     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.126    |\n",
      "|    n_updates        | 9644     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.8     |\n",
      "|    ep_rew_mean      | 20.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 528      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 163      |\n",
      "|    total_timesteps  | 9947     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.112    |\n",
      "|    n_updates        | 9746     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.7     |\n",
      "|    ep_rew_mean      | 20.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 532      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 165      |\n",
      "|    total_timesteps  | 10041    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0691   |\n",
      "|    n_updates        | 9840     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.3     |\n",
      "|    ep_rew_mean      | 19.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 536      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 166      |\n",
      "|    total_timesteps  | 10114    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0876   |\n",
      "|    n_updates        | 9913     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.1     |\n",
      "|    ep_rew_mean      | 19.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 540      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 168      |\n",
      "|    total_timesteps  | 10214    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.232    |\n",
      "|    n_updates        | 10013    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.2     |\n",
      "|    ep_rew_mean      | 19.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 544      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 169      |\n",
      "|    total_timesteps  | 10326    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0895   |\n",
      "|    n_updates        | 10125    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.8     |\n",
      "|    ep_rew_mean      | 19.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 548      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 171      |\n",
      "|    total_timesteps  | 10402    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00848  |\n",
      "|    n_updates        | 10201    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25       |\n",
      "|    ep_rew_mean      | 19.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 552      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 173      |\n",
      "|    total_timesteps  | 10511    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0696   |\n",
      "|    n_updates        | 10310    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.1     |\n",
      "|    ep_rew_mean      | 19.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 556      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 174      |\n",
      "|    total_timesteps  | 10631    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.193    |\n",
      "|    n_updates        | 10430    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.3     |\n",
      "|    ep_rew_mean      | 19.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 560      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 176      |\n",
      "|    total_timesteps  | 10730    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0251   |\n",
      "|    n_updates        | 10529    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25       |\n",
      "|    ep_rew_mean      | 19.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 564      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 177      |\n",
      "|    total_timesteps  | 10798    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.106    |\n",
      "|    n_updates        | 10597    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.8     |\n",
      "|    ep_rew_mean      | 19.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 568      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 179      |\n",
      "|    total_timesteps  | 10899    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0078   |\n",
      "|    n_updates        | 10698    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.3     |\n",
      "|    ep_rew_mean      | 19.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 572      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 180      |\n",
      "|    total_timesteps  | 10967    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.119    |\n",
      "|    n_updates        | 10766    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24       |\n",
      "|    ep_rew_mean      | 18.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 576      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 181      |\n",
      "|    total_timesteps  | 11035    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.309    |\n",
      "|    n_updates        | 10834    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.8     |\n",
      "|    ep_rew_mean      | 18.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 580      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 183      |\n",
      "|    total_timesteps  | 11128    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.198    |\n",
      "|    n_updates        | 10927    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.8     |\n",
      "|    ep_rew_mean      | 18.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 584      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 184      |\n",
      "|    total_timesteps  | 11221    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.047    |\n",
      "|    n_updates        | 11020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.5     |\n",
      "|    ep_rew_mean      | 18.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 588      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 186      |\n",
      "|    total_timesteps  | 11310    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0214   |\n",
      "|    n_updates        | 11109    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.7     |\n",
      "|    ep_rew_mean      | 18.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 592      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 188      |\n",
      "|    total_timesteps  | 11417    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.156    |\n",
      "|    n_updates        | 11216    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.3     |\n",
      "|    ep_rew_mean      | 18.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 596      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 189      |\n",
      "|    total_timesteps  | 11492    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.158    |\n",
      "|    n_updates        | 11291    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.1     |\n",
      "|    ep_rew_mean      | 18.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 190      |\n",
      "|    total_timesteps  | 11579    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.102    |\n",
      "|    n_updates        | 11378    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.7     |\n",
      "|    ep_rew_mean      | 17.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 604      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 192      |\n",
      "|    total_timesteps  | 11659    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0272   |\n",
      "|    n_updates        | 11458    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 17.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 608      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 193      |\n",
      "|    total_timesteps  | 11732    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.257    |\n",
      "|    n_updates        | 11531    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 17.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 612      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 195      |\n",
      "|    total_timesteps  | 11852    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.26     |\n",
      "|    n_updates        | 11651    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 17.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 616      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 196      |\n",
      "|    total_timesteps  | 11914    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0216   |\n",
      "|    n_updates        | 11713    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.6     |\n",
      "|    ep_rew_mean      | 17.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 620      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 198      |\n",
      "|    total_timesteps  | 12020    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 11819    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 17.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 624      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 199      |\n",
      "|    total_timesteps  | 12082    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0373   |\n",
      "|    n_updates        | 11881    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 17.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 628      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 200      |\n",
      "|    total_timesteps  | 12163    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0783   |\n",
      "|    n_updates        | 11962    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.3     |\n",
      "|    ep_rew_mean      | 17.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 632      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 202      |\n",
      "|    total_timesteps  | 12267    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.142    |\n",
      "|    n_updates        | 12066    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.7     |\n",
      "|    ep_rew_mean      | 18       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 636      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 204      |\n",
      "|    total_timesteps  | 12387    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.103    |\n",
      "|    n_updates        | 12186    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.9     |\n",
      "|    ep_rew_mean      | 18.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 640      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 206      |\n",
      "|    total_timesteps  | 12507    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00852  |\n",
      "|    n_updates        | 12306    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.8     |\n",
      "|    ep_rew_mean      | 18       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 644      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 207      |\n",
      "|    total_timesteps  | 12607    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.153    |\n",
      "|    n_updates        | 12406    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.9     |\n",
      "|    ep_rew_mean      | 18.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 648      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 209      |\n",
      "|    total_timesteps  | 12692    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0429   |\n",
      "|    n_updates        | 12491    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 17.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 652      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 210      |\n",
      "|    total_timesteps  | 12749    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.112    |\n",
      "|    n_updates        | 12548    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 17.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 656      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 211      |\n",
      "|    total_timesteps  | 12818    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0793   |\n",
      "|    n_updates        | 12617    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.3     |\n",
      "|    ep_rew_mean      | 16.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 660      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 211      |\n",
      "|    total_timesteps  | 12858    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0416   |\n",
      "|    n_updates        | 12657    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 17.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 664      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 213      |\n",
      "|    total_timesteps  | 12961    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.101    |\n",
      "|    n_updates        | 12760    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.7     |\n",
      "|    ep_rew_mean      | 17       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 668      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 215      |\n",
      "|    total_timesteps  | 13065    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.156    |\n",
      "|    n_updates        | 12864    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 17.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 672      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 216      |\n",
      "|    total_timesteps  | 13170    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.31     |\n",
      "|    n_updates        | 12969    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 17.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 676      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 218      |\n",
      "|    total_timesteps  | 13272    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.123    |\n",
      "|    n_updates        | 13071    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.3     |\n",
      "|    ep_rew_mean      | 17.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 680      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 220      |\n",
      "|    total_timesteps  | 13361    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.091    |\n",
      "|    n_updates        | 13160    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 17.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 684      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 221      |\n",
      "|    total_timesteps  | 13444    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 13243    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 17.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 688      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 223      |\n",
      "|    total_timesteps  | 13553    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.26     |\n",
      "|    n_updates        | 13352    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 17.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 692      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 224      |\n",
      "|    total_timesteps  | 13653    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.199    |\n",
      "|    n_updates        | 13452    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.8     |\n",
      "|    ep_rew_mean      | 17.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 696      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 226      |\n",
      "|    total_timesteps  | 13773    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0287   |\n",
      "|    n_updates        | 13572    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.1     |\n",
      "|    ep_rew_mean      | 18.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 700      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 228      |\n",
      "|    total_timesteps  | 13889    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0561   |\n",
      "|    n_updates        | 13688    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.3     |\n",
      "|    ep_rew_mean      | 18.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 704      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 230      |\n",
      "|    total_timesteps  | 13985    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.038    |\n",
      "|    n_updates        | 13784    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.3     |\n",
      "|    ep_rew_mean      | 18.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 708      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 231      |\n",
      "|    total_timesteps  | 14065    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0821   |\n",
      "|    n_updates        | 13864    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.2     |\n",
      "|    ep_rew_mean      | 18.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 712      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 233      |\n",
      "|    total_timesteps  | 14168    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.128    |\n",
      "|    n_updates        | 13967    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 18.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 716      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 234      |\n",
      "|    total_timesteps  | 14251    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0424   |\n",
      "|    n_updates        | 14050    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.5     |\n",
      "|    ep_rew_mean      | 18.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 720      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 236      |\n",
      "|    total_timesteps  | 14371    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0864   |\n",
      "|    n_updates        | 14170    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.7     |\n",
      "|    ep_rew_mean      | 18.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 724      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 238      |\n",
      "|    total_timesteps  | 14455    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.143    |\n",
      "|    n_updates        | 14254    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.9     |\n",
      "|    ep_rew_mean      | 18.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 728      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 239      |\n",
      "|    total_timesteps  | 14557    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 14356    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24       |\n",
      "|    ep_rew_mean      | 18.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 732      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 241      |\n",
      "|    total_timesteps  | 14668    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.141    |\n",
      "|    n_updates        | 14467    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24       |\n",
      "|    ep_rew_mean      | 18.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 736      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 243      |\n",
      "|    total_timesteps  | 14786    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.02     |\n",
      "|    n_updates        | 14585    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.8     |\n",
      "|    ep_rew_mean      | 18.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 740      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 245      |\n",
      "|    total_timesteps  | 14882    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0893   |\n",
      "|    n_updates        | 14681    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 18.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 744      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 246      |\n",
      "|    total_timesteps  | 14944    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0229   |\n",
      "|    n_updates        | 14743    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.5     |\n",
      "|    ep_rew_mean      | 18.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 748      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 247      |\n",
      "|    total_timesteps  | 15042    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.096    |\n",
      "|    n_updates        | 14841    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.1     |\n",
      "|    ep_rew_mean      | 19       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 752      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 249      |\n",
      "|    total_timesteps  | 15162    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0241   |\n",
      "|    n_updates        | 14961    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24       |\n",
      "|    ep_rew_mean      | 18.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 756      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 250      |\n",
      "|    total_timesteps  | 15219    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.027    |\n",
      "|    n_updates        | 15018    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.5     |\n",
      "|    ep_rew_mean      | 19.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 760      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 252      |\n",
      "|    total_timesteps  | 15307    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0336   |\n",
      "|    n_updates        | 15106    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.7     |\n",
      "|    ep_rew_mean      | 19.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 764      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 254      |\n",
      "|    total_timesteps  | 15427    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.104    |\n",
      "|    n_updates        | 15226    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.6     |\n",
      "|    ep_rew_mean      | 19.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 768      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 255      |\n",
      "|    total_timesteps  | 15520    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.108    |\n",
      "|    n_updates        | 15319    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.5     |\n",
      "|    ep_rew_mean      | 19.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 772      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 257      |\n",
      "|    total_timesteps  | 15621    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.134    |\n",
      "|    n_updates        | 15420    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.4     |\n",
      "|    ep_rew_mean      | 19.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 776      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 258      |\n",
      "|    total_timesteps  | 15710    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00929  |\n",
      "|    n_updates        | 15509    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.6     |\n",
      "|    ep_rew_mean      | 19.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 780      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 260      |\n",
      "|    total_timesteps  | 15820    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.141    |\n",
      "|    n_updates        | 15619    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25       |\n",
      "|    ep_rew_mean      | 19.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 784      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 262      |\n",
      "|    total_timesteps  | 15940    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0684   |\n",
      "|    n_updates        | 15739    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.1     |\n",
      "|    ep_rew_mean      | 19.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 788      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 264      |\n",
      "|    total_timesteps  | 16060    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 15859    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25       |\n",
      "|    ep_rew_mean      | 19.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 792      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 266      |\n",
      "|    total_timesteps  | 16155    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.104    |\n",
      "|    n_updates        | 15954    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25       |\n",
      "|    ep_rew_mean      | 19.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 796      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 267      |\n",
      "|    total_timesteps  | 16275    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 16074    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.9     |\n",
      "|    ep_rew_mean      | 19.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 800      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 269      |\n",
      "|    total_timesteps  | 16382    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 16181    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.8     |\n",
      "|    ep_rew_mean      | 19.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 804      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 271      |\n",
      "|    total_timesteps  | 16465    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00717  |\n",
      "|    n_updates        | 16264    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.2     |\n",
      "|    ep_rew_mean      | 19.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 808      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 273      |\n",
      "|    total_timesteps  | 16585    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0202   |\n",
      "|    n_updates        | 16384    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.1     |\n",
      "|    ep_rew_mean      | 19.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 812      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 274      |\n",
      "|    total_timesteps  | 16680    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 16479    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.1     |\n",
      "|    ep_rew_mean      | 19.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 816      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 275      |\n",
      "|    total_timesteps  | 16762    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0073   |\n",
      "|    n_updates        | 16561    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.9     |\n",
      "|    ep_rew_mean      | 19.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 820      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 277      |\n",
      "|    total_timesteps  | 16863    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0925   |\n",
      "|    n_updates        | 16662    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25       |\n",
      "|    ep_rew_mean      | 19.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 824      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 279      |\n",
      "|    total_timesteps  | 16959    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.182    |\n",
      "|    n_updates        | 16758    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.2     |\n",
      "|    ep_rew_mean      | 19.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 828      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 281      |\n",
      "|    total_timesteps  | 17075    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.057    |\n",
      "|    n_updates        | 16874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25       |\n",
      "|    ep_rew_mean      | 19.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 832      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 282      |\n",
      "|    total_timesteps  | 17170    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.119    |\n",
      "|    n_updates        | 16969    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.3     |\n",
      "|    ep_rew_mean      | 19       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 836      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 283      |\n",
      "|    total_timesteps  | 17213    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0308   |\n",
      "|    n_updates        | 17012    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.1     |\n",
      "|    ep_rew_mean      | 18.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 840      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 284      |\n",
      "|    total_timesteps  | 17292    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0247   |\n",
      "|    n_updates        | 17091    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.6     |\n",
      "|    ep_rew_mean      | 19.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 844      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 286      |\n",
      "|    total_timesteps  | 17403    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0206   |\n",
      "|    n_updates        | 17202    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.8     |\n",
      "|    ep_rew_mean      | 19.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 848      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 288      |\n",
      "|    total_timesteps  | 17523    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0475   |\n",
      "|    n_updates        | 17322    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.6     |\n",
      "|    ep_rew_mean      | 19.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 852      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 290      |\n",
      "|    total_timesteps  | 17622    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.176    |\n",
      "|    n_updates        | 17421    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.1     |\n",
      "|    ep_rew_mean      | 19.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 856      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 291      |\n",
      "|    total_timesteps  | 17730    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.017    |\n",
      "|    n_updates        | 17529    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.3     |\n",
      "|    ep_rew_mean      | 19.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 860      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 293      |\n",
      "|    total_timesteps  | 17836    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0247   |\n",
      "|    n_updates        | 17635    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.2     |\n",
      "|    ep_rew_mean      | 19.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 864      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 295      |\n",
      "|    total_timesteps  | 17944    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0168   |\n",
      "|    n_updates        | 17743    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.4     |\n",
      "|    ep_rew_mean      | 20.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 868      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 297      |\n",
      "|    total_timesteps  | 18064    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0523   |\n",
      "|    n_updates        | 17863    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.5     |\n",
      "|    ep_rew_mean      | 20.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 872      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 299      |\n",
      "|    total_timesteps  | 18172    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0594   |\n",
      "|    n_updates        | 17971    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.7     |\n",
      "|    ep_rew_mean      | 20.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 876      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 300      |\n",
      "|    total_timesteps  | 18276    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0226   |\n",
      "|    n_updates        | 18075    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.3     |\n",
      "|    ep_rew_mean      | 20       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 880      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 302      |\n",
      "|    total_timesteps  | 18353    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 18152    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.3     |\n",
      "|    ep_rew_mean      | 20       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 884      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 304      |\n",
      "|    total_timesteps  | 18473    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0506   |\n",
      "|    n_updates        | 18272    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.3     |\n",
      "|    ep_rew_mean      | 20       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 888      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 306      |\n",
      "|    total_timesteps  | 18586    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00833  |\n",
      "|    n_updates        | 18385    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.1     |\n",
      "|    ep_rew_mean      | 19.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 892      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 307      |\n",
      "|    total_timesteps  | 18669    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.106    |\n",
      "|    n_updates        | 18468    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.1     |\n",
      "|    ep_rew_mean      | 19.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 896      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 309      |\n",
      "|    total_timesteps  | 18783    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.04     |\n",
      "|    n_updates        | 18582    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.9     |\n",
      "|    ep_rew_mean      | 19.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 900      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 310      |\n",
      "|    total_timesteps  | 18873    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00323  |\n",
      "|    n_updates        | 18672    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.3     |\n",
      "|    ep_rew_mean      | 20       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 904      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 312      |\n",
      "|    total_timesteps  | 18993    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0167   |\n",
      "|    n_updates        | 18792    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.8     |\n",
      "|    ep_rew_mean      | 19.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 908      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 314      |\n",
      "|    total_timesteps  | 19069    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.00853  |\n",
      "|    n_updates        | 18868    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.8     |\n",
      "|    ep_rew_mean      | 19.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 912      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 315      |\n",
      "|    total_timesteps  | 19163    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0725   |\n",
      "|    n_updates        | 18962    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.7     |\n",
      "|    ep_rew_mean      | 19.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 916      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 316      |\n",
      "|    total_timesteps  | 19236    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0396   |\n",
      "|    n_updates        | 19035    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.9     |\n",
      "|    ep_rew_mean      | 19.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 920      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 318      |\n",
      "|    total_timesteps  | 19356    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0653   |\n",
      "|    n_updates        | 19155    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.2     |\n",
      "|    ep_rew_mean      | 20       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 924      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 320      |\n",
      "|    total_timesteps  | 19476    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.024    |\n",
      "|    n_updates        | 19275    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.9     |\n",
      "|    ep_rew_mean      | 19.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 928      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 322      |\n",
      "|    total_timesteps  | 19561    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0474   |\n",
      "|    n_updates        | 19360    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.7     |\n",
      "|    ep_rew_mean      | 19.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 932      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 323      |\n",
      "|    total_timesteps  | 19639    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.019    |\n",
      "|    n_updates        | 19438    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.2     |\n",
      "|    ep_rew_mean      | 20.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 936      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 324      |\n",
      "|    total_timesteps  | 19734    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0947   |\n",
      "|    n_updates        | 19533    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.2     |\n",
      "|    ep_rew_mean      | 20.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 940      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 326      |\n",
      "|    total_timesteps  | 19810    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0415   |\n",
      "|    n_updates        | 19609    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.7     |\n",
      "|    ep_rew_mean      | 19.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 944      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 327      |\n",
      "|    total_timesteps  | 19871    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0161   |\n",
      "|    n_updates        | 19670    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.4     |\n",
      "|    ep_rew_mean      | 19.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 948      |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 328      |\n",
      "|    total_timesteps  | 19962    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0005   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 19761    |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import highway_env\n",
    "from stable_baselines3 import DQN\n",
    "\n",
    "model = DQN('MlpPolicy', env,\n",
    "              policy_kwargs=dict(net_arch=[256, 256]),\n",
    "              learning_rate=5e-4,\n",
    "              buffer_size=15000,\n",
    "              learning_starts=200,\n",
    "              batch_size=32,\n",
    "              gamma=0.8,\n",
    "              train_freq=1,\n",
    "              gradient_steps=1,\n",
    "              target_update_interval=50,\n",
    "              verbose=1,\n",
    "              tensorboard_log=\"highway_dqn_baseline/\")\n",
    "model.learn(int(2e4))\n",
    "model.save(\"highway_dqn_baseline/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = 23.285366065523935, Steps = 30\n",
      "Episode 2: Total Reward = 22.797813107567947, Steps = 27\n",
      "Episode 3: Total Reward = 27.316765912362758, Steps = 30\n",
      "Episode 4: Total Reward = 7.098710874823523, Steps = 9\n",
      "Episode 5: Total Reward = 22.91893263557928, Steps = 30\n",
      "Episode 6: Total Reward = 22.518932269559674, Steps = 30\n",
      "Episode 7: Total Reward = 23.352931778494558, Steps = 30\n",
      "Episode 8: Total Reward = 1.8, Steps = 3\n",
      "Episode 9: Total Reward = 14.753554502369047, Steps = 19\n",
      "Episode 10: Total Reward = 6.71296719212355, Steps = 8\n",
      "Episode 11: Total Reward = 10.599377717389222, Steps = 13\n",
      "Episode 12: Total Reward = 10.652463017863719, Steps = 14\n",
      "Episode 13: Total Reward = 6.399371741791317, Steps = 8\n",
      "Episode 14: Total Reward = 23.186265529781203, Steps = 30\n",
      "Episode 15: Total Reward = 5.799649439447541, Steps = 7\n",
      "Episode 16: Total Reward = 24.553554502369668, Steps = 30\n",
      "Episode 17: Total Reward = 24.01959888645741, Steps = 30\n",
      "Episode 18: Total Reward = 8.019864435830614, Steps = 10\n",
      "Episode 19: Total Reward = 23.220221169036343, Steps = 30\n",
      "Episode 20: Total Reward = 21.018062140138472, Steps = 27\n",
      "Episode 21: Total Reward = 22.653092084926254, Steps = 30\n",
      "Episode 22: Total Reward = 4.153111909041576, Steps = 5\n",
      "Episode 23: Total Reward = 9.51169152920379, Steps = 11\n",
      "Episode 24: Total Reward = 8.852259190928365, Steps = 11\n",
      "Episode 25: Total Reward = 27.911223623176543, Steps = 30\n",
      "Episode 26: Total Reward = 5.1162693995639605, Steps = 7\n",
      "Episode 27: Total Reward = 23.486887835702998, Steps = 30\n",
      "Episode 28: Total Reward = 8.099481877983571, Steps = 10\n",
      "Episode 29: Total Reward = 24.186145261832387, Steps = 30\n",
      "Episode 30: Total Reward = 23.48688783570301, Steps = 30\n",
      "Episode 31: Total Reward = 22.653092084926254, Steps = 30\n",
      "Episode 32: Total Reward = 18.952932219757717, Steps = 26\n",
      "Episode 33: Total Reward = 23.45225142870758, Steps = 30\n",
      "Episode 34: Total Reward = 23.41796322322204, Steps = 30\n",
      "Episode 35: Total Reward = 23.886265553124073, Steps = 30\n",
      "Episode 36: Total Reward = 5.179157349186058, Steps = 6\n",
      "Episode 37: Total Reward = 2.013462830304775, Steps = 3\n",
      "Episode 38: Total Reward = 23.718926763540757, Steps = 30\n",
      "Episode 39: Total Reward = 24.41707956337935, Steps = 30\n",
      "Episode 40: Total Reward = 22.819598886424384, Steps = 30\n",
      "Episode 41: Total Reward = 6.4306704772239, Steps = 8\n",
      "Episode 42: Total Reward = 23.753554502369674, Steps = 30\n",
      "Episode 43: Total Reward = 23.319757950823302, Steps = 30\n",
      "Episode 44: Total Reward = 5.620168923598683, Steps = 8\n",
      "Episode 45: Total Reward = 25.116527056596645, Steps = 30\n",
      "Episode 46: Total Reward = 24.69568613643719, Steps = 30\n",
      "Episode 47: Total Reward = 7.353554383268054, Steps = 10\n",
      "Episode 48: Total Reward = 23.752926152592785, Steps = 30\n",
      "Episode 49: Total Reward = 24.93179531265217, Steps = 30\n",
      "Episode 50: Total Reward = 22.55293221975772, Steps = 30\n",
      "Episode 51: Total Reward = 23.486265553090515, Steps = 30\n",
      "Episode 52: Total Reward = 16.886887835703, Steps = 23\n",
      "Episode 53: Total Reward = 22.020221169036343, Steps = 30\n",
      "Episode 54: Total Reward = 7.9306704651655355, Steps = 9\n",
      "Episode 55: Total Reward = 7.399650134793548, Steps = 9\n",
      "Episode 56: Total Reward = 23.78688574299969, Steps = 30\n",
      "Episode 57: Total Reward = 25.752932114367116, Steps = 30\n",
      "Episode 58: Total Reward = 4.745203246074302, Steps = 6\n",
      "Episode 59: Total Reward = 23.867017332646906, Steps = 30\n",
      "Episode 60: Total Reward = 19.73333343878859, Steps = 24\n",
      "Episode 61: Total Reward = 4.399377276124429, Steps = 6\n",
      "Episode 62: Total Reward = 6.063381619546497, Steps = 7\n",
      "Episode 63: Total Reward = 6.650540980252457, Steps = 8\n",
      "Episode 64: Total Reward = 22.78298224446949, Steps = 30\n",
      "Episode 65: Total Reward = 25.200006081085064, Steps = 30\n",
      "Episode 66: Total Reward = 10.266666561215525, Steps = 12\n",
      "Episode 67: Total Reward = 23.352932219757708, Steps = 30\n",
      "Episode 68: Total Reward = 15.01264992523452, Steps = 16\n",
      "Episode 69: Total Reward = 25.432091081505398, Steps = 30\n",
      "Episode 70: Total Reward = 6.2842241787922415, Steps = 8\n",
      "Episode 71: Total Reward = 9.219598767146676, Steps = 12\n",
      "Episode 72: Total Reward = 12.286887835698277, Steps = 16\n",
      "Episode 73: Total Reward = 22.420221169036346, Steps = 30\n",
      "Episode 74: Total Reward = 14.932360384746625, Steps = 16\n",
      "Episode 75: Total Reward = 7.799331541010115, Steps = 9\n",
      "Episode 76: Total Reward = 24.1532500146016, Steps = 30\n",
      "Episode 77: Total Reward = 4.082313950705972, Steps = 6\n",
      "Episode 78: Total Reward = 23.35355439873941, Steps = 30\n",
      "Episode 79: Total Reward = 25.185929328306504, Steps = 30\n",
      "Episode 80: Total Reward = 21.28197949690987, Steps = 30\n",
      "Episode 81: Total Reward = 23.73306127546554, Steps = 30\n",
      "Episode 82: Total Reward = 25.352932219790738, Steps = 30\n",
      "Episode 83: Total Reward = 21.869329536662597, Steps = 26\n",
      "Episode 84: Total Reward = 2.76537776719166, Steps = 4\n",
      "Episode 85: Total Reward = 23.68400243119091, Steps = 30\n",
      "Episode 86: Total Reward = 15.420181071881693, Steps = 21\n",
      "Episode 87: Total Reward = 22.91714205983607, Steps = 30\n",
      "Episode 88: Total Reward = 17.820180179543883, Steps = 23\n",
      "Episode 89: Total Reward = 24.65309226330308, Steps = 30\n",
      "Episode 90: Total Reward = 26.69263944484397, Steps = 30\n",
      "Episode 91: Total Reward = 23.88591568791761, Steps = 30\n",
      "Episode 92: Total Reward = 26.484999189363446, Steps = 30\n",
      "Episode 93: Total Reward = 24.013648357490528, Steps = 30\n",
      "Episode 94: Total Reward = 11.362598671406031, Steps = 13\n",
      "Episode 95: Total Reward = 6.799649347879343, Steps = 8\n",
      "Episode 96: Total Reward = 13.152932219754847, Steps = 17\n",
      "Episode 97: Total Reward = 4.286531889411486, Steps = 6\n",
      "Episode 98: Total Reward = 23.715503417722402, Steps = 30\n",
      "Episode 99: Total Reward = 25.68373840702639, Steps = 30\n",
      "Episode 100: Total Reward = 11.53271298910009, Steps = 13\n"
     ]
    }
   ],
   "source": [
    "model = DQN.load(\"highway_dqn_baseline/model\")\n",
    "num_episodes = 100\n",
    "highway_dqn_baseline_frames = []  # Store frames for each episode\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    done = truncated = False\n",
    "    obs, info = env.reset()\n",
    "    total_reward = 0\n",
    "    steps = 0\n",
    "    \n",
    "    while not (done or truncated):\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        frame = env.render()\n",
    "        highway_dqn_baseline_frames.append(frame)\n",
    "        total_reward += reward\n",
    "        steps += 1\n",
    "    \n",
    "    print(f\"Episode {episode + 1}: Total Reward = {total_reward}, Steps = {steps}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model - Test Visual Inspection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video highway_baseline_performance.mp4.\n",
      "Moviepy - Writing video highway_baseline_performance.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready highway_baseline_performance.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import ImageSequenceClip\n",
    "\n",
    "# Specify the frame rate (frames per second)\n",
    "fps = 14\n",
    "\n",
    "# Create a video clip from the frames\n",
    "clip = ImageSequenceClip(highway_dqn_baseline_frames, fps=fps)\n",
    "clip.write_videofile('highway_baseline_performance.mp4', codec='libx264')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the DQN Model\n",
    "Next, define your DQN model. Here's an example using TensorFlow/Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the DQN Model\n",
    "\n",
    "Before we proceed, initialize your model by specifying the input shape and the number of actions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e4714ee739adca912176564b3eb00229",
     "grade": false,
     "grade_id": "cell-30ac99abe97e62b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Atari Space Invaders Implementation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cf70e6e3c9fe761473c11366c91f40ff",
     "grade": false,
     "grade_id": "cell-b42bead8118e3c9e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As you can see, `reset()` has returned a valid initial state as a four-tuple. The function `plot()` uses the same colour-scheme as described above, but also includes a yellow grid-square to indicate the current position of the agent.\n",
    "\n",
    "Let's make the agent go upward by using `step(1)`, then inspect the result (recall that action `1` increments the agent's vertical speed while leaving the agent's horizontal speed unchanged)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results: A presentation of your results, showing how quickly and how well your agent(s) learn (i.e., improve their policies). Include informative baselines for comparison (e.g. the best possible performance, the performance of an average human, or the performance of an agent that selects actions randomly).\n",
    "\n",
    "Discussion: An evaluation of how well you solved your chosen problem.\n",
    "\n",
    "Future work: A discussion of potential future work you would complete if you had more time.\n",
    "Personal experience: A discussion of your personal experience with the project, such as difficulties or pleasant surprises you encountered while completing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A. A., Veness, J., Bellemare, M. G. & De Freitas, N. (2015). Human-level control through deep reinforcement learning. Nature, 518(7540), 529-533.\n",
    "\n",
    "Oudeyer, P. Y., & Kaplan, F. (2007). Intrinsic motivation systems for autonomous mental development. IEEE Transactions on Evolutionary Computation, 11(1), 26-50.\n",
    "\n",
    "Schaul, T., Hung, A., Pi-Chang, H., & Sutskever, I. (2015, December). Prioritized experience replay. In Advances in neural information processing systems (pp. 4662-4670).\n",
    "\n",
    "Wang, Z., Schaul, T., Hessel, M., Van Hasselt, H., & Wierstra, D. (2016). Dueling network architectures for deep reinforcement learning. In International conference on machine learning (pp. 1994-2003).\n",
    "\n",
    "\n",
    "- Mnih, V. et al. (2015). Human-level control through deep reinforcement learning. *Nature*, 518(7540), 529-533.\n",
    "- Schulman, J., et al. (2015). Trust Region Policy Optimization. *International Conference on Machine Learning (ICML)*.\n",
    "- Schulman, J., et al. (2017). Proximal Policy Optimization Algorithms. *arXiv preprint arXiv:1707.06347*.\n",
    "- Dosovitskiy, A. et al. (2017). Learning to act by predicting the future. *International Conference on Learning Representations (ICLR)*.\n",
    "- Liang, X., et al. (2018). Deep Reinforcement Learning for Autonomous Driving. *Machine Learning Systems Workshop at NeurIPS*.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
